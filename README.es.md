<h1><a name="readme-top"></a></h1>

[![Create Release](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/release.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/release.yml)[![Translate README](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/translate.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/translate.yml)[![Generate HTML and PDF](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/generate-html.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/generate-html.yml)[![Deploy Webpage](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/deploy-webpage.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/deploy-webpage.yml)[![PSScriptAnalyzer](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/powershell.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/powershell.yml)[![Slack Notification](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/slack.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/slack.yml)

* * *

[![MIT License][license-shield]][license-url][![Forks][forks-shield]][forks-url][![Stargazers][stars-shield]][stars-url][![Contributors][contributors-shield]][contributors-url][![Issues][issues-shield]][issues-url][![LinkedIn][linkedin-shield]][linkedin-url]

* * *

# Aprendizaje de LPIC-3 305-300

![LPIC3-305-300](images/lpic3-305-300.jpg)

<p align="center">
<strong>Explore the docs ¬ª</strong></a>
    <br />
    <a href="https://marcossilvestrini.github.io/learning-lpic-3-305-300/">Web Site</a>
    -
    <a href="https://github.com/marcossilvestrini/learning-lpic-3-305-300">Code Page</a>
    -
    <a href="https://github.com/marcossilvestrini/learning-lpic-3-305-300/issues">Report Bug</a>
    -
    <a href="https://github.com/marcossilvestrini/learning-lpic-3-305-300/issues">Request Feature</a>
</p>

* * *

## Resumen

<details>
  <summary><b>TABLE OF CONTENT</b></summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
    </li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#prerequisites">Prerequisites</a></li>
        <li><a href="#installation">installation</a></li>
      </ul>
    </li>
    <li><a href="#usage">Usage</a></li>
    <li><a href="#roadmap">Roadmap</a></li>
    <li><a href="#freedoms">Four Essential Freedoms</a></li>
    <li>
      <a href="#topic-351">Topic 351: Full Virtualization</a>
      <ul>
        <li><a href="#topic-351.1">351.1 Virtualization Concepts and Theory </a></li>
        <li><a href="#topic-351.2">351.2 Xen</a></li>
        <li><a href="#topic-351.3">351.3 QEMU</a></li>
        <li><a href="#topic-351.4">351.4 Libvirt Virtual Machine</a></li>
        <li><a href="#topic-351.5">351.5 Virtual Machine Disk Image Management</a></li>
      </ul>
    </li>
    <li>
      <a href="#topic-352">Topic 352: Container Virtualization</a>
      <ul>
        <li><a href="#topic-352.1">352.1 Container Virtualization Concepts</a></li>
        <li><a href="#topic-352.2">352.2 LXC</a></li>
        <li><a href="#topic-352.3">352.3 Docker</a></li>
        <li><a href="#topic-352.4">352.4 Container Orchestration Platforms</a></li>
      </ul>
    </li>
    <li>
      <a href="#topic-353">Topic 353: VM Deployment and Provisioning</a>
      <ul>
        <li><a href="#topic-353.1">353.1 Cloud Management Tools</a></li>
        <li><a href="#topic-353.2">353.2 Packer</a></li>
        <li><a href="#topic-353.3">353.3 cloud-init</a></li>
        <li><a href="#topic-353.4">353.4 Vagrant</a></li>
      </ul>
    </li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
    <li><a href="#acknowledgments">Acknowledgments</a></li>
  </ol>
</details><br>

* * *

<a name="about-the-project"></a>

## Acerca del proyecto

> Este proyecto tiene como objetivo ayudar a los estudiantes o profesionales a aprender los conceptos principales de Gnulinux.
> y software libre \\
> Algunas distribuciones de Gnulinux como Debian y RPM estar√°n cubiertas \\
> La instalaci√≥n y la configuraci√≥n de algunos paquetes tambi√©n se cubrir√°n \\
> Al hacer esto, puede darle a toda la comunidad la oportunidad de beneficiarse de sus cambios.
> El acceso al c√≥digo fuente es una condici√≥n previa para esto. \\
> Use Vagrant para m√°quinas UP y ejecute laboratorios y practique contenido en este art√≠culo.
> He publicado en carpeta Vagrant un archivo vagabundo con lo que es necesario \\
> Para que subas un entorno para estudios

* * *

<p align="right">(<a href="#readme-top">back to top</a>)</p>

<a name="getting-started"></a>

## Empezando

Para comenzar el aprendizaje, consulte la documentaci√≥n anterior.

<a name="prerequisites"></a>

### Requisitos previos

-   [Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
-   [Estaci√≥n de trabajo de VMware](https://blogs.vmware.com/workstation/2024/05/vmware-workstation-pro-now-available-free-for-personal-use.html)
-   [Utilidad de VMware vagabundo](https://developer.hashicorp.com/vagrant/install/vmware)
-   [Vagabundo](https://developer.hashicorp.com/vagrant/install)

<a name="installation"></a>

### Instalaci√≥n

Clonar el repositorio

```sh
git clone https://github.com/marcossilvestrini/learning-lpic-3-305-300.git
cd learning-lpic-3-305-300
```

Personalizar una plantilla_Vagrantfile-topic-xxx_. Este archivo contiene una configuraci√≥n de VMS para Labs. Ejemplo:

-   Archivo[Vagantfile-topic-351](./vagrant/Vagrantfile-topic-351)
    -   vm.clone_directory = "&lt;Your_driver_letter>:\\<folder>\\&lt;TO_MACHINE>\\#{Vm_name} -instance-1 "
        Ejemplo: vm.clone_directory = "e:\\Servidor\\VMware\\#{Vm_name} -instance-1 "
    -   vm.vmx["Memsize"]= ""
    -   vm.vmx["Numvcpus"]= ""
    -   vm.vmx["CPUID.CORRESPERSOCOUT"]= ""

Personalizar la configuraci√≥n de la red en archivos[configuraciones/red](configs/network/).

* * *

<a name="usage"></a>

## Uso

Use este repositorio para obtener el aprendizaje sobre el examen LPIC-3 305-300

### Para arriba y abajo

Cambiar un_Vagrantfile-topic-xxx_plantilla y copia para un nuevo archivo con el nombre_Archivo vagabundo_

```sh
cd vagrant && vagrant up
cd vagrant && vagrant destroy -f
```

### Para reiniciar m√°quinas virtuales

```sh
cd vagrant && vagrant reload
```

**Importante:**_Si reinicia las m√°quinas virtuales sin Vagerant, la carpeta compartida no se monta despu√©s del arranque._

### Use PowerShell para arriba y abajo

Si usa la plataforma Windows, creo un script PowerShell para VMS arriba y abajo.

```powershell
vagrant/up.ps1
vagrant/destroy.ps1
```

### Schema de infraestructura Tema 351

![topic-351](images/infraestructure-topic-351.png)

<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="roadmap"></a>

## Hoja de ruta

-   [x] Crear repositorio
-   [x] Crear scripts para el aprovisionamiento de laboratorios
-   [x] Crear ejemplos sobre el tema 351
-   [ ] Crear ejemplos sobre el tema 352
-   [ ] Crear ejemplos sobre el tema 353
-   [ ] Cargar itexam simulado

* * *

<a name="freedoms"></a>

## Cuatro libertades esenciales

> 0\. La libertad de ejecutar el programa como desee, para cualquier prop√≥sito (libertad 0).
> 1.La libertad para estudiar c√≥mo funciona el programa y cambiarlo para que lo haga \\
> Su computaci√≥n como desee (Libertad 1). \\
> El acceso al c√≥digo fuente es una condici√≥n previa para esto. \\
> 2\. La libertad para redistribuir copias para que pueda ayudar a los dem√°s (Libertad 2).
> 3\. Freedom para distribuir copias de sus versiones modificadas a otros (libertad 3).

* * *

## Inspeccionar comandos

```sh
type COMMAND
apropos COMMAND
whatis COMMAND --long
whereis COMMAND
COMMAND --help, --h
man COMMAND
```

<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351"></a>

## Tema 351: Virtualizaci√≥n completa

![LPIC3-305-300](images/virtualization-351.png)

* * *

<a name="topic-351.1"></a>

### 351.1 Conceptos y teor√≠a de virtualizaci√≥n

**Peso:**6

**Descripci√≥n:**Los candidatos deben conocer y comprender los conceptos generales, la teor√≠a y la terminolog√≠a de la virtualizaci√≥n. Esto incluye la terminolog√≠a Xen, Qemu y Libvirt.

**√Åreas clave de conocimiento:**

-   üñ•Ô∏è Comprender la terminolog√≠a de la virtualizaci√≥n
-   ‚öñÔ∏è Comprender los pros y los contras de la virtualizaci√≥n
-   üõ†Ô∏è Comprenda las diversas variaciones de hipervisores y monitores de m√°quinas virtuales
-   üîÑ Comprender los aspectos principales de la migraci√≥n de m√°quinas f√≠sicas a virtuales
-   üöÄ Comprender los aspectos principales de la migraci√≥n de m√°quinas virtuales entre los sistemas de host
-   üì∏ Comprenda las caracter√≠sticas y las implicaciones de la virtualizaci√≥n para una m√°quina virtual, como instant√°neas, pausas, clonaci√≥n y l√≠mites de recursos
-   üåê Conciencia de Ovirt, Proxmox, Systemd-Machined y VirtualBox
-   üîó Conciencia de Open Vswitch

#### 351.1 Objetos citados

```sh
Hypervisor
Hardware Virtual Machine (HVM)
Paravirtualization (PV)
Emulation and Simulation
CPU flags
/proc/cpuinfo
Migration (P2V, V2V)
```

#### Hipervisores

##### Hypervisor tipo 1 (hipervisor de metal desnudo)

###### Definici√≥n de tipo 1

Se ejecuta directamente en el hardware f√≠sico del host, proporcionando una capa base para administrar m√°quinas virtuales sin la necesidad de un sistema operativo del host.

###### Caracter√≠sticas del tipo 1

-   ‚ö° Alto rendimiento y eficiencia.
-   ‚è±Ô∏è Mayor latencia y sobrecarga.
-   üè¢ A menudo se usa en entornos empresariales y centros de datos.

###### Ejemplos de tipo 1

-   VMware ESXI: un hipervisor robusto y ampliamente utilizado en la configuraci√≥n empresarial.
-   Microsoft Hyper-V: integrado con Windows Server, que ofrece un fuerte rendimiento y caracter√≠sticas de administraci√≥n.
-   XEN: Un hipervisor de c√≥digo abierto utilizado por muchos proveedores de servicios en la nube.
-   KVM (m√°quina virtual basada en el n√∫cleo): integrado en el kernel de Linux, proporcionando un alto rendimiento para los sistemas basados ‚Äã‚Äãen Linux.

##### Hypervisor tipo 2 (Hypervisor alojado)

###### Definici√≥n de tipo 2

Se ejecuta adem√°s de un sistema operativo convencional, confiando en el sistema operativo host para la administraci√≥n de recursos y el soporte de dispositivos.

###### Caracter√≠sticas de tipo 2

-   üõ†Ô∏è m√°s f√°cil de configurar y usar, especialmente en computadoras personales.
-   üîß M√°s flexible para el desarrollo, las pruebas y las implementaciones de menor escala.
-   üê¢ Por lo general, menos eficiente que los hipervisores tipo 1 debido a la sobrecarga adicional del sistema operativo host.

###### Ejemplos de tipo 2

-   Estaci√≥n de trabajo VMware: un potente hipervisor para ejecutar m√∫ltiples sistemas operativos en un solo escritorio.
-   Oracle VirtualBox: un hipervisor de c√≥digo abierto conocido por su flexibilidad y facilidad de uso.
-   Desktop paralelo: dise√±ado para que los usuarios de Mac ejecute Windows y otros sistemas operativos junto con macOS.
-   QEMU (emulador r√°pido): un emulador y virtualizador de c√≥digo abierto, a menudo utilizado junto con KVM.

##### Diferencias clave entre los hipervisores tipo 1 y tipo 2

-   Entorno de implementaci√≥n:
    -   Los hipervisores tipo 1 se implementan com√∫nmente en centros de datos y entornos empresariales debido a su interacci√≥n directa con hardware y alto rendimiento.
    -   Los hipervisores tipo 2 son m√°s adecuados para el uso personal, el desarrollo, las pruebas y las tareas de virtualizaci√≥n a peque√±a escala.
-   Actuaci√≥n:
    -   Los hipervisores tipo 1 generalmente ofrecen un mejor rendimiento y una latencia m√°s baja porque no dependen de un sistema operativo host.
    -   Los hipervisores tipo 2 pueden experimentar cierta degradaci√≥n del rendimiento debido a la sobrecarga de correr encima de un sistema operativo host.
-   Gesti√≥n y facilidad de uso:
    -   Los hipervisores tipo 1 requieren una configuraci√≥n y gesti√≥n m√°s complejas, pero proporcionan caracter√≠sticas avanzadas y escalabilidad para implementaciones a gran escala.
    -   Los hipervisores tipo 2 son m√°s f√°ciles de instalar y usar, lo que los hace ideales para usuarios individuales y proyectos m√°s peque√±os.

##### Tipos de migraci√≥n

En el contexto de los hipervisores, que son tecnolog√≠as utilizadas para crear y administrar m√°quinas virtuales, los t√©rminos migraci√≥n de P2V y migraci√≥n de V2V son comunes en entornos de virtualizaci√≥n.  
Se refieren a procesos de sistemas migratorios entre diferentes tipos de plataformas.

##### P2V - migraci√≥n f√≠sica a virtual

La migraci√≥n de P2V se refiere al proceso de migraci√≥n de un servidor f√≠sico a una m√°quina virtual.  
En otras palabras, un sistema operativo y sus aplicaciones, que se ejecutan en hardware f√≠sico dedicado, se "convierten" y se mueven a una m√°quina virtual que se ejecuta en un hipervisor (como VMware, Hyper-V, KVM, etc.).

-   Ejemplo: tiene un servidor f√≠sico que ejecuta un sistema de Windows o Linux, y desea moverlo a un entorno virtual, como una infraestructura en la nube o un servidor de virtualizaci√≥n interno.  
    El proceso implica copiar todo el estado del sistema, incluido el sistema operativo, los controladores y los datos, para crear una m√°quina virtual equivalente que pueda ejecutarse como si estuviera en el hardware f√≠sico.

##### V2V - migraci√≥n virtual a virtual

La migraci√≥n de V2V se refiere al proceso de migraci√≥n de una m√°quina virtual de un hipervisor a otro.  
En este caso, ya tiene una m√°quina virtual que se ejecuta en un entorno virtualizado (como VMware), y desea moverla a otro entorno virtualizado (por ejemplo, a Hyper-V o a un nuevo servidor VMware).

-   Ejemplo: tiene una m√°quina virtual que se ejecuta en un servidor de virtualizaci√≥n VMware, pero decide migrarla a una plataforma Hyper-V. En este caso, la migraci√≥n V2V convierte la m√°quina virtual de un formato o hipervisor a otro, asegurando que pueda continuar funcionando correctamente.

#### HVM y paravirtualizaci√≥n

##### Virtualizaci√≥n asistida por hardware (HVM)

###### Definici√≥n de HVM

HVM aprovecha las extensiones de hardware proporcionadas por las CPU modernas para virtualizar el hardware, lo que permite la creaci√≥n y gesti√≥n de m√°quinas virtuales con una sobrecarga de rendimiento m√≠nima.

###### Caracter√≠sticas de la clave HVM

-   üñ•Ô∏è**Soporte de hardware**: Requiere soporte de CPU para extensiones de virtualizaci√≥n como Intel VT-X o AMD-V.
-   üõ†Ô∏è**Virtualizaci√≥n completa:**Las m√°quinas virtuales pueden ejecutar sistemas operativos invitados no modificados, ya que el hipervisor proporciona una emulaci√≥n completa del entorno de hardware.
-   ‚ö°**Actuaci√≥n:**Por lo general, ofrece un rendimiento casi nativo debido a la ejecuci√≥n directa del c√≥digo de invitado en la CPU.
-   üîí**Aislamiento:**Proporciona un aislamiento fuerte entre las m√°quinas virtuales ya que cada VM funciona como si tuviera su propio hardware dedicado.

###### Ejemplo de HVM

VMware ESXI, Microsoft Hyper-V, KVM (m√°quina virtual basada en kernel).

###### Ventajas de HVM

-   ‚úÖ**Compatibilidad:**Puede ejecutar cualquier sistema operativo sin modificaci√≥n.
-   ‚ö°**Actuaci√≥n:**Alto rendimiento debido al soporte de hardware.
-   üîí**Seguridad:**Caracter√≠sticas mejoradas de aislamiento y seguridad proporcionadas por hardware.

###### Desventajas de HVM

-   üõ†Ô∏è**Dependencia del hardware:**Requiere caracter√≠sticas de hardware espec√≠ficas, limitando la compatibilidad con los sistemas m√°s antiguos.
-   üîß**Complejidad:**Puede involucrar una configuraci√≥n y administraci√≥n m√°s complejas.

##### Paravirtualizaci√≥n

###### Definici√≥n de paravirtualizaci√≥n

La paravirtualizaci√≥n implica modificar el sistema operativo invitado para conocer el entorno virtual, lo que le permite interactuar de manera m√°s eficiente con el hipervisor.

###### Caracter√≠sticas clave de paravirtualizaci√≥n

-   üõ†Ô∏è**Modificaci√≥n del invitado:**Requiere cambios en el sistema operativo invitado para comunicarse directamente con el hipervisor utilizando hipercalls.
-   ‚ö°**Actuaci√≥n:**Puede ser m√°s eficiente que la virtualizaci√≥n completa tradicional porque reduce la sobrecarga asociada con la emulaci√≥n de hardware.
-   üîó**Compatibilidad:**Limitado a los sistemas operativos que han sido modificados para la paravirtualizaci√≥n.

###### Ejemplos de paravirtualizaci√≥n

Xen con invitados paravirtualizados, herramientas de VMware en ciertas configuraciones y algunas configuraciones de KVM.

###### Ventajas de paravirtualizaci√≥n

-   ‚ö°**Eficiencia:**Reduce la sobrecarga de la virtualizaci√≥n del hardware, que potencialmente ofrece un mejor rendimiento para ciertas cargas de trabajo.
-   ‚úÖ**Utilizaci√≥n de recursos:**Uso m√°s eficiente de los recursos del sistema debido a la comunicaci√≥n directa entre el sistema operativo invitado y el hipervisor.

###### Desventajas de paravirtualizaci√≥n

-   üõ†Ô∏è**Modificaci√≥n del sistema operativo de invitado:**Requiere modificaciones al sistema operativo invitado, lo que limita la compatibilidad a los sistemas operativos compatibles.
-   üîß**Complejidad:**Requiere complejidad adicional en el sistema operativo invitado para implementaciones de hipercall.

##### Diferencias clave

###### Requisitos del sistema operativo de invitado

-   **HVM:**Puede ejecutar sistemas operativos invitados no modificados.
-   **Paravirtualizaci√≥n:**Requiere que los sistemas operativos de hu√©spedes se modifiquen para trabajar con el hipervisor.

###### Actuaci√≥n

-   **HVM:**Por lo general, proporciona un rendimiento casi nativo debido a la ejecuci√≥n asistida por hardware.
-   **Paravirtualizaci√≥n:**Puede ofrecer un rendimiento eficiente al reducir la sobrecarga de la emulaci√≥n de hardware, pero se basa en un sistema operativo invitado modificado.

###### Dependencia de hardware

-   **HVM:**Requiere caracter√≠sticas espec√≠ficas de CPU (Intel VT-X, AMD-V).
-   **Paravirtualizaci√≥n:**No requiere caracter√≠sticas espec√≠ficas de la CPU, pero necesita un sistema operativo invitado modificado.

###### Aislamiento

-   **HVM:**Proporciona un aislamiento fuerte utilizando caracter√≠sticas de hardware.
-   **Paravirtualizaci√≥n:**Se basa en el aislamiento basado en software, que puede no ser tan robusto como el aislamiento basado en hardware.

###### Complejidad

-   **HVM:**Generalmente m√°s sencillo de implementar ya que admite un sistema operativo no modificado.
-   **Paravirtualizaci√≥n:**Requiere una configuraci√≥n y modificaciones adicionales al sistema operativo invitado, aumentando la complejidad.

#### NUMA (acceso a la memoria no uniforme)

NUMA (acceso de memoria no uniforme) es una arquitectura de memoria utilizada en los sistemas multiprocesador para optimizar el acceso a la memoria por los procesadores.  
En un sistema NUMA, la memoria se distribuye de manera desigual entre los procesadores, lo que significa que cada procesador tiene un acceso m√°s r√°pido a una parte de la memoria (su "memoria local") que a la memoria que est√° f√≠sicamente m√°s lejos (denominada "memoria remota") y asociada con otros procesadores.

##### Caracter√≠sticas clave de la arquitectura NUMA

1.  **Memoria local y remota**: Cada procesador tiene su propia memoria local, a la que puede acceder m√°s r√°pidamente. Sin embargo, tambi√©n puede acceder a la memoria de otros procesadores, aunque esto lleva m√°s tiempo.
2.  **Latencia diferenciada**: La latencia del acceso a la memoria var√≠a seg√∫n si el procesador est√° accediendo a su memoria local o la memoria de otro nodo. El acceso a la memoria local es m√°s r√°pido, mientras que acceder a la memoria de otro nodo (remota) es m√°s lento.
3.  **Escalabilidad**: La arquitectura NUMA est√° dise√±ada para mejorar la escalabilidad en sistemas con muchos procesadores. A medida que se agregan m√°s procesadores, la memoria tambi√©n se distribuye, evitando el cuello de botella que ocurrir√≠a en una arquitectura de acceso de memoria uniforme (UMA).

##### Ventajas de NUMA

-   ‚ö° Mejor rendimiento en sistemas grandes: dado que cada procesador tiene memoria local, puede funcionar de manera m√°s eficiente sin competir tanto con otros procesadores para el acceso a la memoria.
-   üìà Escalabilidad: NUMA permite sistemas con muchos procesadores y grandes cantidades de memoria escalar de manera m√°s efectiva en comparaci√≥n con una arquitectura UMA.

##### Desventajas

-   üõ†Ô∏è Complejidad de programaci√≥n: los programadores deben ser conscientes de qu√© regiones de memoria son locales o remotas, optimizando el uso de la memoria local para lograr un mejor rendimiento.
-   üê¢ Sanciones potenciales de rendimiento: si un procesador con frecuencia accede a la memoria remota, el rendimiento puede sufrir debido a una mayor latencia.
    Esta arquitectura es com√∫n en los sistemas multiprocesador de alto rendimiento, como servidores y supercomputadoras, donde la escalabilidad y la optimizaci√≥n de la memoria son cr√≠ticos.

#### OpenSource Solutions

-   üåê Ovirt:<https://www.ovirt.org/>

-   üåê Proxmox:<https://www.proxmox.com/en/proxmox-virtual-environment/overview>

-   üåê Oracle VirtualBox:<https://www.virtualbox.org/>

-   üåê Abra vswitch:<https://www.openvswitch.org/>

#### Tipos de virtualizaci√≥n

##### Virtualizaci√≥n de hardware (virtualizaci√≥n del servidor)

###### Definici√≥n de HV

Abraza el hardware f√≠sico para crear m√°quinas virtuales (VM) que ejecutan sistemas operativos y aplicaciones separadas.

###### Casos de uso de HV

Centros de datos, computaci√≥n en la nube, consolidaci√≥n del servidor.

###### Ejemplos de HV

VMware ESXI, Microsoft Hyper-V, KVM.

##### Virtualizaci√≥n del sistema operativo (contenedorizaci√≥n)

###### Definici√≥n de contenedores

Permite que se ejecuten m√∫ltiples instancias de espacio de usuario aisladas (contenedores) en un solo n√∫cleo del sistema operativo.

###### Casos de uso de contenedores

Microservicios Arquitectura, desarrollo y entornos de prueba.

###### Ejemplos de contenedores

Docker, Kubernetes, LXC.

##### Virtualizaci√≥n de red

###### Definici√≥n de virtualizaci√≥n de red

Combina recursos de red de hardware y software en una entidad administrativa √∫nica basada en software.

###### Casos de uso de virtualizaci√≥n de red

Networking (SDN) definido por software, Virtualizaci√≥n de funciones de red (NFV).

###### Ejemplos de virtualizaci√≥n de red

VMware NSX, Cisco ACI, OpenStack Neutron.

##### Virtualizaci√≥n de almacenamiento

###### Definici√≥n de virtualizaci√≥n de almacenamiento

Agrupar el almacenamiento f√≠sico de m√∫ltiples dispositivos en una sola unidad de almacenamiento virtual que se puede administrar centralmente.

###### Casos de uso de definici√≥n de virtualizaci√≥n de almacenamiento

Gesti√≥n de datos, optimizaci√≥n de almacenamiento, recuperaci√≥n de desastres.

###### Ejemplos de definici√≥n de virtualizaci√≥n de almacenamiento

Controlador de volumen IBM SAN, VMware VSAN, NetApp Ontap.

##### Virtualizaci√≥n de escritorio

###### Definici√≥n de virtualizaci√≥n de escritorio

Permite que un sistema operativo de escritorio se ejecute en una m√°quina virtual alojada en un servidor.

###### Casos de uso de definici√≥n de virtualizaci√≥n de escritorio

Infraestructura de escritorio virtual (VDI), soluciones de trabajo remoto.

###### Ejemplos de definici√≥n de virtualizaci√≥n de escritorio

Aplicaciones y escritorios virtuales de Citrix, VMware Horizon, Servicios de escritorio remotos de Microsoft.

##### Virtualizaci√≥n de la aplicaci√≥n

###### Definici√≥n de virtualizaci√≥n de la aplicaci√≥n

Separa las aplicaciones del hardware y el sistema operativo subyacente, lo que les permite ejecutarse en entornos aislados.

###### Casos de uso de la definici√≥n de virtualizaci√≥n de la aplicaci√≥n

Implementaci√≥n de aplicaciones simplificada, prueba de compatibilidad.

###### Ejemplos de definici√≥n de virtualizaci√≥n de aplicaciones

VMware ThinApp, Microsoft App-V, Citrix XenApp.

##### Virtualizaci√≥n de datos

###### Definici√≥n de virtualizaci√≥n de datos

Integra datos de varias fuentes sin consolidarlo f√≠sicamente, proporcionando una vista unificada para el an√°lisis y los informes.

###### Casos de uso de la definici√≥n de virtualizaci√≥n de datos

Inteligencia de negocios, integraci√≥n de datos en tiempo real.

###### Ejemplos de definici√≥n de virtualizaci√≥n de datos

Denodo, Red Hat JBoss Virtualizaci√≥n de datos, IBM InfoShere.

##### Beneficios de la virtualizaci√≥n

-   ‚ö° Eficiencia de recursos: mejor utilizaci√≥n de los recursos f√≠sicos.
-   üí∞ Ahorro de costos: costos reducidos de hardware y operaciones.
-   üìà Escalabilidad: f√°cil de escalar hacia arriba o hacia abajo seg√∫n la demanda.
-   üîß Flexibilidad: admite una variedad de cargas de trabajo y aplicaciones.
-   üîÑ Recuperaci√≥n por desastres: procesos de respaldo y recuperaci√≥n simplificados.
-   üîí Aislamiento: mejor seguridad a trav√©s del aislamiento de los entornos.

#### Emulaci√≥n

La emulaci√≥n implica simular el comportamiento del hardware o el software en una plataforma diferente a la prevista originalmente.

Este proceso permite el software dise√±ado para que un sistema se ejecute en otro sistema que puede tener una arquitectura o entorno operativo diferente.

Si bien la emulaci√≥n proporciona versatilidad al habilitar la ejecuci√≥n de sistemas operativos o aplicaciones de invitados no modificados, a menudo viene con sobrecarga de rendimiento.

Esta sobrecarga surge porque el sistema emulado necesita interpretar y traducir instrucciones destinadas al sistema original a instrucciones compatibles con el sistema de host. Como resultado, la emulaci√≥n puede ser m√°s lenta que la ejecuci√≥n nativa, lo que lo hace menos eficiente para las tareas intensivas en recursos.

A pesar de este inconveniente, la emulaci√≥n sigue siendo valiosa para ejecutar software heredado, probar aplicaciones en diferentes plataformas y facilitar el desarrollo multiplataforma.

#### systemd-maquined

El servicio Machined SystemD est√° dedicado a administrar m√°quinas y contenedores virtuales dentro del ecosistema SystemD.
 Proporciona funcionalidades esenciales para controlar, monitorear y mantener instancias virtuales, ofreciendo una integraci√≥n y eficiencia s√≥lidas dentro de los entornos de Linux.

<p align="right">(<a href="#topic-351.1">back to sub Topic 351.1</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351.2"></a>

### 351.2 Alterna

![xen-architecture](images/xen-achitecture.png)

![xen-architecture](images/xen-achitecture2.png)

**Peso:**3

**Descripci√≥n:**Los candidatos deben poder instalar, configurar, mantener, migrar y solucionar problemas de XEN. El foco est√° en XEN versi√≥n 4.x.

**√Åreas clave de conocimiento:**

-   Comprender la arquitectura de Xen, incluidas las redes y el almacenamiento
-   Configuraci√≥n b√°sica de nodos y dominios XEN
-   Gesti√≥n b√°sica de nodos y dominios XEN
-   Soluci√≥n de problemas b√°sicas de las instalaciones de XEN
-   P√≠ldora de avarines
-   Conciencia de Xenstore
-   Conciencia de los par√°metros de arranque xen
-   Conciencia de la utilidad XM

#### Alternar

![panda](images/xen-panda.png)

Xen es un hipervisor de c√≥digo abierto (desnudo) (moderno), que permite que m√∫ltiples sistemas operativos se ejecuten simult√°neamente en el mismo hardware f√≠sico.  
Xen proporciona una capa entre el hardware f√≠sico y las m√°quinas virtuales (VM), lo que permite un intercambio de recursos eficiente y el aislamiento.

-   **Arquitectura:**XEN opera con un sistema de dos niveles donde el dominio 0 (DOM0) es el dominio privilegiado con acceso directo a hardware y administra el hipervisor. Otras m√°quinas virtuales, llamadas Domain U (DOMU), ejecutan sistemas operativos invitados y son administradas por DOM0.
-   **Tipos de virtualizaci√≥n:**XEN admite la paravirtualizaci√≥n (PV), que requiere un sistema operativo invitado modificado y la virtualizaci√≥n asistida por hardware (HVM), que utiliza extensiones de hardware (por ejemplo, Intel VT-X o AMD-V) para ejecutar sistemas operativos invitados no modificados.
    XEN es ampliamente utilizado en entornos en la nube, especialmente por Amazon Web Services (AWS) y otros proveedores de nubes a gran escala.

#### Xenseurce

Xensource fue la compa√±√≠a fundada por los desarrolladores originales del Xen Hypervisor de la Universidad de Cambridge para comercializar Xen.  
La Compa√±√≠a proporcion√≥ soluciones empresariales basadas en XEN y ofreci√≥ herramientas y soporte adicionales para mejorar las capacidades de XEN para uso empresarial.

-   **Adquisici√≥n de Citrix**: En 2007, Xensource fue adquirido por Citrix Systems, Inc. Citrix utiliz√≥ la tecnolog√≠a XEN como base para su producto Citrix Xenserver, que se convirti√≥ en una plataforma de virtualizaci√≥n popular de grado empresarial basada en Xen.
-   **Transici√≥n**: Despu√©s de la adquisici√≥n, el Proyecto XEN continu√≥ como un proyecto de c√≥digo abierto, mientras que Citrix se centr√≥ en ofertas comerciales como Xenserver, aprovechando la tecnolog√≠a Xensource.

#### Proyecto Xen

El Proyecto XEN se refiere a la comunidad e iniciativa de c√≥digo abierto responsables de desarrollar y mantener el Hypervisor XEN despu√©s de su comercializaci√≥n.  
El proyecto XEN opera bajo la Fundaci√≥n Linux, con un enfoque en la construcci√≥n, mejora y apoyar a Xen como un esfuerzo colaborativo y impulsado por la comunidad.

-   **Objetivos:**El proyecto XEN tiene como objetivo avanzar al hipervisor mejorando su rendimiento, seguridad y conjunto de caracter√≠sticas para una amplia gama de casos de uso, incluida la computaci√≥n en la nube, la virtualizaci√≥n centrada en la seguridad (por ejemplo, QUBES OS) y sistemas integrados.
-   **Colaboradores:**El proyecto incluye contribuyentes de varias organizaciones, incluidos los principales proveedores de la nube, proveedores de hardware y desarrolladores independientes.
-   **P√≠ldora y hedools:**El proyecto XEN tambi√©n incluye herramientas como XAPI (XENAPI), que se utiliza para administrar las instalaciones de XEN Hypervisor y varias otras utilidades para la gesti√≥n y optimizaci√≥n del sistema.

#### Xenstore

La tienda XEN es un componente cr√≠tico del Hypervisor XEN.  
Esencialmente, Xen Store es una base de datos de valor clave distribuida utilizada para la comunicaci√≥n y el intercambio de informaci√≥n entre el Hypervisor XEN y las m√°quinas virtuales (tambi√©n conocidas como dominios) que administra.

Aqu√≠ hay algunos aspectos clave de la tienda Xen:

-   **Comunicaci√≥n entre dominios:**La tienda XEN permite la comunicaci√≥n entre dominios, como DOM0 (el dominio privilegiado que controla los recursos de hardware) y DOMUS (dominios de usuario, que son las m√°quinas virtuales). Esto se realiza a trav√©s de entradas de valor clave, donde cada dominio puede leer o escribir informaci√≥n.

-   **Gesti√≥n de configuraci√≥n:**Se utiliza para almacenar y acceder a la informaci√≥n de configuraci√≥n, como dispositivos virtuales, redes y par√°metros de arranque. Esto facilita la gesti√≥n din√°mica y la configuraci√≥n de las m√°quinas virtuales.

-   **Eventos y notificaciones:**Xen Store tambi√©n admite notificaciones de eventos. Cuando se modifica una clave o valor particular en la tienda XEN, se pueden notificar dominios interesados ‚Äã‚Äãpara reaccionar a estos cambios. Esto es √∫til para monitorear y administrar recursos.

-   API simple: la tienda XEN proporciona una API simple para leer y escribir datos, lo que facilita a los desarrolladores integrar sus aplicaciones con el sistema de virtualizaci√≥n XEN.

#### P√≠ldora

XAPI, o XENAPI, es la interfaz de programaci√≥n de aplicaciones (API) utilizada para administrar el Hypervisor XEN y sus m√°quinas virtuales (VM).  
XAPI es un componente clave de Xenserver (ahora conocido como Citrix Hypervisor) y proporciona una forma estandarizada de interactuar con el Hypervisor XEN para realizar operaciones como crear, configurar, monitorear y controlar las m√°quinas virtuales.

Aqu√≠ hay algunos aspectos importantes de Xapi:

-   **Gesti√≥n de VM:**XAPI permite a los administradores crear, eliminar, iniciar, iniciar y detener las m√°quinas virtuales.

-   **Automatizaci√≥n:**Con XAPI, es posible automatizar la gesti√≥n de los recursos virtuales, incluidas las redes, el almacenamiento y la computaci√≥n, que es crucial para grandes entornos en la nube.

-   **Integraci√≥n:**XAPI se puede integrar con otras herramientas y scripts para proporcionar una administraci√≥n m√°s eficiente y personalizada del entorno XEN.

-   **Control de acceso:**XAPI tambi√©n proporciona mecanismos de control de acceso para garantizar que solo los usuarios autorizados puedan realizar operaciones espec√≠ficas en el entorno virtual.

XAPI es la interfaz que permite el control y la automatizaci√≥n del Hypervisor XEN, lo que facilita la gesti√≥n de entornos virtualizados.

#### Resumen de Xen

-   **Interpretado:**La tecnolog√≠a Core Hypervisor que permite que las m√°quinas virtuales se ejecuten en hardware f√≠sico.
-   **XENSOURCE:**La compa√±√≠a que comercializ√≥ Xen, m√°s tarde adquirida por Citrix, que condujo al desarrollo de Citrix Xenserver.
-   **Proyecto Xen:**La iniciativa de c√≥digo abierto y la comunidad que contin√∫a desarrollando y manteniendo el Hypervisor XEN bajo la Fundaci√≥n Linux.
-   **Xenstore:**La tienda XEN act√∫a como un intermediario de comunicaci√≥n y configuraci√≥n entre el Hypervisor XEN y las m√°quinas virtuales, racionalizando la operaci√≥n y la gesti√≥n de entornos virtualizados.
-   **P√≠ldora**es la interfaz que permite el control y la automatizaci√≥n del Hypervisor XEN, lo que facilita la gesti√≥n de entornos virtualizados.

#### Dominio0 (DOM0)

Domain0, o DOM0, es el dominio de control en una arquitectura XEN. Manejan otros dominios (DOMUS) y tiene acceso directo al hardware.  
DOM0 ejecuta los controladores de dispositivos, permitiendo que DOMUS, que carecen de acceso directo a hardware, se comuniquen con los dispositivos. Por lo general, es una instancia completa de un sistema operativo, como Linux, y es esencial para la operaci√≥n del hipervisor XEN.

#### Dominio (casa)

DOMUS son dominios no privilegiados que ejecutan m√°quinas virtuales.  
Son administrados por DOM0 y no tienen acceso directo al hardware. DOMUS se puede configurar para ejecutar diferentes sistemas operativos y se utilizan para varios fines, como servidores de aplicaciones y entornos de desarrollo. Conf√≠an en DOM0 para la interacci√≥n de hardware.

#### Peewee-Dom (Paravardiyed Domina)

PV-DOMUS Utiliza una t√©cnica llamada paravirtualizaci√≥n. En este modelo, el sistema operativo DOMU se modifica para tener en cuenta que se ejecuta en un entorno virtualizado, lo que le permite comunicarse directamente con el hipervisor para un rendimiento optimizado.  
Esto da como resultado una sobrecarga m√°s baja y una mejor eficiencia en comparaci√≥n con la virtualizaci√≥n completa.

#### HVM-DOMU (Hardware Virtual Machine Domainu)

HVM-DOMUS son m√°quinas virtuales que utilizan virtualizaci√≥n completa, lo que permite que los sistemas operativos no modificados se ejecuten. El Hypervisor XEN proporciona emulaci√≥n de hardware para estos DOMUS, lo que les permite ejecutar cualquier sistema operativo que admita la arquitectura de hardware subyacente.  
Si bien esto ofrece una mayor flexibilidad, puede dar como resultado una mayor sobrecarga en comparaci√≥n con PV-DOMUS.

#### Red xen

Dispositivos de red en paravirtualizados![pv-networking](images/xen-networking2.png)

Puente![pv-networking](images/xen-networking1.png)

#### 351.2 Objetos citados

```sh
Domain0 (Dom0), DomainU (DomU)
PV-DomU, HVM-DomU
/etc/xen/
xl
xl.cfg 
xl.conf # Xen global configurations
xentop
oxenstored # Xenstore configurations
```

#### 351.2 notas

```sh

# Xen Settings
/etc/xen/
/etc/xen/xl.conf - Main general configuration file for Xen
/etc/xen/oxenstored.conf - Xenstore configurations

# VM Configurations
/etc/xen/xlexample.pvlinux
/etc/xen/xlexample.hvm

# Service Configurations
/etc/default/xen
/etc/default/xendomains

# xen-tools configurations
/etc/xen-tools/
/usr/share/xen-tools/

# docs
xl(1)
xl.conf(5)
xlcpupool.cfg(5)
xl-disk-configuration(5)
xl-network-configuration(5)
xen-tscmode(7)

# initialized domains auto
/etc/default/xendomains
   XENDOMAINS_AUTO=/etc/xen/auto

/etc/xen/auto/


# set domain for up after xen reboot
## create folder auto
cd /etc/xen && mkdir -p auto && cd auto

# create simbolic link
ln -s /etc/xen/lpic3-pv-guest /etc/xen/auto/lpic3-pv-guest
```

#### 351.2 comandos importantes

##### xen-create-imagen

```sh
# create a pv image
xen-create-image \
  --hostname=lpic3-pv-guest \
  --memory=1gb \
  --vcpus=2 \
  --lvm=vg_xen \
  --bridge=xenbr0 \
  --dhcp \
  --pygrub \
  --password=vagrant \
  --dist=bookworm
```

##### im√°genes de la lista xen

```sh
# list image
xen-list-image
```

##### Xen-Delete-Image

```sh
# delete a pv image
xen-delete-image lpic3-pv-guest --lvm=vg_xen
```

##### xenstore-ls

```sh
# list xenstore infos
xenstore-ls
```

##### SG

```sh
# view xen information
xl infos

# list Domains
xl list
xl list lpic3-hvm-guest
xl list lpic3-hvm-guest -l

# uptime Domains
xl uptime

# pause Domain
xl pause 2
xl pause lpic3-hvm-guest

# save state Domains
xl -v save lpic3-hvm-guest ~root/image-lpic3-hvm-guest.save

# restore Domain
xl restore /root/image-lpic3-hvm-guest.save

# get Domain name
xl domname 2

# view dmesg information
xl dmesg

# monitoring domain
xl top
xentop
xen top

# Limit mem Dom0
xl mem-set 0 2048

# Limite cpu (not permanent after boot)
xl vcpu-set 0 2

# create DomainU - virtual machine
xl create /etc/xen/lpic3-pv-guest.cfg

# create DomainU virtual machine and connect to guest
xl create -c /etc/xen/lpic3-pv-guest.cfg

##----------------------------------------------
# create DomainU virtual machine HVM

## create logical volume
lvcreate -l +20%FREE -n lpic3-hvm-guest-disk  vg_xen

## create a ssh tunel for vnc
ssh -l vagrant -L 5900:localhost:5900  192.168.0.130

## configure /etc/xen/lpic3-hvm-guest.cfg
## set boot for cdrom: boot = "d"

## create domain hvm
xl create /etc/xen/lpic3-hvm-guest.cfg

## open vcn conection in your vnc client with localhost
## for view install details

## after installation finished, destroy domain: xl destroy <id_or_name>

## set /etc/xen/lpic3-hvm-guest.cfg: boot for hard disc: boot = "c"

## create domain hvm
xl create /etc/xen/lpic3-hvm-guest.cfg

## access domain hvm
xl console <id_or_name>
##----------------------------------------------

# connect in domain guest
xl console <id>|<name> (press enter)
xl console 1
xl console lpic3-pv-guest

#How do I exit domU "xl console" session
#Press ctrl+] or if you're using Putty press ctrl+5.

# Poweroff domain
xl shutdown lpic3-pv-guest

# destroy domain
xl destroy lpic3-pv-guest

# reboot domain
xl reboot lpic3-pv-guest

# list block devices
xl block-list 1
xl block-list lpic3-pv-guest

# detach block devices
xl block-detach lpic3-hvm-guest hdc
xl block-detach 2 xvdc

# attach block devices

## hard disk devices
xl block-attach lpic3-hvm-guest-ubuntu 'phy:/dev/vg_xen/lpic3-hvm-guest-disk2,xvde,w'

## cdrom
xl block-attach lpic3-hvm-guest 'file:/home/vagrant/isos/ubuntu/seed.iso,xvdc:cdrom,r'
xl block-attach 2 'file:/home/vagrant/isos/ubuntu/seed.iso,xvdc:cdrom,r'

# insert and eject cdrom devices
xl cd-insert lpic3-hvm-guest-ubuntu xvdb  /home/vagrant/isos/ubuntu/ubuntu-24.04.1-live-server-amd64.iso
xl cd-eject lpic3-hvm-guest-ubuntu xvdb
```

#### 251.2 notas

##### vif

En XEN, "VIF" significa interfaz virtual y se utiliza para configurar redes para m√°quinas virtuales (dominios).

Al especificar las directivas "VIF" en los archivos de configuraci√≥n de dominio, los administradores pueden definir interfaces de red, asignar direcciones IP, configurar VLAN y configurar otros par√°metros de red para m√°quinas virtuales que se ejecutan en los hosts XEN. Por ejemplo: vif =[‚ÄòBridge = xenbr0], en este caso, conecta la interfaz de red de la VM con el puente XEN llamado "XenBr0".

````sh

<p align="right">(<a href="#topic-351.2">back to sub Topic 351.2</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

---

<a name="topic-351.3"></a>

### 351.3 QEMU

![xen-kvm-qemu](/images/xen-kvm-qemu.png)

**Weight:** 4

**Description:** Candidates should be able to install, configure, maintain, migrate and troubleshoot QEMU installations.

**Key Knowledge Areas:**

* Understand the architecture of QEMU, including KVM, networking and storage
* Start QEMU instances from the command line
* Manage snapshots using the QEMU monitor
* Install the QEMU Guest Agent and VirtIO device drivers
* Troubleshoot QEMU installations, including networking and storage
* Awareness of important QEMU configuration parameters

#### 351.3 Cited Objects

```sh
Kernel modules: kvm, kvm-intel and kvm-amd
/dev/kvm
QEMU monitor
qemu
qemu-system-x86_64
ip
brctl
tunctl
````

#### 351.3 comandos importantes

##### 351.3 Otros comandos

##### Verifique el m√≥dulo KVM

```sh
# check if kvm is enabled
egrep -o '(vmx|svm)' /proc/cpuinfo
lscpu |grep Virtualization
lsmod|grep kvm
ls -l /dev/kvm
hostnamectl
systemd-detect-virt
```

```sh
# check if kvm is enabled
egrep -o '(vmx|svm)' /proc/cpuinfo
lscpu |grep Virtualization
lsmod|grep kvm
ls -l /dev/kvm

# check kernel infos
uname -a

# check root device
findmnt /

# mount a qcow2 image
## Example 1:
mkdir -p /mnt/qemu
guestmount -a os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 -i /mnt/qemu/

## Example 2:
sudo guestfish --rw -a os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2
run
list-filesystems

# run commands in qcow2 images
## Example 1:
virt-customize -a  os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2  --run-command 'echo hello >/root/hello.txt'
## Example 2:
sudo virt-customize -a os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  --run-command 'echo -e "auto ens3\niface ens3 inet dhcp" > /etc/network/interfaces.d/ens3.cfg'

# generate mac 
printf 'DE:AD:BE:EF:%02X:%02X\n' $((RANDOM%256)) $((RANDOM%256))
```

##### IP

```sh
# list links
ip link show

# create bridge
ip link add br0 type bridge
```

##### brctl

```sh
# list links
ip link show

# create bridge
ip link add br0 type bridge
```

##### QEM-IMG

```sh
# create image
qemu-img create -f qcow2 vm-disk-debian-12.qcow2 20G

# convert vmdk to qcow2 image
qemu-img convert \
  -f vmdk \
  -O qcow2 os-images/Debian_12.0.0_VMM/Debian_12.0.0_VMM_LinuxVMImages.COM.vmdk os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -p \
  -m16

# check image
qemu-img info os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2
```

##### qemu-system-x86_64

```sh
# create vm with ISO
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm -hda vm-disk-debian-12.qcow2 \
  -cdrom /home/vagrant/isos/debian/debian-12.8.0-amd64-DVD-1.iso  \
  -boot d \
  -m 2048 \
  -smp cpus=2 \
  -k pt-br

# create vm with ISO using vnc in no gui servers \ ssh connections

## create ssh tunel in host
 ssh -l vagrant -L 5902:localhost:5902  192.168.0.131

## create vm 
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -k pt-br \
  -vnc :2 \
  -device qemu-xhci \
  -device usb-tablet \
  -device ide-cd,bus=ide.1,drive=cdrom,bootindex=1 \
  -drive id=cdrom,media=cdrom,if=none,file=/home/vagrant/isos/debian/debian-12.8.0-amd64-DVD-1.iso \
  -hda vm-disk-debian-12.qcow2 \
  -boot order=d \
  -vga std \
  -display none \
  -monitor stdio

# create vm with OS Image - qcow2

## create vm
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -k pt-br \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2

## create vm with custom kernel params
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -kernel /vmlinuz \
  -initrd /initrd.img \
  -append "root=/dev/mapper/debian--vg-root ro fastboot console=ttyS0" \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -k pt-br \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2

## create vm with and attach disk
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -hdb vmdisk-debian12.qcow2 \
  -drive file=vmdisk-extra-debian12.qcow2,index=2,media=disk,if=ide \
  -netdev bridge,id=net0,br=qemubr0 \
  -device virtio-net-pci,netdev=net0
  
## create vm network netdev user
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -netdev user,id=mynet0,net=192.168.0.150/24,dhcpstart=192.168.0.155,hostfwd=tcp::2222-:22 \
  -device virtio-net-pci,netdev=mynet0

## create vm network netdev tap (Private Network)
ip link add br0 type bridge ; ifconfig br0 up
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -netdev tap,id=br0 \
  -device e1000,netdev=br0,mac=DE:AD:BE:EF:1A:24

## create vm with public bridge
#create a public bridge : https://www.linux-kvm.org/page/Networking

qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -k pt-br \
  -vnc :2 \
  -device qemu-xhci \
  -device usb-tablet \
  -vga std \
  -display none \
  -netdev bridge,id=net0,br=qemubr0 \
  -device virtio-net-pci,netdev=net0

## get a ipv4 ip - open ssh in vm and:
dhcpclient ens4
```

#### Monitor QEMU

Para iniciar el monitor QEMU en el uso de l√≠nea de comandos**-monitor stdio**paramur**qemu-system-x86_64**

```sh
qemu-system-x86_64 -monitor stdio
```

Salir qemu-monitor:

```sh
ctrl+alt+2
```

```sh
# Managment
info status # vm info
info cpus # cpu information
info network # network informations
stop # pause vm
cont # start vm in status pause
system_powerdown # poweroff vm
system_reset # restart monitor


# Blocks
info block # block info
boot_set d # force boot iso
change ide1-cd0  /home/vagrant/isos/debian/debian-12.8.0-amd64-DVD-1.iso  # attach cdrom
eject ide1-cd0 # detach cdrom

# Snapshots
info snapshots # list snapshots
savevm snapshot-01  # create snapshot
loadvm snapshot-01 # restore snapshot
delvm snapshot-01
```

#### Agente invitado

Para habilitar, usar:

```sh
qemu-system-x86_x64
 -chardev socket,path=/tmp/qga.sock,server=on,wait=off,id=qga0 \
 -device virtio-serial \
 -device virtserialport,chardev=qga0,name=org.qemu.guest_agent.0
```

<p align="right">(<a href="#topic-351.3">back to sub Topic 351.3</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351.4"></a>

### 351.4 Libvirt Virtual Machine Management

![libvirt](images/libvirt.png)

![libvirt-network](images/libvirt-default-network.jpg)

**Peso:**9

**Descripci√≥n:**Los candidatos deben poder administrar hosts de virtualizaci√≥n y m√°quinas virtuales ("dominios libvirt") utilizando libvirt y herramientas relacionadas.

**√Åreas clave de conocimiento:**

-   Comprender la arquitectura de libvirt
-   Gestionar las conexiones y nodos libvirt
-   Crear y administrar dominios QEMU y XEN, incluidas las instant√°neas
-   Administrar y analizar el consumo de recursos de dominios
-   Crear y administrar grupos y vol√∫menes de almacenamiento
-   Crear y administrar redes virtuales
-   Migrar dominios entre nodos
-   Comprender c√≥mo Libvirt interact√∫a con Xen y Qemu
-   Comprenda c√≥mo Libvirt interact√∫a con servicios de red como DNSMASQ y RADVD
-   Comprender archivos de configuraci√≥n de Libvirt XML
-   Conciencia de VirtLogd y Virtlockd

#### 351.4 Objetos citados

```sh
libvirtd
/etc/libvirt/
/var/lib/libvirt
/var/log/libvirt
virsh (including relevant subcommands) 
```

#### 351.4 comandos importantes

##### Virsh

```sh
# using env variable for set virsh uri (local or remotly)
export LIBVIRT_DEFAULT_URI=qemu:///system
export LIBVIRT_DEFAULT_URI=xen+ssh://vagrant@192.168.0.130
export LIBVIRT_DEFAULT_URI='xen+ssh://vagrant@192.168.0.130?keyfile=/home/vagrant/.ssh/skynet-key-ecdsa'

# COMMONS

# get helps
virsh help
virsh help pool-create

# view version
virsh version

# view system info
sudo virsh sysinfo

# view node info
virsh nodeinfo

# hostname
virsh hostname

# check vcn allocated port
virsh vncdisplay <domain_id>
virsh vncdisplay <domain_name>
virsh vncdisplay rocky9-server01 

# HYPERVISIONER

# view libvirt hypervisioner connection
virsh uri

# list valid hypervisioners
virt-host-validate
virt-host-validate qemu

# test connetion uri(vm test)
virsh -c test:///default list

# connect remotly
virsh -c xen+ssh://vagrant@192.168.0.130
virsh -c xen+ssh://vagrant@192.168.0.130 list
virsh -c qemu+ssh://vagrant@192.168.0.130/system list

# connect remotly without enter password
virsh -c 'xen+ssh://vagrant@192.168.0.130?keyfile=/home/vagrant/.ssh/skynet-key-ecdsa'

# STORAGE

# list storage pools
virsh pool-list --details

# list all storage pool
virsh pool-list --all --details

# get a pool configuration
virsh pool-dumpxml default

# get pool info
virsh pool-info default

# create a storage pool
virsh pool-define-as --name default --type dir --target /var/lib/libvirt/images

# create a storage pool with dumpxml
virsh pool-create --overwrite --file configs/kvm/libvirt/pool.xml

# start storage pool
virsh pool-start default

# set storage pool for autostart
virsh pool-autostart default

# stop storage pool
virsh pool-destroy linux

# delete xml storage pool file
virsh pool-undefine linux

# edit storage pool
virsh pool-edit linux

# list volumes
virsh vol-list linux

# get volume infos
virsh vol-info Debian_12.0.0.qcow2 os-images
virsh vol-info --pool os-images Debian_12.0.0.qcow2 

# get volume xml
virsh vol-dumpxml rocky9-disk1 default

# create volume
virsh vol-create-as default --format qcow2 disk1 10G

# delete volume
virsh vol-delete  disk1 default

# DOMAINS \ INSTANCES \ VIRTUAL MACHINES

# list domain\instance\vm
virsh list
virsh list --all

# create domain\instance\vm
virsh create configs/kvm/libvirt/rocky9-server03.xml

# view domain\instance\vm info
virsh dominfo rocky9-server01

# view domain\instance\vm xml
virsh dumpxml rocky9-server01

# edit domain\instance\vm xml
virsh edit rocky9-server01

# stop domain\instance\vm
virsh shutdown rocky9-server01 # gracefully
virsh destroy 1
virsh destroy rocky9-server01

# suspend domain\instance\vm
virsh suspend rocky9-server01

# resume domain\instance\vm
virsh resume rocky9-server01

# start domain\instance\vm
virsh start rocky9-server01

# remove domain\instance\vm
virsh undefine rocky9-server01

# remove domain\instance\vm and storage volumes
virsh undefine rocky9-server01 --remove-all-storage

# save domain\instance\vm
virsh save rocky9-server01 rocky9-server01.qcow2

# restore domain\instance\vm
virsh restore rocky9-server01.qcow2

# list snapshots
virsh snapshot-list rocky9-server01

# create snapshot
virsh snapshot-create rocky9-server01

# restore snapshot
virsh snapshot-revert rocky9-server01 1748983520

# view snapshot xml
virsh snapshot-info rocky9-server01 1748983520

# dumpxml snapshot
virsh snapshot-dumpxml rocky9-server01 1748983520

# xml snapshot path
/var/lib/libvirt/qemu/snapshot/rocky9-server01/

# view snapshot info
virsh snapshot-info rocky9-server01 1748983671

# edit snapshot
virsh snapshot-edit rocky9-server01 1748983520

# delete snapshot
virsh snapshot-delete rocky9-server01 1748983520

# DEVICES

# list block devices
virsh domblklist rocky9-server01 --details

# add cdrom media 
virsh change-media rocky9-server01 sda /home/vagrant/isos/rocky/Rocky-9.5-x86_64-minimal.iso
virsh attach-disk rocky9-server01 /home/vagrant/isos/rocky/Rocky-9.5-x86_64-minimal.iso sda --type cdrom --mode readonly

# remove cdrom media
virsh change-media rocky9-server01 sda --eject

# add new disk
virsh attach-disk rocky9-server01  /var/lib/libvirt/images/rocky9-disk2  vdb --persistent

# remove disk
virsh detach-disk rocky9-server01 vdb --persistent

# RESOURCES (CPU and Memory)

# get cpu infos
virsh vcpuinfo rocky9-server01 --pretty
virsh dominfo rocky9-server01 | grep 'CPU'

# get vcpu count
virsh vcpucount rocky9-server01

# set vcpus maximum config
virsh setvcpus rocky9-server01 --count 4 --maximum --config
virsh shutdown rocky9-server01
virsh start rocky9-server01

# set vcpu current config
virsh setvcpus rocky9-server01 --count 4 --config

# set vcpu current live
virsh setvcpus rocky9-server01 --count 3 --current
virsh setvcpus rocky9-server01 --count 3 --live

# configure vcpu afinity config
virsh vcpupin rocky9-server01 0 7 --config
virsh vcpupin rocky9-server01 1 5-6 --config

# configure vcpu afinity current
virsh vcpupin rocky9-server01 0 7
virsh vcpupin rocky9-server01 1 5-6

# set maximum memory config
virsh setmaxmem rocky9-server01 3000000 --config
virsh shutdown rocky9-server01
virsh start rocky9-server01

# set current memory config
virsh setmem rocky9-server01 2500000 --current

# NETWORK

# get netwwork bridges
brctl show

# get iptables rules for libvirt
sudo iptables -L -n -t  nat

# list network
virsh net-list --all

# set default network
virsh net-define /etc/libvirt/qemu/networks/default.xml

# get network infos
virsh net-info default

# get xml network
virsh net-dumpxml default

# xml file
cat /etc/libvirt/qemu/networks/default.xml

# dhcp config
sudo cat /etc/libvirt/qemu/networks/default.xml | grep -A 10 dhcp
sudo cat /var/lib/libvirt/dnsmasq/default.conf

# get domain ipp address
virsh net-dhcp-leases default
virsh net-dhcp-leases default --mac 52\:54\:00\:89\:19\:86

# edit network
virsh net-edit default

# get domain network detais
virsh domiflist debian-server01

# path for network filter files
/etc/libvirt/nwfilter/

# list network filters
virsh nwfilter-list

# create network filter - block icmp traffic
virsh nwfilter-define block-icmp.xml
# virsh edit Debian-Server
    #  <interface type='network'>
    #        ...
    #        <filterref filter='block-icmp'/>
    #        ...
    # </interface>
# virsh destroy debian-server01
# virsh start debian-server01

# delete network filter
virsh nwfilter-undefine block-icmp

# get xml network filter
virsh nwfilter-dumpxml block-icmp
```

###### Virt-Install

```sh
# list os variants
virt-install --os-variant list
osinfo-query os

# create domain\instance\vm with iso file
virsh vol-create-as default --format qcow2 rocky9-disk1 20G
virt-install --name rocky9-server01 \
--vcpus 2 \
--cpu host \
--memory 2048 \
--disk vol=default/rocky9-disk1 \
--cdrom /home/vagrant/isos/rocky/Rocky-9.5-x86_64-minimal.iso \
--os-variant=rocky9 \
--graphics vnc,listen=0.0.0.0,port=5905

# create debian domain\instance\vm with qcow2 file
virt-install --name debian-server01 \
--vcpus 2 \
--ram 2048 \
--disk vol=os-images/Debian_12.0.0.qcow2 \
--import \
--osinfo detect=on \
--graphics vnc,listen=0.0.0.0,port=5906 \
--network network=default \
--noautoconsole

# create rocky9 domain\instance\vm with qcow2 file
virt-install --name rocky9-server02 \
--vcpus 2 \
--ram 2048 \
--disk path=os-images/RockyLinux_9.4_VMG/RockyLinux_9.4.qcow2,format=qcow2,bus=virtio \
--import \
--osinfo detect=on \
--graphics vnc,listen=0.0.0.0,port=5907 \
--network bridge=qemubr0,model=virtio \
--noautoconsole

# open domain\instance\vm gui console
virt-viewer debian-server01

# check metadata domain\instance\vm file (if uri is qemu:////system)
less /etc/libvirt/qemu/debian-server01.xml
```

<p align="right">(<a href="#topic-351.4">back to sub Topic 351.4</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351.5"></a>

### 351.5 Administraci√≥n de im√°genes de disco de m√°quina virtual

![disk-managment](images/virtual-machine-disk.png)

**Peso:**3

**Descripci√≥n:**Los candidatos deben poder administrar im√°genes de disco de m√°quinas virtuales. Esto incluye la conversi√≥n de im√°genes de disco entre varios formatos e hipervisores y el acceso a los datos almacenados dentro de una imagen.

**√Åreas clave de conocimiento:**

-   Comprender las caracter√≠sticas de varios formatos de imagen de disco virtual, como im√°genes RAW, QCOW2 y VMDK
-   Administrar im√°genes de disco de m√°quina virtual usando qemu-img
-   Monte las particiones y los archivos de acceso contenidos en las im√°genes de disco de m√°quina virtual utilizando el pez libguest
-   Copiar contenido de disco f√≠sico a una imagen de disco de m√°quina virtual
-   Migrar contenido de disco entre varios formatos de imagen de disco de m√°quina virtual
-   Conciencia del formato de virtualizaci√≥n abierta (OVF)

#### 351.5 objetos citados

```sh
qemu-img
guestfish (including relevant subcommands)
guestmount
guestumount
virt-cat
virt-copy-in
virt-copy-out
virt-diff
virt-inspector
virt-filesystems
virt-rescue
virt-df
virt-sparsify
virt-p2v
virt-p2v-make-disk
virt-v2v
```

#### 351.5 comandos importantes

##### 351.5.1 QEMU-IMG

```sh
# Display detailed information about a disk image
qemu-img info UbuntuServer_24.04.qcow2

# Create a new 22G raw disk image (default format is raw)
qemu-img create new-disk 22G

# Create a new 22G disk image in qcow2 format
qemu-img create -f qcow2 new-disk2 22G

# Convert a VDI image to raw format using 5 threads and show progress
qemu-img convert -f vdi -O raw Ubuntu-Server.vdk new-Ubuntu.raw -m5 -p

# Convert vmdk to qcow2 image
qemu-img convert \
-f vmdk \
-O qcow2 os-images/UbuntuServer_24.04_VM/UbuntuServer_24.04_VM_LinuxVMImages.COM.vmdk \
os-images/UbuntuServer_24.04_VM/UbuntuServer_24.04.qcow2 \
-p \
-m16

# Resize a raw image to 30G
qemu-img resize -f raw new-disk 30G

# Resize a qcow2 image to 15G(actual size 30Gdisk 30G)
qemu-img resize -f raw --shrink new-disk 15G

# Snapshots

# List all snapshots in the image
qemu-img snapshot -l new-disk2.qcow2

# Create a snapshot named SNAP1
qemu-img snapshot -c SNAP1 disk

# Apply a snapshot by ID or name
qemu-img snapshot -a 123456789 disk

# Delete the snapshot named SNAP1
qemu-img snapshot -d SNAP1 disk
```

##### pez invitado

```sh
# set enviroment variables for guestfish
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg

# Launch guestfish with a disk image
guestfish -a UbuntuServer_24.04.qcow2
#run
#list-partitions

# Run the commands in a script file
guestfish -a UbuntuServer_24.04.qcow2 -m /dev/sda -i < script.ssh

# Interactively run commands
guestfish --rw -a UbuntuServer_24.04.qcow2 <<'EOF'
run
list-filesystems
EOF

# Copy a file from the guest image to the host
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
sudo guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
copy-out /etc/hostname /tmp/
EOF

# Copy a file from the host into the guest image
echo "new-hostname" > /tmp/hostname
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
sudo guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
copy-in /tmp/hostname /etc/
EOF

# View contents of a file in the guest image
guestfish --ro -a UbuntuServer_24.04.qcow2 -i <<'EOF'
cat /etc/hostname
EOF

# List files in the guest image
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
ls /home/ubuntu
EOF

# Edit a file in the guest image
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
edit /etc/hosts
EOF
```

###### montaje de invitados

```sh
# Mount a disk image to a directory
guestmount -a UbuntuServer_24.04.qcow2 -m /dev/ubuntu-vg/ubuntu-lv /mnt/ubuntu
# domain
guestmount -d rocky9-server02 -m /dev/ubuntu-vg/ubuntu-lv /mnt/ubuntu 

# Mount a specific partition from a disk image
guestmount -a UbuntuServer_24.04.qcow2 -m /dev/sda2 /mnt/ubuntu
# domain
guestmount -d debian-server01 --ro -m  /dev/debian-vg/root /mnt/debian
```

###### invitada

```sh
# Umount a disk image to a directory
sudo guestunmount /mnt/ubuntu
```

##### virt-DF

```sh
# Show free and used space on virtual machine filesystems
virt-df UbuntuServer_24.04.qcow2 -h
virt-df -d rocky9-server02 -h
```

##### virtilystems

```sh
# List filesystems, partitions, and logical volumes in a VM disk image (disk image)
virt-filesystems -a UbuntuServer_24.04.qcow2 --all --long -h

# List filesystems, partitions, and logical volumes in a VM disk image (domain)
virt-filesystems -d debian-server01 --all --long -h
```

##### Virt-inspector

```sh
# Inspect and report on the operating system in a VM disk image
virt-inspector -a UbuntuServer_24.04.qcow2 #(disk)
virt-inspector -d debian-server01 #(domain) 
```

##### virt Cat

```sh
# Display the contents of a file inside a VM disk image
virt-cat -a UbuntuServer_24.04.qcow2 /etc/hosts
virt-cat -d debian-server01 /etc/hosts #(domain)
```

##### virt-diff

```sh
# Show differences between two VM disk images
virt-diff -a UbuntuServer_24.04.qcow2 -A Rocky-Linux.qcow2
```

##### virt-sparsify

```sh
# Make a VM disk image smaller by removing unused space
virt-sparsify UbuntuServer_24.04.qcow2 UbuntuServer_24.04-sparse.qcow2
```

##### retrato de virtud

```sh
# Resize a VM disk image or its partitions
virt-filesystems -a UbuntuServer_24.04.qcow2 --all --long -h #(check size of partitions)
qemu-img create -f qcow2 UbuntuServer_24.04-expanded.qcow2 100G #(create new disk image with 100G)
virt-resize --expand /dev/ubuntu-vg/ubuntu-lv \
UbuntuServer_24.04.qcow2 UbuntuServer_24.04-expanded.qcow2

```

##### virt-in-in

```sh
# Copy files from the host into a VM disk image

virt-copy-in -a UbuntuServer_24.04.qcow2 ~vagrant/test-virt-copy-in.txt /home/ubuntu
```

##### virtud

```sh
# Copy files from a VM disk image to the host
virt-copy-out -a UbuntuServer_24.04.qcow2 /home/ubuntu/.bashrc /tmp
```

##### virt-LS

```sh
# List files and directories inside a VM disk image
virt-ls -a UbuntuServer_24.04.qcow2 /home/ubuntu
```

##### rescate de virtud

```sh
# Launch a rescue shell on a VM disk image for recovery
virt-rescue -a UbuntuServer_24.04.qcow2
```

##### Virt-sysprep

```sh
# Prepare a VM disk image for cloning by removing system-specific data
virt-sysprep -a UbuntuServer_24.04.qcow2
```

##### virt-v2v

```sh
# Convert a VM from a foreign hypervisor to run on KVM
virt-v2v -i disk input-disk.img -o local -os /var/tmp
```

##### virt-p2v

```sh
# Convert a physical machine to use KVM
```

##### virt-p2v-make-disisk

```sh
# Create a bootable disk image for physical to virtual conversion
sudo virt-p2v-make-disk -o output.img
```

#### 351.5 notas

##### OVF: Formato de virtualizaci√≥n abierto

OVF: un formato abierto que define un est√°ndar para empaquetar y distribuir m√°quinas virtuales en diferentes entornos.

El paquete generado tiene la extensi√≥n .ova y contiene los siguientes archivos:

-   .ovf: archivo XML con metadatos que definen el entorno de la m√°quina virtual
-   Archivos de imagen: .vmdk, .vhd, .vhdx, .qcow2, .raw
-   Archivos adicionales: metadatos, instant√°neas, configuraci√≥n, hash

<p align="right">(<a href="#topic-351.5">back to sub Topic 351.5</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-352"></a>

## Tema 352: Virtualizaci√≥n de contenedores

* * *

<a name="topic-352.1"></a>

### 352.1 Conceptos de virtualizaci√≥n de contenedores

![virtualization-container](images/virtualization-container.png)

```mermaid
timeline
    title Time Line Containers Evolution
    1979 : chroot
    2000 : FreeBSD Jails
    2002 : Linux Namespaces
    2005 : Solaris Containers
    2007 : cgroups
    2008 : LXC
    2013 : Docker
    2015 : Kubernetes
```

* * *

**Peso:**7

**Descripci√≥n:**Los candidatos deben comprender el concepto de virtualizaci√≥n de contenedores. Esto incluye comprender los componentes de Linux utilizados para implementar la virtualizaci√≥n de contenedores, as√≠ como usar herramientas de Linux est√°ndar para solucionar estos componentes.

**√Åreas clave de conocimiento:**

-   Comprender los conceptos del sistema y el contenedor de aplicaciones
-   Comprender y analizar los espacios de nombres del n√∫cleo
-   Comprender y analizar grupos de control
-   Comprender y analizar las capacidades
-   Comprender el papel de SecComp, Selinux y Apparmor para la virtualizaci√≥n de contenedores
-   Comprenda c√≥mo LXC y Docker aprovechan los espacios de nombres, CGROUPS, Capacidades, SECComp y Mac
-   Comprender el principio de RUNC
-   Comprender el principio de Cri-O y Containerd
-   Conciencia del tiempo de ejecuci√≥n de OCI y las especificaciones de la imagen
-   Conciencia de la interfaz de tiempo de ejecuci√≥n del contenedor Kubernetes (CRI)
-   Conciencia de Podman, Buildah y Scopeo
-   Conciencia de otros enfoques de virtualizaci√≥n de contenedores en Linux y otros sistemas operativos gratuitos, como RKT, OpenVZ, Systemd-Nspawn o BSD Cails

* * *

#### 352.1 Objetos citados

```sh
nsenter
unshare
ip (including relevant subcommands)
capsh
/sys/fs/cgroups
/proc/[0-9]+/ns
/proc/[0-9]+/status
```

* * *

#### Chroot: cambiar el directorio ra√≠z en Unix/Linux

![chroot](images/chroot.png)

##### ¬øQu√© es Chroot?

Chroot (abreviatura de Root de cambio) es una llamada y comando del sistema en sistemas operativos similares a UNIX que cambia el directorio ra√≠z aparente (/) para el proceso de ejecuci√≥n actual y sus hijos. Esto crea un entorno aislado, com√∫nmente conocido como una c√°rcel de chroot.

##### üß± Casos de prop√≥sito y uso

-   üîí Aislar aplicaciones para la seguridad (c√°rcel).
-   üß™ Crear entornos de prueba sin afectar el resto del sistema.
-   üõ†Ô∏è Recuperaci√≥n del sistema (por ejemplo, arranque en LIVECD y Chroot en el sistema instalado).
-   üì¶ Construir paquetes de software en un entorno controlado.

##### üìÅ Estructura m√≠nima requerida

El entorno chroot debe tener sus propios archivos y estructura esenciales:

```sh
/mnt/myenv/
‚îú‚îÄ‚îÄ bin/
‚îÇ   ‚îî‚îÄ‚îÄ bash
‚îú‚îÄ‚îÄ etc/
‚îú‚îÄ‚îÄ lib/
‚îú‚îÄ‚îÄ lib64/
‚îú‚îÄ‚îÄ usr/
‚îú‚îÄ‚îÄ dev/
‚îú‚îÄ‚îÄ proc/
‚îî‚îÄ‚îÄ tmp/
```

Use LDD para identificar las bibliotecas requeridas:

```sh
ldd /bin/bash
```

##### üö® Limitaciones y consideraciones de seguridad

-   Chroot no es un l√≠mite de seguridad como contenedores o m√°quinas virtuales.
-   Un usuario privilegiado (ra√≠z) dentro de la c√°rcel puede estallar.
-   No hay aislamiento de espacios de nombres de procesos, dispositivos o recursos a nivel de n√∫cleo.

Para un aislamiento m√°s fuerte, considere alternativas como:

-   Contenedores de Linux (LXC, Docker)
-   M√°quinas virtuales (KVM, QEMU)
-   Espacios de nombres de n√∫cleo y CGROUPS

##### üß™ Ejemplo: configuraci√≥n b√°sica del entorno de chroot

Use este script para configurar un entorno m√≠nimo de chroot:

[**chroot.sh**](scripts/container/chroot.sh)

##### üß™ Pruebe chroot con desbootstrap

```sh
# download debain files
sudo debootstrap stable ~vagrant/debian http://deb.debian.org/debian
sudo chroot ~vagrant/debian bash
```

#### üîç Comprender los contenedores

![container](images/containers1.png)

Los contenedores son una tecnolog√≠a de virtualizaci√≥n ligera que empaqueta las aplicaciones junto con sus dependencias requeridas (c√≥digo, bibliotecas, variables de entorno y archivos de configuraci√≥n) en unidades aisladas, port√°tiles y reproducibles.

> En t√©rminos simples: un contenedor es una caja aut√≥noma que ejecuta su aplicaci√≥n de la misma manera, en cualquier lugar.

##### üí° ¬øQu√© es un contenedor?

A diferencia de las m√°quinas virtuales (m√°quinas virtuales), los contenedores no virtualizan hardware. En cambio, virtualizan el sistema operativo. Los contenedores comparten el mismo n√∫cleo de Linux con el host, pero cada uno funciona en un espacio de usuario totalmente aislado.

üìå Contenedores vs m√°quinas virtuales:

| Caracter√≠stica               | Contenedores                                     | M√°quinas virtuales                        |
| ---------------------------- | ------------------------------------------------ | ----------------------------------------- |
| Kernel del sistema operativo | Compartido con el anfitri√≥n                      | Cada VM tiene su propio sistema operativo |
| Tiempo de inicio             | R√°pido (segundos o menos)                        | Lento (minutos)                           |
| Tama√±o de imagen             | Ligero (MBS)                                     | Pesado (GBS)                              |
| Eficiencia de recursos       | Alto                                             | M√°s bajo                                  |
| Mecanismo de aislamiento     | Caracter√≠sticas del n√∫cleo (espacios de nombres) | Hipervisor                                |

##### üîë Caracter√≠sticas clave de los contenedores

üîπ**Ligero**: Comparta el n√∫cleo del sistema operativo Host, reduciendo la sobrecarga y habilita el inicio r√°pido.

üîπ**Port√°til**: Ejecute consistentemente en diferentes entornos (Dev, Staging, ProD, Cloud, On-Prem).

üîπ**Aislado**: Use espacios de nombres para el aislamiento de procesos, redes y sistemas de archivos.

üîπ**Eficiente**: Habilite una mayor densidad y una mejor utilizaci√≥n de recursos que las m√°quinas virtuales tradicionales.

üîπ**Escalable**: Perfecto ajuste para microservicios y arquitectura nativa de nube.

##### üß± Tipos de contenedores

1.  Contenedores del sistema
    -   Dise√±ado para ejecutar todo el sistema operativo, parecerse a las m√°quinas virtuales.
    -   Admite m√∫ltiples procesos y servicios del sistema (init, syslog).
    -   Ideal para aplicaciones heredadas o monol√≠ticas.
    -   Ejemplo: LXC, Libvirt-LXC.

2.  Contenedores de aplicaciones
    -   Dise√±ado para ejecutar un solo proceso.
    -   Sin estado, ef√≠mero y horizontalmente escalable.
    -   Se utiliza ampliamente en entornos modernos DevOps y Kubernetes.
    -   Ejemplo: Docker, Containerd, Cri-O.

##### üöÄ Times de ejecuci√≥n de contenedores populares

| Tiempo de ejecuci√≥n | Descripci√≥n                                                                             |
| ------------------- | --------------------------------------------------------------------------------------- |
| **Estibador**       | La CLI/demonio m√°s adoptada para los contenedores de construcci√≥n y ejecuci√≥n.          |
| **contenedor**      | Docker y Kubernetes ligeros de tiempo de ejecuci√≥n.                                     |
| **Criticarlo**      | Tiempo de ejecuci√≥n nativo de Kubernetes para contenedores OCI.                         |
| **LXC**             | Contenedores tradicionales del sistema Linux, m√°s cerca del sistema operativo completo. |
| **Rkt**             | Tiempo de ejecuci√≥n centrado en la seguridad (en desuso).                               |

##### üîê Contenedores internales y elementos de seguridad

| Componente              | Role                                                                             |
| ----------------------- | -------------------------------------------------------------------------------- |
| **Espacios de nombres** | Aislar procesos, usuarios, monturas, redes.                                      |
| **CGROUPS**             | Controlar y limitar el uso de recursos (CPU, memoria, IO).                       |
| **Capacidades**         | Control de privilegios de grano fino dentro de los contenedores.                 |
| **seccompe**            | Las restricciones permitieron que los syscalls reduzcan la superficie de ataque. |
| **Apparmor / Selinux**  | Control de control de acceso obligatorio a nivel de n√∫cleo.                      |

* * *

#### üß† Comprender los espacios de nombres de Linux

![linux-namespaces](images/linux-namespaces2.png)

Los espacios de nombres son una caracter√≠stica de n√∫cleo de Linux Core que habilita el aislamiento a nivel de proceso. Crean "vistas" separadas de los recursos del sistema global, como ID de proceso, redes, sistemas de archivos y usuarios, para que cada grupo de procesos crea que se est√° ejecutando en su propio sistema.

> En t√©rminos simples: los espacios de nombres enga√±an a un proceso para pensar que posee la m√°quina, a pesar de que solo la est√° compartiendo.

Esta es la base para el aislamiento del contenedor.

##### üîç ¬øQu√© espacios de nombres aislan?

Cada tipo de espacio de nombres a√≠sla un recurso espec√≠fico del sistema. Juntos, forman la caja de arena en la que opera un contenedor:

| Espacio de nombres | Aislamientos ...                          | Ejemplo del mundo real                                        |
| ------------------ | ----------------------------------------- | ------------------------------------------------------------- |
| **Pid**            | IDS de proceso                            | Procesos dentro de un contenedor Vea un espacio PID diferente |
| **Montar**         | Puntos de montaje del sistema de archivos | Cada contenedor ve su propio sistema de archivos ra√≠z         |
| **Red**            | Pila de red                               | Los contenedores tienen IP, interfaces y rutas aisladas       |
| **UTS**            | Nombre de host y nombre de dominio        | Cada contenedor establece su propio nombre de host            |
| **IPC**            | Memoria compartida y sem√°foros            | Previene la comunicaci√≥n entre procesos entre contenedores    |
| **Usuario**        | IDS de usuario y grupo                    | Habilita la ra√≠z falsa (uid 0) dentro del contenedor          |
| **CGROUP (V2)**    | Membres√≠a del grupo de control            | Atacas en controles de recursos como CPU y l√≠mites de memoria |

##### üß™ Analog√≠a visual

![linux-namespaces](images/linux-namespaces.png)

Imagina un edificio de oficinas compartido:

-   Todos los inquilinos comparten la misma base (Linux Kernel).
-   Cada compa√±√≠a tiene su propia oficina (espacio de nombres): diferentes cerraduras, muebles, l√≠neas telef√≥nicas y nombre de la empresa.
-   Para cada inquilino, se siente como su propio edificio.

As√≠ es exactamente como los contenedores experimentan el sistema: aislado, pero eficiente.

##### üîß C√≥mo los contenedores usan espacios de nombres

Cuando ejecuta un contenedor (por ejemplo, con Docker o Podman), el tiempo de ejecuci√≥n crea un nuevo conjunto de espacios de nombres:

```bash
docker run -it --rm alpine sh
```

Este comando da el proceso:

-   Un nuevo espacio de nombres PID ‚Üí Es el proceso 1 dentro del contenedor.
-   Un nuevo espacio de nombres de red ‚Üí su propio Ethernet virtual.
-   Un espacio de nombres de montaje ‚Üí un sistema de archivos ra√≠z espec√≠fico de contenedor.
-   Otros espacios de nombres dependiendo de la configuraci√≥n (usuario, IPC, etc.)

El resultado: un entorno de tiempo de ejecuci√≥n aislado ligero que se comporta como un sistema separado.

##### ‚öôÔ∏è Caracter√≠sticas complementarias del n√∫cleo

Los espacios de nombres ocultan recursos de contenedores. Pero para controlar cu√°nto pueden usar y qu√© pueden hacer, necesitamos mecanismos adicionales:

##### üî© CGROUPS (grupos de control)

Los CGROUP permiten que el n√∫cleo limite, priorice y monitoree el uso de recursos en los grupos de procesos.

| Recurso      | Ejemplos de casos de uso                        |
| ------------ | ----------------------------------------------- |
| UPC          | Limitar el tiempo de la CPU por contenedor      |
| Memoria      | Uso de la ram de la tapa                        |
| E/S de disco | Operaciones de lectura/escritura del acelerador |
| Red (V2)     | Restricciones de ancho de banda                 |

üõ°Ô∏è Evita el problema de "vecino ruidoso" al evitar que un contenedor consuma todos los recursos del sistema.

##### üß± Capacidades

Linux tradicional utiliza un modelo de privilegio binario: Root (UID 0) puede hacer todo, todos los dem√°s son limitados.

| Capacidad              | Permitir ...                                                  |
| ---------------------- | ------------------------------------------------------------- |
| `CAP_NET_BIND_SERVICE` | Vinculante a puertos privilegiados (por ejemplo, 80, 443)     |
| `CAP_SYS_ADMIN`        | Un poderoso captura para tareas de administraci√≥n del sistema |
| `CAP_KILL`             | Enviar se√±ales a procesos arbitrarios                         |

Al dejar caer capacidades innecesarias, los contenedores pueden funcionar solo con lo que necesitan, reduciendo el riesgo.

##### üîê Mecanismos de seguridad

Se utiliza junto con espacios de nombres y CGROUPS para bloquear lo que puede hacer un proceso contenedorizado:

| Caracter√≠stica | Descripci√≥n                                                                        |
| -------------- | ---------------------------------------------------------------------------------- |
| **seccompe**   | Llamadas del sistema Whitelist o Block Linux (SYSCalls)                            |
| **Aparmor**    | Aplicar perfiles de seguridad por aplicaci√≥n por aplicaci√≥n                        |
| **Selinux**    | Hacer cumplir el control de acceso obligatorio con pol√≠ticas estrictas del sistema |

##### üß† Resumen para principiantes

> ‚úÖ Los espacios de nombres aislan lo que un contenedor puede ver  
> ‚úÖ CGROUPS CONTRATO LO QUE PUEDE USAR  
> ‚úÖ Capacidades y m√≥dulos de seguridad definen lo que puede hacer

Juntas, estas caracter√≠sticas del n√∫cleo forman la columna vertebral t√©cnica del aislamiento del contenedor, lo que permite la implementaci√≥n de aplicaciones de alta densidad, segura y eficiente sin m√°quinas virtuales completas.

##### üß† Comprender los grupos C (grupos de control)

````sh
Verificar os Cgroups do sistema
# systemctl status
# systemd-cgls

Ferramentas de manipula√ß√£o dos Cgroups
# apt-get install cgroup-tools

# cgcreate -g memory,cpu:lsf
# cgclassify -g memory,cpu:lsf <PID>
---

#### 352.1 Important Commands

##### unshare

```sh
# create a new namespaces and run a command in it
unshare --mount --uts --ipc --user --pid --net  --map-root-user --mount-proc --fork chroot ~vagrant/debian bash
# mount /proc for test
#mount -t proc proc /proc
#ps -aux
#ip addr show
#umount /proc
````

##### LSNS

```sh
# show all namespaces
lsns

# show only pid namespace
lsns -s <pid>
lsns -p 3669

ls -l /proc/<pid>/ns
ls -l /proc/3669/ns

ps -o pid,pidns,netns,ipcns,utsns,userns,args -p <PID>
ps -o pid,pidns,netns,ipcns,utsns,userns,args -p 3669
```

##### nsenter

```sh
# execute a command in namespace
sudo nsenter -t <PID> -n  ip link show
sudo nsenter -t 3669 -n ip link show
```

##### 252.1 IP

```sh
# create a new network namespace
sudo ip netns add lxc1

# list network list
ip netns list

# exec command in network namespace
sudo ip netns exec lxc1 ip addr show
```

* * *

<p align="right">(<a href="#topic-352.1">back to sub topic 352.1</a>)</p>
<p align="right">(<a href="#topic-352">back to topic 352</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-352.2"></a>

### 352.2 LXC

**Peso:**6

**Descripci√≥n:**Los candidatos deben poder usar contenedores del sistema utilizando LXC y LXD. La versi√≥n de LXC cubierta es de 3.0 o m√°s.

**√Åreas clave de conocimiento:**

-   Comprender la arquitectura de LXC y LXD
-   Administre contenedores LXC en funci√≥n de las im√°genes existentes utilizando LXD, incluidas las redes y el almacenamiento
-   Configurar las propiedades del contenedor LXC
-   Limite el uso de recursos de contenedores LXC
-   Usar perfiles LXD
-   Comprender las im√°genes LXC
-   Conciencia de las herramientas LXC tradicionales

#### 352.2 Objetos citados

```sh
lxd
lxc (including relevant subcommands)
```

#### 352.2 Comandos importantes

##### foo

```sh
foo
```

<p align="right">(<a href="#topic-352.2">back to sub topic 352.2</a>)</p>
<p align="right">(<a href="#topic-352">back to topic 352</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-352.3"></a>

### 352.3 Docker

**Peso:**9

**Descripci√≥n:**El candidato debe poder administrar nodos Docker y contenedores Docker. Esto incluye comprender la arquitectura de Docker y comprender c√≥mo Docker interact√∫a con el sistema Linux del nodo.

**√Åreas clave de conocimiento:**

-   Comprender la arquitectura y los componentes de Docker
-   Administre contenedores Docker utilizando im√°genes de un registro de Docker
-   Comprender y administrar im√°genes y vol√∫menes para contenedores Docker
-   Comprender y administrar el registro de contenedores Docker
-   Comprender y administrar redes para Docker
-   Use DockerFiles para crear im√°genes de contenedores
-   Ejecutar un registro de Docker utilizando la imagen Docker de registro

#### 352.3 Objetos citados

```sh
dockerd
/etc/docker/daemon.json
/var/lib/docker/
docker
Dockerfile
```

#### 352.3 Comandos importantes

##### estibador

```sh
# Examples of docker
```

<p align="right">(<a href="#topic-352.3">back to sub topic 352.3</a>)</p>
<p align="right">(<a href="#topic-352">back to topic 352</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-352.4"></a>

### 352.4 plataformas de orquestaci√≥n de contenedores

**Peso:**3

**Descripci√≥n:**Los candidatos deben comprender la importancia de la orquestaci√≥n de contenedores y los conceptos clave que Docker Swarm y Kubernetes proporcionan para implementar la orquestaci√≥n de contenedores.

**√Åreas clave de conocimiento:**

-   Comprender la relevancia de la orquestaci√≥n del contenedor
-   Comprender los conceptos clave de Docker Compose y Docker Swarm
-   Comprender los conceptos clave de Kubernetes y Helm
-   Conciencia de Openshift, Rancher y Mesosphere DC/OS

<p align="right">(<a href="#topic-352.4">back to sub topic 352.4</a>)</p>
<p align="right">(<a href="#topic-352">back to topic 352</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-353"></a>

## Tema 353: Despliegue y aprovisionamiento de VM

* * *

<a name="topic-353.1"></a>

### 353.1 Herramientas de gesti√≥n de la nube

**Peso:**2

**Descripci√≥n:**Los candidatos deben comprender las ofertas comunes en las nubes p√∫blicas y tener un conocimiento b√°sico de caracter√≠sticas de las herramientas de gesti√≥n de la nube com√∫nmente disponibles.

**√Åreas clave de conocimiento:**

-   Comprender las ofertas comunes en las nubes p√∫blicas
-   Conocimiento de caracter√≠sticas b√°sicas de OpenStack
-   Conocimiento b√°sico de caracter√≠sticas de Terraform
-   Conciencia de CloudStack, Eucalipto y OpenNebula

#### 353.1 Objetos citados

```sh
IaaS, PaaS, SaaS
OpenStack
Terraform
```

#### 353.1 comandos importantes

##### foo

```sh
# examples
```

<p align="right">(<a href="#topic-353.1">back to sub topic 353.1</a>)</p>
<p align="right">(<a href="#topic-353">back to topic 353</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-353.2"></a>

### 353.2 Packer

**Peso:**2

**Descripci√≥n:**Los candidatos deben poder usar Packer para crear im√°genes del sistema. Esto incluye ejecutar Packer en varios entornos de nube p√∫blico y privado, as√≠ como la creaci√≥n de im√°genes de contenedores para LXC/LXD.

**√Åreas clave de conocimiento:**

-   Comprender la funcionalidad y las caracter√≠sticas de Packer
-   Crear y mantener archivos de plantilla
-   Cree im√°genes a partir de archivos de plantilla utilizando diferentes constructores

#### 353.2 Objetos citados

```sh
packer
```

#### 353.2 Comandos importantes

##### envasador

```sh
# examples
```

<p align="right">(<a href="#topic-353.2">back to sub topic 353.2</a>)</p>
<p align="right">(<a href="#topic 353">back to topic 353</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-353.3"></a>

### 353.3 INITO CLOCE

**Peso:**3

**Descripci√≥n:**Los candidatos deben usar la Inicla Cloud para configurar m√°quinas virtuales creadas a partir de im√°genes estandarizadas. Esto incluye ajustar m√°quinas virtuales para que coincidan con sus recursos de hardware disponibles, espec√≠ficamente, espacio en disco y vol√∫menes.  
Adem√°s, los candidatos deber√≠an poder configurar instancias para permitir los inicios de sesi√≥n SSH seguros e instalar un conjunto espec√≠fico de paquetes de software.  
Adem√°s, los candidatos deber√≠an poder crear nuevas im√°genes del sistema con soporte de In-Init.

**√Åreas clave de conocimiento:**

-   Comprensi√≥n de las caracter√≠sticas y conceptos de In-INIT, incluidos los datos del usuario, la inicializaci√≥n y la configuraci√≥n de la In-Init de la nube
-   Use la entrada en la nube para crear, cambiar el tama√±o y montar los sistemas de archivos, configurar cuentas de usuario, incluidas las credenciales de inicio de sesi√≥n, como las claves SSH e instalar paquetes de software desde el repositorio de la distribuci√≥n
-   Integre la entrada de la nube en las im√°genes del sistema
-   Utilice la fuente de datos de configuraci√≥n de la unidad para las pruebas

#### 353.3 Objetos citados

```sh
cloud-init
user-data
/var/lib/cloud/
```

#### 353.3 comandos importantes

##### foo

```sh
# examples
```

<p align="right">(<a href="#topic-353.3">back to sub topic 353.3</a>)</p>
<p align="right">(<a href="#topic 353">back to topic 353</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-353.4"></a>

### 353.4 vagabundo

**Peso:**3

**Descripci√≥n:**El candidato debe poder usar Vagrant para administrar m√°quinas virtuales, incluido el aprovisionamiento de la m√°quina virtual.

**√Åreas clave de conocimiento:**

-   Understand Vagrant architecture and concepts, including storage and networking
-   Recuperar y usar cajas de Atlas
-   Crear y ejecutar a Vagrantfiles
-   Acceder a m√°quinas virtuales vagabundas
-   Compartir y sincronizar la carpeta entre una m√°quina virtual vagabunda y el sistema de host
-   Comprender el aprovisionamiento vagabundo, es decir, los proveedores de archivos y shell
-   Comprender la configuraci√≥n de m√∫ltiples m√°quinas

#### 353.4 objetos citados

```sh
vagrant
Vagrantfile
```

#### 353.4 comandos importantes

##### vagabundo

```sh
# examples
```

<p align="right">(<a href="#topic-353.4">back to sub topic 353.4</a>)</p>
<p align="right">(<a href="#topic 353">back to topic 353</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

## Que contribuye

Las contribuciones son las que hacen que la comunidad de c√≥digo abierto sea un lugar tan incre√≠ble para
Aprende, inspira y crea. Cualquier contribuci√≥n que haga son**muy apreciado**.

Si tiene una sugerencia que lo mejore, bifurca el repositorio y
crear una solicitud de extracci√≥n. Tambi√©n puede simplemente abrir un problema con la etiqueta "Mejora".
¬°No olvides darle una estrella al proyecto! ¬°Gracias de nuevo!

1.  Bifurca el proyecto
2.  Crea tu rama de caracter√≠sticas (`git checkout -b feature/AmazingFeature`)
3.  Comprometa tus cambios (`git commit -m 'Add some AmazingFeature'`)
4.  Empujar a la rama (`git push origin feature/AmazingFeature`)
5.  Abra una solicitud de extracci√≥n

* * *

## Licencia

-   Este proyecto tiene licencia bajo la licencia MIT \* Consulte el archivo de licencia. MD para obtener m√°s detalles

* * *

## Contacto

Marcos Silvestrini -[marcos.silvestrini@gmail.com](mailto:marcos.silvestrini@gmail.com)\\[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/mrsilvestrini.svg?style=social&label=Follow%20%40mrsilvestrini)](https://twitter.com/mrsilvestrini)

Enlace del proyecto:<https://github.com/marcossilvestrini/learning-lpic-3-305-300>

<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

## Expresiones de gratitud

-   [Richard Stallman's](http://www.stallman.org/)
-   [√ëU](<>)
    -   [Preguntas frecuentes de GNU/Linux por Richard Stallman](https://www.gnu.org/gnu/gnu-linux-faq.html)
    -   [√ëU](https://www.gnu.org/)
    -   [Sistema operativo GNU](https://www.gnu.org/gnu/thegnuproject.html)
    -   [Compilador de GCC](https://gcc.gnu.org/wiki/History)
    -   [Alquitr√°n GNU](https://www.gnu.org/software/tar/)
    -   [GNU Make](https://www.gnu.org/software/make/)
    -   [Emacs de GNU](https://en.wikipedia.org/wiki/Emacs)
    -   [Paquetes de GNU](https://www.gnu.org/software/)
    -   [Colecci√≥n GNU/Linux](https://directory.fsf.org/wiki/Collection:GNU/Linux)
    -   [Gestor de arranque de GNU GRUB](https://www.gnu.org/software/grub/)
    -   [GNU Hurd](https://www.gnu.org/software/hurd/hurd/what_is_the_gnu_hurd.html)
-   [N√∫cleo](<>)
    -   [N√∫cleo](https://www.kernel.org/)
    -   [P√°ginas de Linux Kernel Man](https://www.kernel.org/doc/man-pages/)
    -   [Compila tu n√∫cleo](https://wiki.linuxquestions.org/wiki/How_to_build_and_install_your_own_Linux_kernel)
-   [Base est√°ndar de Linux](<>)
    -   [Base est√°ndar de Linux](https://en.wikipedia.org/wiki/Linux_Standard_Base)
    -   [Est√°ndar de jerarqu√≠a del sistema de archivos](https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard)
    -   [Estructura de jerarqu√≠a de archivos](https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.pdf)
-   [Software libre](<>)
    -   [FSF](https://www.fsf.org)
    -   [Directorio de software gratuito](https://directory.fsf.org/wiki/Free_Software_Directory:Free_software_replacements)
-   [Licencia](<>)
    -   [Software libre](https://www.gnu.org/philosophy/free-sw.html)
    -   [Copyleft](https://www.gnu.org/licenses/copyleft.en.html)
    -   [GPL](https://www.gnu.org/licenses/quick-guide-gplv3.html)
    -   [Licencia p√∫blica general de GNU Lesser Lesser](https://www.gnu.org/licenses/lgpl-3.0.html)
    -   [BSD](https://opensource.org/licenses/BSD-3-Clause)
    -   [Iniciativa de c√≥digo abierto](https://opensource.org/)
    -   [Comunics creativos](https://creativecommons.org/)
    -   [Licencia LTS](https://en.wikipedia.org/wiki/Long-term_support)
-   [Distracci√≥n](<>)
    -   [Directrices de software gratuito de Debian](https://www.debian.org/social_contract#guidelines)
    -   [Lista de distribuci√≥n de Linux](https://en.wikipedia.org/wiki/List_of_Linux_distributions)
    -   [Distribuir](https://distrowatch.com/)
    -   [Comparaci√≥n de distribuciones de Linux](https://en.wikipedia.org/wiki/Comparison_of_Linux_distributions)
-   [Entornos de escritorio](<>)
    -   [X11 orgg](https://www.x.org/wiki/)
    -   [Tierra](https://wayland.freedesktop.org/)
    -   [Gnu gnomo](https://www.gnu.org/press/gnome-1.0.html)
    -   [GNOMO](https://www.gnome.org/)
    -   [XFCE](https://xfce.org/)
    -   [Donde plasma](https://kde.org/plasma-desktop/)
    -   [Armon√≠a](https://en.wikipedia.org/wiki/Harmony_(toolkit))
-   [Protocolos](<>)
    -   [Http](<>)
        -   [W3Techs](https://w3techs.com/)
        -   [apache](https://www.apache.org/)
        -   [Directivas Apache][def]
        -   [C√≥digos de estado HTTP](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)
        -   [Cifradores fuertes para Apache, Nginx y LightTPD](https://cipherlist.eu/)
        -   [Tutoriales SSL](https://www.golinuxcloud.com/blog/)
        -   [SSL Config mozilla](https://ssl-config.mozilla.org/)
    -   [XRDP](https://bytexd.com/xrdp-centos/)
    -   [NTP](https://www.ntppool.org/en/)
-   [DNS](<>)
    -   [Unir](https://www.isc.org/bind/)
    -   [Bind Rogging](https://www.zytrax.com/books/dns/ch7/logging.html)
    -   [Lista de tipos de registro DNS](https://en.wikipedia.org/wiki/List_of_DNS_record_types)
    -   [Lista de tipos de registro DNS](https://en.wikipedia.org/wiki/List_of_DNS_record_types)
-   [Administrador de paquetes](<>)
    -   [Descargar paquetes](https://pkgs.org/)
    -   [Instalar paquetes](https://installati.one/)
    -   [Gu√≠a de instalaci√≥n de paquetes](https://installati.one/)
-   [Gui√≥n de shell](<>)
    -   [Bourne Again Shell](https://www.gnu.org/software/bash/manual/)
    -   [El asunto](https://bash.cyberciti.biz/guide/Shebang)
    -   [Variables de entorno](https://linuxize.com/post/how-to-set-and-list-environment-variables-in-linux/)
    -   [GNU Globbing](https://man7.org/linux/man-pages/man7/glob.7.html)
    -   [Globo](https://linuxhint.com/bash_globbing_tutorial/)
    -   [Citado](https://www.gnu.org/software/bash/manual/html_node/Quoting.html)
    -   [Expresiones regulares](https://www.gnu.org/software/grep/manual/html_node/Regular-Expressions.html)
    -   [Comando no se encuentra](https://command-not-found.com/)
    -   [Generador de aviso de bash](https://bash-prompt-generator.org/)
    -   [Explicar](https://explainshell.com/)
    -   [Tutorial vim](https://www.openvim.com/)
    -   [Tutorial de secuencias de comandos de Linux Shell](https://bash.cyberciti.biz/guide/Main_Page)
    -   [Ejemplos de comandos](https://www.geeksforgeeks.org/)
-   [Otras herramientas](<>)
    -   [Bugzila](https://bugzilla.kernel.org/)
    -   [Insignias de Github](https://github.com/alexandresanlim/Badges4-README.md-Profile)
-   [Definiciones de virtualizaci√≥n](<>)
    -   [Sombrero rojo](https://www.redhat.com/pt-br/topics/virtualization/what-is-virtualization/)
    -   [AWS](https://aws.amazon.com/pt/what-is/virtualization/)
    -   [IBM](https://www.ibm.com/topics/virtualization)
    -   [OpenSource.com](https://opensource.com/resources/virtualization)
-   [Alternar](<>)
    -   [Xenserver](https://www.xenserver.com/)
    -   [Wiki xenproject](https://wiki.xenproject.org/wiki/Main_Page)
    -   [Interfaces de red](https://wiki.xenproject.org/wiki/Xen_Networking#Virtual_Network_Interfaces)
    -   [Herramientas xen](https://xen-tools.org/software/)
    -   [Blog de LPI: XEN Virtualization and Cloud Computing #01: Introducci√≥n](https://www.lpi.org/pt-br/blog/2020/10/01/xen-virtualization-and-cloud-computing-01-introduction/)
    -   [Blog de LPI: Virtualizaci√≥n XEN y computaci√≥n en la nube #02: C√≥mo Xen hace el trabajo](https://www.lpi.org/blog/2020/10/08/xen-virtualization-and-cloud-computing-02-how-xen-does-job/)
    -   [Blog LPI: Virtualizaci√≥n XEN y computaci√≥n en la nube #04: Contenedores, OpenStack y otras plataformas relacionadas](https://www.lpi.org/pt-br/blog/2020/10/22/xen-virtualization-and-cloud-computing-04-containers-openstack-and-other-related/)
    -   [Virtualizaci√≥n XEN y computaci√≥n en la nube #05: El proyecto Xen, Unikernels y el futuro](https://www.lpi.org/pt-br/blog/2020/10/29/xen-virtualization-and-cloud-computing-05-xen-project-unikernels-and-future/)
    -   [Gu√≠a de principiantes del proyecto XEN](https://wiki.xenproject.org/wiki/Xen_Project_Beginners_Guide#Installing_the_Xen_Project_Software)
    -   [Libro loco](https://wiki.xenproject.org/wiki/Book/HelloXenProject/0-Contents)
-   [Unicernel](https://www.lpi.org/blog/2020/10/29/xen-virtualization-and-cloud-computing-05-xen-project-unikernels-and-future/)
    -   [Fuerza √∫nica](https://github.com/unikraft/unikraft)
    -   [MirageOS](https://mirage.io/docs/hello-world)
    -   [Malo](https://galois.com/project/halvm/)
    -   [√önico](https://github.com/solo-io/unik/blob/master/docs/providers/virtualbox.md)
-   [KVM](<>)
    -   [Oficial Doc](https://linux-kvm.org/page/Main_Page)
    -   [KVM (m√°quinas virtuales del n√∫cleo de Redhat)](https://www.redhat.com/pt-br/topics/virtualization/what-is-KVM)
    -   [Herramientas de gesti√≥n de KVM](https://www.linux-kvm.org/page/Management_Tools)
    -   [Red KVM](https://www.linux-kvm.org/page/Networking)
-   [QEMU](<>)
    -   [Oficial Doc](https://www.qemu.org/)
    -   [Descargar im√°genes OSBOXES](https://www.osboxes.org/)
    -   [Descargar im√°genes LinuxImages](https://www.linuxvmimages.com/)
    -   [Urbano](https://en.wikibooks.org/wiki/QEMU/Devices/Virtio)
    -   [Agente invitado](https://wiki.qemu.org/Features/GuestAgent)
-   [Libvirt](<>)
    -   [Oficial Doc](https://libvirt.org/)
    -   [Activaci√≥n del enchufe del sistema](https://libvirt.org/manpages/libvirtd.html#system-socket-activation)
    -   [Conexi√≥n](https://libvirt.org/uri.html)
    -   [Almacenamiento](https://libvirt.org/storage.html)
    -   [Red](https://wiki.libvirt.org/Networking.html)
    -   [Virtualnetwork](https://wiki.libvirt.org/VirtualNetworking.html)
    -   [virtogd](https://libvirt.org/manpages/virtlogd.html)
    -   [virtlockd](https://libvirt.org/manpages/virtlockd.html)
    -   [gerente de virtud](https://virt-manager.org/)
-   [Gesti√≥n de disco](<>)
    -   [Im√°genes de disco](https://qemu-project.gitlab.io/qemu/system/images.html)
    -   [copia de escritura](https://sempreupdate.com.br/linux/tutoriais/sistema-de-arquivos-copy-on-write-saiba-o-que-e-e-quais-as-vantagens-e-desvantagens/)
    -   [RAM x QCOW2](https://docs.redhat.com/en/documentation/red_hat_virtualization/4.3/html/technical_reference/qcow2)
    -   [Libguestfs](https://libguestfs.org/)
-   [Virtualizaci√≥n y contenedorizaci√≥n](<>)
    -   [Contenedores de documentos de AWS](https://aws.amazon.com/pt/containers/)
    -   [Contenedores de documentos de GCP](https://cloud.google.com/learn/what-are-containers?hl=pt-br)
    -   [Contenedor de Doc IBM](https://www.ibm.com/br-pt/topics/containers)
    -   [Contenedores de Docs de Red Hat](https://www.redhat.com/en/topics/containers/whats-a-linux-container)
    -   [Espacios de nombres](https://manpages.ubuntu.com/manpages/noble/man7/namespaces.7.html)
    -   [Espacios de nombres m√°s importantes](https://www.redhat.com/en/blog/7-linux-namespaces)
    -   [Clases de CGROUPS](https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/6/html/resource_management_guide/ch01)
    -   [Groups de hombre](https://manpages.ubuntu.com/manpages/noble/man7/cgroups.7.html)
-   [OpenStack Docs](<>)
    -   [Redhat](https://www.redhat.com/pt-br/topics/openstack)
-   [Abrir vswitch](<>)
    -   [OVS doc 4Linux](https://blog.4linux.com.br/open-vswitch-o-que-e-o-que-come-onde-vive)
-   [Examen LPIC-3 305-300](<>)
    -   [LPIC-3 305-300 OBJETIVOS](https://www.lpi.org/our-certifications/exam-305-objectives/)
    -   [LPIC-3 305-300 wiki](https://wiki.lpi.org/wiki/LPIC-305_Objectives_V3.0)
    -   [LPIC-3 305-300 Material de aprendizaje](https://cursos.linuxsemfronteiras.com.br/courses/preparatorio-para-certificacao-lpic-3-305/)
    -   [Examen simulado LPIC-3 305-300 por ITEXAMS](https://www.itexams.com/info/305-300)

<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<!-- MARKDOWN LINKS & IMAGES-->

<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->

[contributors-shield]: https://img.shields.io/github/contributors/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[contributors-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/graphs/contributors

[forks-shield]: https://img.shields.io/github/forks/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[forks-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/network/members

[stars-shield]: https://img.shields.io/github/stars/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[stars-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/stargazers

[issues-shield]: https://img.shields.io/github/issues/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[issues-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/issues

[license-shield]: https://img.shields.io/github/license/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[license-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/blob/master/LICENSE

[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555

[linkedin-url]: https://linkedin.com/in/marcossilvestrini

[def]: https://httpd.apache.org/docs/2.4/mod/directives.html
