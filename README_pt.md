<h1><a name="readme-top"></a></h1>

[![Create Release](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/release.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/release.yml)[![Translate README](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/translate.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/translate.yml)[![Generate HTML and PDF](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/generate-html.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/generate-html.yml)[![Deploy Webpage](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/deploy-webpage.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/deploy-webpage.yml)[![Generate GitBook Docs](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/generate-docs.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/generate-docs.yml)[![PSScriptAnalyzer](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/powershell.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/powershell.yml)[![Slack Notification](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/slack.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/slack.yml)

* * *

[Minha licenÃ§a][license-url][Garfos][forks-url][Observadores das estrelas][stars-url][Colaboradores][contributors-url][Problemas][issues-url]

## [LinkedIn][linkedin-url]

# ğŸ“š APRENDIZAGEM LPIC-3 305-300

[![English](https://img.shields.io/badge/lang-English-blue?logo=readme&logoColor=white)](./README.md)[![PortuguÃªs](https://img.shields.io/badge/lang-PortuguÃªs-green?logo=readme&logoColor=white)](README_pt.md)

![LPIC3-305-300](images/lpic3-305-300.jpg)

<p align="center">
<strong>Explore the docs Â»</strong></a>
    <br />
    <a href="https://marcossilvestrini.github.io/learning-lpic-3-305-300/">Web Site</a>
    -
    <a href="https://github.com/marcossilvestrini/learning-lpic-3-305-300">Code Page</a>
    -
    <a href="https://skynet-8.gitbook.io/learning-lpic-3-305-300">Gitbook</a>
    -
    <a href="https://github.com/marcossilvestrini/learning-lpic-3-305-300/issues">Report Bug</a>
    -
    <a href="https://github.com/marcossilvestrini/learning-lpic-3-305-300/issues">Request Feature</a>
</p>

* * *

## ğŸ—‚ï¸ Resumo

<details>
  <summary><b>TABLE OF CONTENT</b></summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
    </li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#prerequisites">Prerequisites</a></li>
        <li><a href="#installation">installation</a></li>
      </ul>
    </li>
    <li><a href="#usage">Usage</a></li>
    <li><a href="#roadmap">Roadmap</a></li>
    <li><a href="#freedoms">Four Essential Freedoms</a></li>
    <li>
      <a href="#topic-351">Topic 351: Full Virtualization</a>
      <ul>
        <li><a href="#topic-351.1">351.1 Virtualization Concepts and Theory </a></li>
        <li><a href="#topic-351.2">351.2 Xen</a></li>
        <li><a href="#topic-351.3">351.3 QEMU</a></li>
        <li><a href="#topic-351.4">351.4 Libvirt Virtual Machine</a></li>
        <li><a href="#topic-351.5">351.5 Virtual Machine Disk Image Management</a></li>
      </ul>
    </li>
    <li>
      <a href="#topic-352">Topic 352: container Virtualization</a>
      <ul>
        <li><a href="#topic-352.1">352.1 container Virtualization Concepts</a></li>
        <li><a href="#topic-352.2">352.2 LXC</a></li>
        <li><a href="#topic-352.3">352.3 Docker</a></li>
        <li><a href="#topic-352.4">352.4 container Orchestration Platforms</a></li>
      </ul>
    </li>
    <li>
      <a href="#topic-353">Topic 353: VM Deployment and Provisioning</a>
      <ul>
        <li><a href="#topic-353.1">353.1 Cloud Management Tools</a></li>
        <li><a href="#topic-353.2">353.2 Packer</a></li>
        <li><a href="#topic-353.3">353.3 cloud-init</a></li>
        <li><a href="#topic-353.4">353.4 Vagrant</a></li>
      </ul>
    </li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
    <li><a href="#acknowledgments">Acknowledgments</a></li>
  </ol>
</details><br>

* * *

<a name="about-the-project"></a>

## ğŸ“– Sobre o Projeto

> Este projeto visa ajudar estudantes ou profissionais a aprender os principais conceitos do GNULinux
> e software livre
> Algumas distribuiÃ§Ãµes GNULinux como Debian e RPM serÃ£o abordadas
> A instalaÃ§Ã£o e configuraÃ§Ã£o de alguns pacotes tambÃ©m serÃ£o abordadas
> Ao fazer isso, vocÃª pode dar a toda a comunidade a chance de se beneficiar de suas mudanÃ§as.
> O acesso ao cÃ³digo-fonte Ã© uma prÃ©-condiÃ§Ã£o para isso.
> Use o vagrant para atualizar mÃ¡quinas e executar laboratÃ³rios e praticar o conteÃºdo deste artigo.
> Publiquei na pasta Vagrant um Vagrantfile com o que Ã© necessÃ¡rio
> para vocÃª subir um ambiente para estudos

* * *

<p align="right">(<a href="#readme-top">back to top</a>)</p>

<a name="getting-started"></a>

## ğŸš€ Primeiros passos

Para iniciar o aprendizado, consulte a documentaÃ§Ã£o acima.

<a name="prerequisites"></a>

### ğŸ› ï¸ PrÃ©-requisitos

-   [Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
-   [EstaÃ§Ã£o de trabalho VMware](https://blogs.vmware.com/workstation/2024/05/vmware-workstation-pro-now-available-free-for-personal-use.html)
-   [UtilitÃ¡rio Vagrant VMWare](https://developer.hashicorp.com/vagrant/install/vmware)
-   [Vagabundo](https://developer.hashicorp.com/vagrant/install)

<a name="installation"></a>

### ğŸ’¾ InstalaÃ§Ã£o

Clonar o repositÃ³rio

```sh
git clone https://github.com/marcossilvestrini/learning-lpic-3-305-300.git
cd learning-lpic-3-305-300
```

Personalize um modelo_Vagrantfile-tÃ³pico-XXX_. Este arquivo contÃ©m uma configuraÃ§Ã£o de vms para laboratÃ³rios. Exemplo:

-   Arquivo[Vagrantfile-topic-351](vagrant/Vagrantfile-topic-351)
    -   vm.clone_directory = "&lt;sua_letra_do_driver>:\\`<folder>`\\&lt;para_mÃ¡quina>\\#{VM_NAME}-instance-1"
        Exemplo: vm.clone_directory = "E:\\Servidores\\VMware\\#{VM_NAME}-instance-1"
    -   vm.vmx["mem tamanho"]= ""
    -   vm.vmx[â€œnumvcpusâ€"]= ""
    -   vm.vmx["Cpuid.correspersocout"]= ""

Personalize a configuraÃ§Ã£o de rede em arquivos[configuraÃ§Ãµes/rede](configs/network/).

* * *

<a name="usage"></a>

## ğŸ“ Uso

Use este repositÃ³rio para aprender sobre o exame LPIC-3 305-300

### â¬†ï¸â¬‡ï¸ Para cima e para baixo

Mudar um_Vagrantfile-tÃ³pico-xxx_modelo e copie para um novo arquivo com nome_Vagrantfile_

```sh
cd vagrant && vagrant up
cd vagrant && vagrant destroy -f
```

### ğŸ”„ Para reiniciar VMs

```sh
cd vagrant && vagrant reload
```

**Importante:**_Se vocÃª reiniciar o vms sem o vagrant, a pasta compartilhada nÃ£o serÃ¡ montada apÃ³s a inicializaÃ§Ã£o._

### ğŸ’» Use o PowerShell para cima e para baixo

Se vocÃª usa a plataforma Windows, eu crio um script PowerShell para ativar e desativar vms.

```powershell
vagrant/up.ps1
vagrant/destroy.ps1
```

### ğŸ—ºï¸ TÃ³pico 351 do esquema de infraestrutura

![topic-351](images/infrastructure-topic-351.png)

<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="roadmap"></a>

## ğŸ›£ï¸ Roteiro

-   [x] Criar repositÃ³rio
-   [x] Crie scripts para laboratÃ³rios de provisionamento
-   [x] Crie exemplos sobre o TÃ³pico 351
-   [x] Crie exemplos sobre o TÃ³pico 352
-   [ ] Crie exemplos sobre o TÃ³pico 353
-   [ ] Carregar itexam simulado

* * *

<a name="freedoms"></a>

## ğŸ—½ Quatro liberdades essenciais

> 0.A liberdade de executar o programa como desejar, para qualquer finalidade (liberdade 0).
> 1\. A liberdade de estudar como o programa funciona e alterÃ¡-lo para que funcione
> sua computaÃ§Ã£o como desejar (liberdade 1).
> O acesso ao cÃ³digo-fonte Ã© uma prÃ©-condiÃ§Ã£o para isso.
> 2.A liberdade de redistribuir cÃ³pias para que vocÃª possa ajudar outras pessoas (liberdade 2).
> 3.liberdade para distribuir cÃ³pias de suas versÃµes modificadas para terceiros (liberdade 3).

* * *

## ğŸ” Inspecione comandos

```sh
type COMMAND
apropos COMMAND
whatis COMMAND --long
whereis COMMAND
COMMAND --help, --h
man COMMAND
```

<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351"></a>

## ğŸ–¥ï¸ TÃ³pico 351: VirtualizaÃ§Ã£o completa

![Virtualization](images/virtualization-351.png)

* * *

<a name="topic-351.1"></a>

### ğŸ§  351.1 Conceitos e teoria de virtualizaÃ§Ã£o

**Peso:**6

**DescriÃ§Ã£o:**Os candidatos devem conhecer e compreender os conceitos gerais, teoria e terminologia da virtualizaÃ§Ã£o. Isso inclui a terminologia Xen, QEMU e libvirt.

**Principais Ã¡reas de conhecimento:**

-   ğŸ–¥ï¸ Compreender a terminologia de virtualizaÃ§Ã£o
-   âš–ï¸ Entenda os prÃ³s e os contras da virtualizaÃ§Ã£o
-   ğŸ› ï¸ Entenda as diversas variaÃ§Ãµes de hipervisores e monitores de mÃ¡quinas virtuais
-   ğŸ”„ Entenda os principais aspectos da migraÃ§Ã£o de mÃ¡quinas fÃ­sicas para virtuais
-   ğŸš€ Compreenda os principais aspectos da migraÃ§Ã£o de mÃ¡quinas virtuais entre sistemas host
-   ğŸ“¸ Compreender os recursos e implicaÃ§Ãµes da virtualizaÃ§Ã£o para uma mÃ¡quina virtual, como snapshot, pausa, clonagem e limites de recursos
-   ğŸŒ ConscientizaÃ§Ã£o sobre oVirt, Proxmox, systemd-machined e VirtualBox
-   ğŸ”— ConscientizaÃ§Ã£o do Open vSwitch

#### ğŸ“‹ 351,1 Objetos Citados

```sh
Hypervisor
Hardware Virtual Machine (HVM)
Paravirtualization (PV)
Emulation and Simulation
CPU flags
/proc/cpuinfo
Migration (P2V, V2V)
```

#### ğŸ–¥ï¸ Hipervisores

##### ğŸ¢ Hipervisor Tipo 1 (Hipervisor Bare-Metal)

###### ğŸ“„ DefiniÃ§Ã£o Tipo 1

Ã‰ executado diretamente no hardware fÃ­sico do host, fornecendo uma camada base para gerenciar VMs sem a necessidade de um sistema operacional host.

###### ğŸ“ CaracterÃ­sticas Tipo 1

-   âš¡ Alto desempenho e eficiÃªncia.
-   â±ï¸ Menor latÃªncia e sobrecarga.
-   ğŸ¢ Frequentemente usado em ambientes corporativos e data centers.

###### ğŸ’¡ Exemplos de tipo 1

-   VMware ESXi: um hipervisor robusto e amplamente utilizado em ambientes empresariais.
-   Microsoft Hyper-V: Integrado ao Windows Server, oferecendo forte desempenho e recursos de gerenciamento.
-   Xen: Um hipervisor de cÃ³digo aberto usado por muitos provedores de serviÃ§os em nuvem.
-   KVM (MÃ¡quina Virtual Baseada em Kernel): Integrado ao kernel Linux, proporcionando alto desempenho para sistemas baseados em Linux.

##### ğŸ  Hipervisor Tipo 2 (hipervisor hospedado)

###### ğŸ“„ DefiniÃ§Ã£o Tipo 2

Ã‰ executado sobre um sistema operacional convencional, contando com o sistema operacional host para gerenciamento de recursos e suporte a dispositivos.

###### ğŸ“ CaracterÃ­sticas do tipo 2

-   ğŸ› ï¸ Mais fÃ¡cil de configurar e usar, especialmente em computadores pessoais.
-   ğŸ”§ Mais flexÃ­vel para desenvolvimento, testes e implantaÃ§Ãµes em menor escala.
-   ğŸ¢ Normalmente menos eficiente que os hipervisores Tipo 1 devido Ã  sobrecarga adicional do sistema operacional host.

###### ğŸ’¡ Exemplos de tipo 2

-   EstaÃ§Ã£o de trabalho VMware: um hipervisor poderoso para executar vÃ¡rios sistemas operacionais em um Ãºnico desktop.
-   Oracle VirtualBox: um hipervisor de cÃ³digo aberto conhecido por sua flexibilidade e facilidade de uso.
-   Parallels Desktop: projetado para usuÃ¡rios de Mac executarem Windows e outros sistemas operacionais junto com o macOS.
-   QEMU (Quick EMUlator): Um emulador e virtualizador de cÃ³digo aberto, frequentemente usado em conjunto com KVM.

##### âš–ï¸ Principais diferenÃ§as entre hipervisores tipo 1 e tipo 2

-   Ambiente de implantaÃ§Ã£o:
    -   Os hipervisores tipo 1 sÃ£o comumente implantados em data centers e ambientes corporativos devido Ã  sua interaÃ§Ã£o direta com hardware e alto desempenho.
    -   Os hipervisores tipo 2 sÃ£o mais adequados para uso pessoal, desenvolvimento, testes e tarefas de virtualizaÃ§Ã£o em pequena escala.
-   Desempenho:
    -   Os hipervisores tipo 1 geralmente oferecem melhor desempenho e menor latÃªncia porque nÃ£o dependem de um sistema operacional host.
    -   Os hipervisores tipo 2 podem sofrer alguma degradaÃ§Ã£o de desempenho devido Ã  sobrecarga de execuÃ§Ã£o em um sistema operacional host.
-   Gerenciamento e facilidade de uso:
    -   Os hipervisores tipo 1 exigem configuraÃ§Ã£o e gerenciamento mais complexos, mas fornecem recursos avanÃ§ados e escalabilidade para implantaÃ§Ãµes em larga escala.
    -   Os hipervisores tipo 2 sÃ£o mais fÃ¡ceis de instalar e usar, tornando-os ideais para usuÃ¡rios individuais e projetos menores.

##### ğŸ”„ Tipos de migraÃ§Ã£o

No contexto dos hipervisores, que sÃ£o tecnologias utilizadas para criar e gerenciar mÃ¡quinas virtuais, os termos migraÃ§Ã£o P2V e migraÃ§Ã£o V2V sÃ£o comuns em ambientes de virtualizaÃ§Ã£o.
Referem-se a processos de migraÃ§Ã£o de sistemas entre diferentes tipos de plataformas.

##### ğŸ–¥ï¸â¡ï¸ğŸ–¥ï¸ P2V - MigraÃ§Ã£o FÃ­sica para Virtual

A migraÃ§Ã£o P2V refere-se ao processo de migraÃ§Ã£o de um servidor fÃ­sico para uma mÃ¡quina virtual. Em outras palavras, um sistema operacional e seus aplicativos, executados em hardware fÃ­sico dedicado, sÃ£o "convertidos" e movidos para uma mÃ¡quina virtual executada em um hipervisor (como VMware, Hyper-V, KVM, etc.).

-   Exemplo: vocÃª tem um servidor fÃ­sico executando um sistema Windows ou Linux e deseja movÃª-lo para um ambiente virtual, como uma infraestrutura em nuvem ou um servidor de virtualizaÃ§Ã£o interno.
    O processo envolve copiar todo o estado do sistema, incluindo sistema operacional, drivers e dados, para criar uma mÃ¡quina virtual equivalente que possa ser executada como se estivesse no hardware fÃ­sico.

##### ğŸ–¥ï¸ğŸ”ğŸ–¥ï¸ V2V - MigraÃ§Ã£o Virtual para Virtual

A migraÃ§Ã£o V2V refere-se ao processo de migraÃ§Ã£o de uma mÃ¡quina virtual de um hipervisor para outro. Nesse caso, vocÃª jÃ¡ tem uma mÃ¡quina virtual rodando em um ambiente virtualizado (como VMware) e deseja movÃª-la para outro ambiente virtualizado (por exemplo, para Hyper-V ou para um novo servidor VMware).

-   Exemplo: vocÃª tem uma mÃ¡quina virtual rodando em um servidor de virtualizaÃ§Ã£o VMware, mas decide migrÃ¡-la para uma plataforma Hyper-V. Nesse caso, a migraÃ§Ã£o V2V converte a mÃ¡quina virtual de um formato ou hipervisor para outro, garantindo que ela continue funcionando corretamente.

#### ğŸ§© HVM e ParavirtualizaÃ§Ã£o

##### âš™ï¸ VirtualizaÃ§Ã£o assistida por hardware (HVM)

###### ğŸ“„ DefiniÃ§Ã£o HVM

O HVM aproveita extensÃµes de hardware fornecidas por CPUs modernas para virtualizar hardware, permitindo a criaÃ§Ã£o e o gerenciamento de VMs com sobrecarga mÃ­nima de desempenho.

###### ğŸ“ Principais caracterÃ­sticas do HVM

-   ğŸ–¥ï¸**Suporte de Hardware**: requer suporte de CPU para extensÃµes de virtualizaÃ§Ã£o como Intel VT-x ou AMD-V.
-   ğŸ› ï¸**VirtualizaÃ§Ã£o completa:**As VMs podem executar sistemas operacionais convidados nÃ£o modificados, pois o hipervisor fornece uma emulaÃ§Ã£o completa do ambiente de hardware.
-   âš¡**Desempenho:**Normalmente oferece desempenho quase nativo devido Ã  execuÃ§Ã£o direta do cÃ³digo convidado na CPU.
-   ğŸ”’**Isolamento:**Fornece forte isolamento entre VMs, pois cada VM opera como se tivesse seu prÃ³prio hardware dedicado.

###### ğŸ’¡ Exemplos de HVM

VMware ESXi, Microsoft Hyper-V, KVM (mÃ¡quina virtual baseada em kernel).

###### âœ… Vantagens do HVM

-   âœ…**Compatibilidade:**Pode executar qualquer sistema operacional sem modificaÃ§Ã£o.
-   âš¡**Desempenho:**Alto desempenho devido ao suporte de hardware.
-   ğŸ”’**SeguranÃ§a:**Recursos aprimorados de isolamento e seguranÃ§a fornecidos pelo hardware.

###### âŒ Desvantagens do HVM

-   ğŸ› ï¸**DependÃªncia de Hardware:**Requer recursos de hardware especÃ­ficos, limitando a compatibilidade com sistemas mais antigos.
-   ğŸ”§**Complexidade:**Pode envolver configuraÃ§Ã£o e gerenciamento mais complexos.

##### ğŸ§© ParavirtualizaÃ§Ã£o

###### ğŸ“„ DefiniÃ§Ã£o de ParavirtualizaÃ§Ã£o

A paravirtualizaÃ§Ã£o envolve a modificaÃ§Ã£o do sistema operacional convidado para estar ciente do ambiente virtual, permitindo que ele interaja de forma mais eficiente com o hipervisor.

###### ğŸ“ Principais caracterÃ­sticas da paravirtualizaÃ§Ã£o

-   ğŸ› ï¸**ModificaÃ§Ã£o de convidado:**Requer alteraÃ§Ãµes no sistema operacional convidado para se comunicar diretamente com o hipervisor usando hiperchamadas.
-   âš¡**Desempenho:**Pode ser mais eficiente do que a virtualizaÃ§Ã£o completa tradicional porque reduz a sobrecarga associada Ã  emulaÃ§Ã£o de hardware.
-   ğŸ”—**Compatibilidade:**Limitado a sistemas operacionais que foram modificados para paravirtualizaÃ§Ã£o.

###### ğŸ’¡ Exemplos de paravirtualizaÃ§Ã£o

Xen com convidados paravirtualizados, ferramentas VMware em determinadas configuraÃ§Ãµes e algumas configuraÃ§Ãµes KVM.

###### âœ… Vantagens da ParavirtualizaÃ§Ã£o

-   âš¡**EficiÃªncia:**Reduz a sobrecarga de virtualizaÃ§Ã£o de hardware, oferecendo potencialmente melhor desempenho para determinadas cargas de trabalho.
-   âœ…**UtilizaÃ§Ã£o de recursos:**Uso mais eficiente dos recursos do sistema devido Ã  comunicaÃ§Ã£o direta entre o sistema operacional convidado e o hipervisor.

###### âŒ Desvantagens da ParavirtualizaÃ§Ã£o

-   ğŸ› ï¸**ModificaÃ§Ã£o do sistema operacional convidado:**Requer modificaÃ§Ãµes no sistema operacional convidado, limitando a compatibilidade aos sistemas operacionais suportados.
-   ğŸ”§**Complexidade:**Requer complexidade adicional no sistema operacional convidado para implementaÃ§Ãµes de hiperchamada.

##### âš–ï¸ Principais diferenÃ§as

###### ğŸ–¥ï¸ Requisitos de sistema operacional convidado

-   **HVM:**Pode executar sistemas operacionais convidados nÃ£o modificados.
-   **ParavirtualizaÃ§Ã£o:**Requer que os sistemas operacionais convidados sejam modificados para funcionar com o hipervisor.

###### âš¡ Desempenho

-   **HVM:**Normalmente fornece desempenho quase nativo devido Ã  execuÃ§Ã£o assistida por hardware.
-   **ParavirtualizaÃ§Ã£o:**Pode oferecer desempenho eficiente reduzindo a sobrecarga da emulaÃ§Ã£o de hardware, mas depende do sistema operacional convidado modificado.

###### ğŸ§° DependÃªncia de Hardware

-   **HVM:**Requer recursos especÃ­ficos de CPU (Intel VT-x, AMD-V).
-   **ParavirtualizaÃ§Ã£o:**NÃ£o requer recursos especÃ­ficos de CPU, mas precisa de um sistema operacional convidado modificado.

###### ğŸ”’ Isolamento

-   **HVM:**Fornece forte isolamento usando recursos de hardware.
-   **ParavirtualizaÃ§Ã£o:**Baseia-se no isolamento baseado em software, que pode nÃ£o ser tÃ£o robusto quanto o isolamento baseado em hardware.

###### ğŸ§© Complexidade

-   **HVM:**Geralmente mais simples de implantar, pois oferece suporte a sistemas operacionais nÃ£o modificados.
-   **ParavirtualizaÃ§Ã£o:**Requer configuraÃ§Ã£o e modificaÃ§Ãµes adicionais no sistema operacional convidado, aumentando a complexidade.

#### ğŸ§  NUMA (acesso Ã  memÃ³ria nÃ£o uniforme)

NUMA (Non-Uniform Memory Access) Ã© uma arquitetura de memÃ³ria usada em sistemas multiprocessadores para otimizar o acesso Ã  memÃ³ria pelos processadores.
Num sistema NUMA, a memÃ³ria Ã© distribuÃ­da de forma desigual entre os processadores, o que significa que cada processador tem acesso mais rÃ¡pido a uma parte da memÃ³ria (sua "memÃ³ria local") do que Ã  memÃ³ria que estÃ¡ fisicamente mais distante (conhecida como "memÃ³ria remota") e associada a outros processadores.

##### ğŸ“ Principais recursos da arquitetura NUMA

1.  **MemÃ³ria local e remota**: Cada processador possui sua prÃ³pria memÃ³ria local, que pode acessar mais rapidamente. No entanto, tambÃ©m pode acessar a memÃ³ria de outros processadores, embora demore mais.
2.  **LatÃªncia Diferenciada**: A latÃªncia de acesso Ã  memÃ³ria varia dependendo se o processador estÃ¡ acessando sua memÃ³ria local ou a memÃ³ria de outro nÃ³. O acesso Ã  memÃ³ria local Ã© mais rÃ¡pido, enquanto o acesso Ã  memÃ³ria de outro nÃ³ (remoto) Ã© mais lento.
3.  **Escalabilidade**: A arquitetura NUMA foi projetada para melhorar a escalabilidade em sistemas com muitos processadores. Ã€ medida que mais processadores sÃ£o adicionados, a memÃ³ria tambÃ©m Ã© distribuÃ­da, evitando o gargalo que ocorreria em uma arquitetura de acesso uniforme Ã  memÃ³ria (UMA).

##### âœ… Advantages of NUMA

-   âš¡ Melhor Desempenho em Sistemas Grandes: Como cada processador possui memÃ³ria local, ele pode funcionar com mais eficiÃªncia sem competir tanto com outros processadores pelo acesso Ã  memÃ³ria.
-   ğŸ“ˆ Escalabilidade: NUMA permite que sistemas com muitos processadores e grandes quantidades de memÃ³ria sejam dimensionados de forma mais eficaz em comparaÃ§Ã£o com uma arquitetura UMA.

##### âŒ Desvantagens

-   ğŸ› ï¸ Complexidade de programaÃ§Ã£o: Os programadores precisam estar cientes de quais regiÃµes da memÃ³ria sÃ£o locais ou remotas, otimizando o uso da memÃ³ria local para obter melhor desempenho.
-   ğŸ¢ Potenciais penalidades de desempenho: Se um processador acessa frequentemente a memÃ³ria remota, o desempenho pode ser prejudicado devido Ã  maior latÃªncia.
    Essa arquitetura Ã© comum em sistemas multiprocessadores de alto desempenho, como servidores e supercomputadores, onde a escalabilidade e a otimizaÃ§Ã£o da memÃ³ria sÃ£o crÃ­ticas.

#### ğŸ†“ SoluÃ§Ãµes de cÃ³digo aberto

-   ğŸŒ oVirt:<https://www.ovirt.org/>
-   ğŸŒProxmox:<https://www.proxmox.com/en/proxmox-virtual-environment/overview>
-   ğŸŒOracle VirtualBox:<https://www.virtualbox.org/>
-   ğŸŒ Abra o vSwitch:<https://www.openvswitch.org/>

#### ğŸ—‚ï¸ Tipos de virtualizaÃ§Ã£o

##### ğŸ–¥ï¸ VirtualizaÃ§Ã£o de Hardware (VirtualizaÃ§Ã£o de Servidor)

###### ğŸ“„ DefiniÃ§Ã£o de alta tensÃ£o

Abstrai o hardware fÃ­sico para criar mÃ¡quinas virtuais (VMs) que executam sistemas operacionais e aplicativos separados.

###### ğŸ› ï¸ Casos de uso de alta tensÃ£o

Data centers, computaÃ§Ã£o em nuvem, consolidaÃ§Ã£o de servidores.

###### ğŸ’¡ Exemplos de alta tensÃ£o

VMware ESXi, Microsoft Hyper-V, KVM.

##### ğŸ“¦ VirtualizaÃ§Ã£o de Sistema Operacional (containerizaÃ§Ã£o)

###### ğŸ“„ DefiniÃ§Ã£o de conteinerizaÃ§Ã£o

Permite que vÃ¡rias instÃ¢ncias isoladas do espaÃ§o do usuÃ¡rio (contÃªineres) sejam executadas em um Ãºnico kernel do sistema operacional.

###### ğŸ› ï¸ Casos de uso de conteinerizaÃ§Ã£o

Arquitetura de microsserviÃ§os, ambientes de desenvolvimento e testes.

###### ğŸ’¡ Exemplos de conteinerizaÃ§Ã£o

Docker, Kubernetes, LXC.

##### ğŸŒ VirtualizaÃ§Ã£o de rede

###### ğŸ“„ DefiniÃ§Ã£o de virtualizaÃ§Ã£o de rede

Combina recursos de rede de hardware e software em uma Ãºnica entidade administrativa baseada em software.

###### ğŸ› ï¸ Casos de uso de virtualizaÃ§Ã£o de rede

Rede definida por software (SDN), virtualizaÃ§Ã£o de funÃ§Ãµes de rede (NFV).

###### ğŸ’¡ Exemplos de virtualizaÃ§Ã£o de rede

VMware NSX, Cisco ACI, OpenStack Neutron.

##### ğŸ’¾ VirtualizaÃ§Ã£o de armazenamento

###### ğŸ“„ DefiniÃ§Ã£o de virtualizaÃ§Ã£o de armazenamento

Agrupa o armazenamento fÃ­sico de vÃ¡rios dispositivos em uma Ãºnica unidade de armazenamento virtual que pode ser gerenciada centralmente.

###### ğŸ› ï¸ Casos de uso de virtualizaÃ§Ã£o de armazenamento

Gerenciamento de dados, otimizaÃ§Ã£o de armazenamento, recuperaÃ§Ã£o de desastres.

###### ğŸ’¡ Exemplos de virtualizaÃ§Ã£o de armazenamento

IBM SAN Volume Controller, VMware vSAN, NetApp ONTAP.

##### ğŸ–¥ï¸ VirtualizaÃ§Ã£o de desktop

###### ğŸ“„ DefiniÃ§Ã£o de virtualizaÃ§Ã£o de desktop

Permite que um sistema operacional de desktop seja executado em uma mÃ¡quina virtual hospedada em um servidor.

###### ğŸ› ï¸ Casos de uso de virtualizaÃ§Ã£o de desktop

Infraestrutura de desktop virtual (VDI), soluÃ§Ãµes de trabalho remoto.

###### ğŸ’¡ Exemplos de virtualizaÃ§Ã£o de desktop

Aplicativos e desktops virtuais Citrix, VMware Horizon, serviÃ§os de desktop remoto da Microsoft.

##### ğŸ“± VirtualizaÃ§Ã£o de aplicativos

###### ğŸ“„ DefiniÃ§Ã£o de virtualizaÃ§Ã£o de aplicativos

Separa aplicativos do hardware e do sistema operacional subjacentes, permitindo que sejam executados em ambientes isolados.

###### ğŸ› ï¸ Casos de uso de virtualizaÃ§Ã£o de aplicativos

ImplantaÃ§Ã£o simplificada de aplicativos, testes de compatibilidade.

###### ğŸ’¡ Exemplos de virtualizaÃ§Ã£o de aplicativos

VMware ThinApp, Microsoft App-V, Citrix XenApp.

##### ğŸ—ƒï¸ VirtualizaÃ§Ã£o de dados

###### ğŸ“„ DefiniÃ§Ã£o de virtualizaÃ§Ã£o de dados

Integra dados de diversas fontes sem consolidÃ¡-los fisicamente, fornecendo uma visÃ£o unificada para anÃ¡lise e relatÃ³rios.

###### ğŸ› ï¸ Casos de uso de virtualizaÃ§Ã£o de dados

InteligÃªncia de negÃ³cios, integraÃ§Ã£o de dados em tempo real.

###### ğŸ’¡ Exemplos de virtualizaÃ§Ã£o de dados

Denodo, Red Hat JBoss Data Virtualization, IBM InfoSphere.

##### ğŸŒŸ BenefÃ­cios da virtualizaÃ§Ã£o

-   âš¡ EficiÃªncia de Recursos: Melhor utilizaÃ§Ã£o dos recursos fÃ­sicos.
-   ğŸ’° Economia de custos: reduÃ§Ã£o de custos operacionais e de hardware.
-   ğŸ“ˆ Escalabilidade: FÃ¡cil de aumentar ou diminuir de acordo com a demanda.
-   ğŸ”§ Flexibilidade: Suporta uma variedade de cargas de trabalho e aplicativos.
-   ğŸ”„ RecuperaÃ§Ã£o de desastres: processos simplificados de backup e recuperaÃ§Ã£o.
-   ğŸ”’ Isolamento: Maior seguranÃ§a atravÃ©s do isolamento de ambientes.

#### EmulaÃ§Ã£o

A emulaÃ§Ã£o envolve simular o comportamento de hardware ou software em uma plataforma diferente da originalmente pretendida.

Este processo permite que software projetado para um sistema seja executado em outro sistema que pode ter arquitetura ou ambiente operacional diferente.

Embora a emulaÃ§Ã£o forneÃ§a versatilidade ao permitir a execuÃ§Ã£o de sistemas operacionais ou aplicativos convidados nÃ£o modificados, ela geralmente acarreta sobrecarga de desempenho.

Essa sobrecarga surge porque o sistema emulado precisa interpretar e traduzir instruÃ§Ãµes destinadas ao sistema original em instruÃ§Ãµes compatÃ­veis com o sistema host. Como resultado, a emulaÃ§Ã£o pode ser mais lenta que a execuÃ§Ã£o nativa, tornando-a menos eficiente para tarefas que consomem muitos recursos.

Apesar dessa desvantagem, a emulaÃ§Ã£o continua valiosa para executar software legado, testar aplicativos em diferentes plataformas e facilitar o desenvolvimento entre plataformas.

#### usinado em systemd

O serviÃ§o systemd-machined Ã© dedicado ao gerenciamento de mÃ¡quinas virtuais e contÃªineres dentro do ecossistema systemd.
 Fornece funcionalidades essenciais para controle, monitoramento e manutenÃ§Ã£o de instÃ¢ncias virtuais, oferecendo integraÃ§Ã£o robusta e eficiÃªncia em ambientes Linux.

<p align="right">(<a href="#topic-351.1">back to sub Topic 351.1</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351.2"></a>

### ğŸ§ 351,2 Xen

![xen-architecture](images/xen-architecture.png)

![xen-architecture](images/xen-architecture2.png)

**Peso:**3

**DescriÃ§Ã£o:**Os candidatos devem ser capazes de instalar, configurar, manter, migrar e solucionar problemas de instalaÃ§Ãµes do Xen. O foco estÃ¡ no Xen versÃ£o 4.x.

**Principais Ã¡reas de conhecimento:**

-   Entenda a arquitetura do Xen, incluindo rede e armazenamento
-   ConfiguraÃ§Ã£o bÃ¡sica de nÃ³s e domÃ­nios Xen
-   Gerenciamento bÃ¡sico de nÃ³s e domÃ­nios Xen
-   SoluÃ§Ã£o de problemas bÃ¡sicos de instalaÃ§Ãµes Xen
-   Avarines fora da pÃ­lula
-   Conhecimento do XenStore
-   Conhecimento dos parÃ¢metros de inicializaÃ§Ã£o do Xen
-   ConscientizaÃ§Ã£o do utilitÃ¡rio xm

#### ğŸ§ Xen

![panda](images/xen-panda.png)

Xen Ã© um hipervisor tipo 1 (bare metal) de cÃ³digo aberto, que permite que vÃ¡rios sistemas operacionais sejam executados simultaneamente no mesmo hardware fÃ­sico. O Xen fornece uma camada entre o hardware fÃ­sico e as mÃ¡quinas virtuais (VMs), permitindo compartilhamento e isolamento eficiente de recursos.

-   **Arquitetura:**O Xen opera com um sistema de duas camadas onde o DomÃ­nio 0 (Dom0) Ã© o domÃ­nio privilegiado com acesso direto ao hardware e gerencia o hipervisor. Outras mÃ¡quinas virtuais, chamadas Domain U (DomU), executam sistemas operacionais convidados e sÃ£o gerenciadas pelo Dom0.
-   **Tipos de virtualizaÃ§Ã£o:**O Xen suporta tanto a paravirtualizaÃ§Ã£o (PV), que requer sistema operacional convidado modificado, quanto a virtualizaÃ§Ã£o assistida por hardware (HVM), que usa extensÃµes de hardware (por exemplo, Intel VT-x ou AMD-V) para executar sistemas operacionais convidados nÃ£o modificados.
    O Xen Ã© amplamente utilizado em ambientes de nuvem, principalmente pela Amazon Web Services (AWS) e outros provedores de nuvem de grande escala.

#### ğŸ¢XenSource

XenSource foi a empresa fundada pelos desenvolvedores originais do hipervisor Xen na Universidade de Cambridge para comercializar o Xen. A empresa forneceu soluÃ§Ãµes empresariais baseadas no Xen e ofereceu ferramentas e suporte adicionais para aprimorar os recursos do Xen para uso empresarial.

-   **AquisiÃ§Ã£o pela Citrix**: Em 2007, a XenSource foi adquirida pela Citrix Systems, Inc. A Citrix usou a tecnologia Xen como base para seu produto Citrix XenServer, que se tornou uma popular plataforma de virtualizaÃ§Ã£o de nÃ­vel empresarial baseada em Xen.
-   **TransiÃ§Ã£o**: ApÃ³s a aquisiÃ§Ã£o, o projeto Xen continuou como um projeto de cÃ³digo aberto, enquanto a Citrix se concentrou em ofertas comerciais como o XenServer, aproveitando a tecnologia XenSource.

#### ğŸŒ Projeto Xen

Projeto Xen refere-se Ã  comunidade e iniciativa de cÃ³digo aberto responsÃ¡vel pelo desenvolvimento e manutenÃ§Ã£o do hipervisor Xen apÃ³s sua comercializaÃ§Ã£o. O Projeto Xen opera sob a FundaÃ§Ã£o Linux, com foco na construÃ§Ã£o, melhoria e suporte ao Xen como um esforÃ§o colaborativo e voltado para a comunidade.

-   **Metas:**O Projeto Xen visa avanÃ§ar o hipervisor melhorando seu desempenho, seguranÃ§a e conjunto de recursos para uma ampla gama de casos de uso, incluindo computaÃ§Ã£o em nuvem, virtualizaÃ§Ã£o focada em seguranÃ§a (por exemplo, Qubes OS) e sistemas embarcados.
-   **Colaboradores:**O projeto inclui colaboradores de diversas organizaÃ§Ãµes, incluindo grandes provedores de nuvem, fornecedores de hardware e desenvolvedores independentes.
-   **PÃ­lula e Hedools:**O Projeto Xen tambÃ©m inclui ferramentas como XAPI (XenAPI), que Ã© usado para gerenciar instalaÃ§Ãµes de hipervisores Xen, e vÃ¡rios outros utilitÃ¡rios para gerenciamento e otimizaÃ§Ã£o do sistema.

#### ğŸ—„ï¸XenStore

Xen Store Ã© um componente crÃ­tico do Xen Hypervisor.
Essencialmente, o Xen Store Ã© um banco de dados de valores-chave distribuÃ­do usado para comunicaÃ§Ã£o e compartilhamento de informaÃ§Ãµes entre o hipervisor Xen e as mÃ¡quinas virtuais (tambÃ©m conhecidas como domÃ­nios) que ele gerencia.

Aqui estÃ£o alguns aspectos principais da Xen Store:

-   **ComunicaÃ§Ã£o entre domÃ­nios:**O Xen Store permite a comunicaÃ§Ã£o entre domÃ­nios, como Dom0 (o domÃ­nio privilegiado que controla os recursos de hardware) e DomUs (domÃ­nios de usuÃ¡rios, que sÃ£o as VMs). Isso Ã© feito por meio de entradas de valores-chave, onde cada domÃ­nio pode ler ou gravar informaÃ§Ãµes.
-   **Gerenciamento de configuraÃ§Ã£o:**Ele Ã© usado para armazenar e acessar informaÃ§Ãµes de configuraÃ§Ã£o, como dispositivos virtuais, rede e parÃ¢metros de inicializaÃ§Ã£o. Isso facilita o gerenciamento dinÃ¢mico e a configuraÃ§Ã£o de VMs.
-   **Eventos e notificaÃ§Ãµes:**A Xen Store tambÃ©m oferece suporte a notificaÃ§Ãµes de eventos. Quando uma chave ou valor especÃ­fico na Xen Store Ã© modificado, os domÃ­nios interessados â€‹â€‹podem ser notificados para reagir a essas mudanÃ§as. Isso Ã© Ãºtil para monitorar e gerenciar recursos.
-   API simples: O Xen Store fornece uma API simples para leitura e gravaÃ§Ã£o de dados, facilitando aos desenvolvedores a integraÃ§Ã£o de seus aplicativos com o sistema de virtualizaÃ§Ã£o Xen.

#### ğŸ”—xapi

XAPI, ou XenAPI, Ã© a interface de programaÃ§Ã£o de aplicativos (API) usada para gerenciar o hipervisor Xen e suas mÃ¡quinas virtuais (VMs).
XAPI Ã© um componente chave do XenServer (agora conhecido como Citrix Hypervisor) e fornece uma maneira padronizada de interagir com o hipervisor Xen para executar operaÃ§Ãµes como criaÃ§Ã£o, configuraÃ§Ã£o, monitoramento e controle de VMs.

Aqui estÃ£o alguns aspectos importantes do XAPI:

-   **Gerenciamento de VM:**XAPI permite que os administradores criem, excluam, iniciem e parem mÃ¡quinas virtuais de maneira programÃ¡tica.
-   **AutomaÃ§Ã£o:**Com o XAPI, Ã© possÃ­vel automatizar o gerenciamento de recursos virtuais, incluindo rede, armazenamento e computaÃ§Ã£o, o que Ã© crucial para grandes ambientes de nuvem.
-   **IntegraÃ§Ã£o:**O XAPI pode ser integrado a outras ferramentas e scripts para fornecer uma administraÃ§Ã£o mais eficiente e personalizada do ambiente Xen.
-   **Controle de acesso:**A XAPI tambÃ©m fornece mecanismos de controle de acesso para garantir que apenas usuÃ¡rios autorizados possam realizar operaÃ§Ãµes especÃ­ficas no ambiente virtual.

XAPI Ã© a interface que permite o controle e automaÃ§Ã£o do Hipervisor Xen, facilitando o gerenciamento de ambientes virtualizados.

#### ğŸ“ Resumo Xen

-   **Xen:**A principal tecnologia de hipervisor que permite que mÃ¡quinas virtuais sejam executadas em hardware fÃ­sico.
-   **XenFonte:**Empresa que comercializou o Xen, posteriormente adquirida pela Citrix, levando ao desenvolvimento do Citrix XenServer.
-   **Projeto Xen:**A iniciativa e comunidade de cÃ³digo aberto que continua a desenvolver e manter o hipervisor Xen sob a Linux Foundation.
-   **XenStore:**A Xen Store atua como intermediÃ¡ria de comunicaÃ§Ã£o e configuraÃ§Ã£o entre o hipervisor Xen e as VMs, agilizando a operaÃ§Ã£o e o gerenciamento de ambientes virtualizados.
-   **PÃ­lula**Ã© a interface que permite o controle e automaÃ§Ã£o do Hipervisor Xen, facilitando o gerenciamento de ambientes virtualizados.

#### ğŸ–¥ï¸ DomÃ­nio0 (Dom0)

Domain0, ou Dom0, Ã© o domÃ­nio de controle em uma arquitetura Xen. Gerencia outros domÃ­nios (DomUs) e tem acesso direto ao hardware.
Dom0 executa drivers de dispositivos, permitindo que DomUs, que nÃ£o possuem acesso direto ao hardware, se comuniquem com os dispositivos. Normalmente, Ã© uma instÃ¢ncia completa de um sistema operacional, como o Linux, e Ã© essencial para a operaÃ§Ã£o do hipervisor Xen.

#### ğŸ’» domÃ­nio (casa)

DomUs sÃ£o domÃ­nios nÃ£o privilegiados que executam mÃ¡quinas virtuais.
Eles sÃ£o gerenciados pelo Dom0 e nÃ£o tÃªm acesso direto ao hardware. DomUs podem ser configurados para executar diferentes sistemas operacionais e sÃ£o usados â€‹â€‹para diversos fins, como servidores de aplicativos e ambientes de desenvolvimento. Eles contam com Dom0 para interaÃ§Ã£o de hardware.

#### ğŸ§© PV-domu (domÃ­nio paravirtualizadou)

PV-DomUs usam uma tÃ©cnica chamada paravirtualizaÃ§Ã£o. Neste modelo, o sistema operacional DomU Ã© modificado para saber que roda em um ambiente virtualizado, permitindo a comunicaÃ§Ã£o direta com o hipervisor para desempenho otimizado.
Isso resulta em menor sobrecarga e melhor eficiÃªncia em comparaÃ§Ã£o com a virtualizaÃ§Ã£o completa.

#### âš™ï¸ HVM-DomU (DomÃ­nio de MÃ¡quina Virtual de HardwareU)

HVM-DomUs sÃ£o mÃ¡quinas virtuais que utilizam virtualizaÃ§Ã£o completa, permitindo a execuÃ§Ã£o de sistemas operacionais nÃ£o modificados. O hipervisor Xen fornece emulaÃ§Ã£o de hardware para esses DomUs, permitindo-lhes executar qualquer sistema operacional que suporte a arquitetura de hardware subjacente.
Embora isso ofereÃ§a maior flexibilidade, pode resultar em maior sobrecarga em comparaÃ§Ã£o com PV-DomUs.

#### ğŸŒ Rede Xen

Dispositivos de rede paravirtualizados![pv-networking](images/xen-networking2.png)

Ponte![pv-networking](images/xen-networking1.png)

#### ğŸ“‹ 351,2 objetos citados

```sh
Domain0 (Dom0), DomainU (DomU)
PV-DomU, HVM-DomU
/etc/xen/
xl
xl.cfg 
xl.conf # Xen global configurations
xentop
oxenstored # Xenstore configurations
```

#### ğŸ“ 351,2 Notas

```sh

# Xen Settings
/etc/xen/
/etc/xen/xl.conf - Main general configuration file for Xen
/etc/xen/oxenstored.conf - Xenstore configurations

# VM Configurations
/etc/xen/xlexample.pvlinux
/etc/xen/xlexample.hvm

# Service Configurations
/etc/default/xen
/etc/default/xendomains

# xen-tools configurations
/etc/xen-tools/
/usr/share/xen-tools/

# docs
xl(1)
xl.conf(5)
xlcpupool.cfg(5)
xl-disk-configuration(5)
xl-network-configuration(5)
xen-tscmode(7)

# initialized domains auto
/etc/default/xendomains
   XENDOMAINS_AUTO=/etc/xen/auto

/etc/xen/auto/

# set domain for up after xen reboot
## create folder auto
cd /etc/xen && mkdir -p auto && cd auto

# create symbolic link
ln -s /etc/xen/lpic3-pv-guest /etc/xen/auto/lpic3-pv-guest
```

##### vif

No Xen, â€œvifâ€ significa Interface Virtual e Ã© usado para configurar redes para mÃ¡quinas virtuais (domÃ­nios).

Ao especificar diretivas â€œvifâ€ nos arquivos de configuraÃ§Ã£o de domÃ­nio, os administradores podem definir interfaces de rede, atribuir endereÃ§os IP, configurar VLANs e configurar outros parÃ¢metros de rede para mÃ¡quinas virtuais executadas em hosts Xen. Por exemplo: vif =[â€˜ponte=xenbr0â€™], neste caso, conecta a interface de rede da VM Ã  ponte Xen denominada â€œxenbr0â€.

#### LaboratÃ³rio Xen

Use este script para provisionamento de laboratÃ³rio:[xen.sh](scripts/xen/xen.sh)

#### ğŸ’» 351,2 comandos importantes

##### ğŸ—ï¸ xen-create-image

```sh
# create a pv image
xen-create-image \
  --hostname=lpic3-pv-guest \
  --memory=1gb \
  --vcpus=2 \
  --lvm=vg_xen \
  --bridge=xenbr0 \
  --dhcp \
  --pygrub \
  --password=vagrant \
  --dist=bookworm
```

##### ğŸ“„ imagens da lista xen

```sh
# list image
xen-list-image
```

##### âŒ xen-delete-image

```sh
# delete a pv image
xen-delete-image lpic3-pv-guest --lvm=vg_xen
```

##### ğŸ—„ï¸ xenstore-ls

```sh
# list xenstore infos
xenstore-ls
```

##### âš™ï¸xl

```sh
# view xen information
xl infos

# list Domains
xl list
xl list lpic3-hvm-guest
xl list lpic3-hvm-guest -l

# uptime Domains
xl uptime

# pause Domain
xl pause 2
xl pause lpic3-hvm-guest

# save state Domains
xl -v save lpic3-hvm-guest ~root/image-lpic3-hvm-guest.save

# restore Domain
xl restore /root/image-lpic3-hvm-guest.save

# get Domain name
xl domname 2

# view dmesg information
xl dmesg

# monitoring domain
xl top
xentop
xen top

# Limit mem Dom0
xl mem-set 0 2048

# Limit cpu (not permanent after boot)
xl vcpu-set 0 2

# create DomainU - virtual machine
xl create /etc/xen/lpic3-pv-guest.cfg

# create DomainU virtual machine and connect to guest
xl create -c /etc/xen/lpic3-pv-guest.cfg

##----------------------------------------------
# create DomainU virtual machine HVM

## create logical volume
lvcreate -l +20%FREE -n lpic3-hvm-guest-disk  vg_xen

## create a ssh tunel for vnc
ssh -l vagrant -L 5900:localhost:5900  192.168.0.130

## configure /etc/xen/lpic3-hvm-guest.cfg
## set boot for cdrom: boot = "d"

## create domain hvm
xl create /etc/xen/lpic3-hvm-guest.cfg

## open vcn connection in your vnc client with localhost
## for view install details

## after installation finished, destroy domain: xl destroy <id_or_name>

## set /etc/xen/lpic3-hvm-guest.cfg: boot for hard disc: boot = "c"

## create domain hvm
xl create /etc/xen/lpic3-hvm-guest.cfg

## access domain hvm
xl console <id_or_name>
##----------------------------------------------

# connect in domain guest
xl console <id>|<name> (press enter)
xl console 1
xl console lpic3-pv-guest

#How do I exit domU "xl console" session
#Press ctrl+] or if you're using Putty press ctrl+5.

# Poweroff domain
xl shutdown lpic3-pv-guest

# destroy domain
xl destroy lpic3-pv-guest

# reboot domain
xl reboot lpic3-pv-guest

# list block devices
xl block-list 1
xl block-list lpic3-pv-guest

# detach block devices
xl block-detach lpic3-hvm-guest hdc
xl block-detach 2 xvdc

# attach block devices

## hard disk devices
xl block-attach lpic3-hvm-guest-ubuntu 'phy:/dev/vg_xen/lpic3-hvm-guest-disk2,xvde,w'

## cdrom
xl block-attach lpic3-hvm-guest 'file:/home/vagrant/isos/ubuntu/seed.iso,xvdc:cdrom,r'
xl block-attach 2 'file:/home/vagrant/isos/ubuntu/seed.iso,xvdc:cdrom,r'

# insert and eject cdrom devices
xl cd-insert lpic3-hvm-guest-ubuntu xvdb  /home/vagrant/isos/ubuntu/ubuntu-24.04.1-live-server-amd64.iso
xl cd-eject lpic3-hvm-guest-ubuntu xvdb
```

<p align="right">(<a href="#topic-351.2">back to sub Topic 351.2</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351.3"></a>

### ğŸ–¥ï¸ 351,3 QEMU

![xen-kvm-qemu](/images/xen-kvm-qemu.png)

**Peso:**4

**DescriÃ§Ã£o:**Os candidatos devem ser capazes de instalar, configurar, manter, migrar e solucionar problemas de instalaÃ§Ãµes do QEMU.

**Principais Ã¡reas de conhecimento:**

-   Compreenda a arquitetura do QEMU, incluindo KVM, rede e armazenamento
-   Inicie instÃ¢ncias do QEMU na linha de comando
-   Gerencie instantÃ¢neos usando o monitor QEMU
-   Instale os drivers de dispositivo QEMU Guest Agent e VirtIO
-   Solucionar problemas de instalaÃ§Ãµes QEMU, incluindo rede e armazenamento
-   ConsciÃªncia de parÃ¢metros importantes de configuraÃ§Ã£o do QEMU

#### ğŸ“‹ 351,3 objetos citados

```sh
Kernel modules: kvm, kvm-intel and kvm-amd
/dev/kvm
QEMU monitor
qemu
qemu-system-x86_64
ip
brctl
tunctl
```

#### ğŸ› ï¸ 351,3 comandos importantes

##### ğŸ“ 351,3 Outros comandos

##### ğŸ§ª verifique o mÃ³dulo kvm

```sh
# check if kvm is enabled
egrep -o '(vmx|svm)' /proc/cpuinfo
lscpu |grep Virtualization
lsmod|grep kvm
ls -l /dev/kvm
hostnamectl
systemd-detect-virt
```

```sh
# check if kvm is enabled
egrep -o '(vmx|svm)' /proc/cpuinfo
lscpu |grep Virtualization
lsmod|grep kvm
ls -l /dev/kvm

# check kernel infos
uname -a

# check root device
findmnt /

# mount a qcow2 image
## Example 1:
mkdir -p /mnt/qemu
guestmount -a os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 -i /mnt/qemu/

## Example 2:
sudo guestfish --rw -a os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2
run
list-filesystems

# run commands in qcow2 images
## Example 1:
virt-customize -a  os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2  --run-command 'echo hello >/root/hello.txt'
## Example 2:
sudo virt-customize -a os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  --run-command 'echo -e "auto ens3\niface ens3 inet dhcp" > /etc/network/interfaces.d/ens3.cfg'

# generate mac 
printf 'DE:AD:BE:EF:%02X:%02X\n' $((RANDOM%256)) $((RANDOM%256))
```

##### ğŸŒ ip

```sh
# list links
ip link show

# create bridge
ip link add br0 type bridge
```

##### ğŸŒ‰brctl

```sh
# list links
ip link show

# create bridge
ip link add br0 type bridge
```

##### ğŸ’¾ qemu-img

```sh
# create image
qemu-img create -f qcow2 vm-disk-debian-12.qcow2 20G

# convert vmdk to qcow2 image
qemu-img convert \
  -f vmdk \
  -O qcow2 os-images/Debian_12.0.0_VMM/Debian_12.0.0_VMM_LinuxVMImages.COM.vmdk os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -p \
  -m16

# check image
qemu-img info os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2
```

##### ğŸ–¥ï¸ qemu-system-x86_64

```sh
# create vm with ISO
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm -hda vm-disk-debian-12.qcow2 \
  -cdrom /home/vagrant/isos/debian/debian-12.8.0-amd64-DVD-1.iso  \
  -boot d \
  -m 2048 \
  -smp cpus=2 \
  -k pt-br

# create vm with ISO using vnc in no gui servers \ ssh connections

## create ssh tunel in host
 ssh -l vagrant -L 5902:localhost:5902  192.168.0.131

## create vm 
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -k pt-br \
  -vnc :2 \
  -device qemu-xhci \
  -device usb-tablet \
  -device ide-cd,bus=ide.1,drive=cdrom,bootindex=1 \
  -drive id=cdrom,media=cdrom,if=none,file=/home/vagrant/isos/debian/debian-12.8.0-amd64-DVD-1.iso \
  -hda vm-disk-debian-12.qcow2 \
  -boot order=d \
  -vga std \
  -display none \
  -monitor stdio

# create vm with OS Image - qcow2

## create vm
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -k pt-br \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2

## create vm with custom kernel params
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -kernel /vmlinuz \
  -initrd /initrd.img \
  -append "root=/dev/mapper/debian--vg-root ro fastboot console=ttyS0" \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -k pt-br \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2

## create vm with and attach disk
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -hdb vmdisk-debian12.qcow2 \
  -drive file=vmdisk-extra-debian12.qcow2,index=2,media=disk,if=ide \
  -netdev bridge,id=net0,br=qemubr0 \
  -device virtio-net-pci,netdev=net0
  
## create vm network netdev user
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -netdev user,id=mynet0,net=192.168.0.150/24,dhcpstart=192.168.0.155,hostfwd=tcp::2222-:22 \
  -device virtio-net-pci,netdev=mynet0

## create vm network netdev tap (Private Network)
ip link add br0 type bridge ; ifconfig br0 up
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -netdev tap,id=br0 \
  -device e1000,netdev=br0,mac=DE:AD:BE:EF:1A:24

## create vm with public bridge
#create a public bridge : https://www.linux-kvm.org/page/Networking

qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -k pt-br \
  -vnc :2 \
  -device qemu-xhci \
  -device usb-tablet \
  -vga std \
  -display none \
  -netdev bridge,id=net0,br=qemubr0 \
  -device virtio-net-pci,netdev=net0

## get a ipv4 ip - open ssh in vm and:
dhcpclient ens4
```

#### ğŸ–¥ï¸ Monitor QEMU

Para iniciar o monitor QEMU no uso da linha de comando**-monitorar stdio**parÃ¢metro em**qemu-sistema-x86_64**

```sh
qemu-system-x86_64 -monitor stdio
```

Saia do monitor qemu:

```sh
ctrl+alt+2
```

```sh
# Management
info status # vm info
info cpus # cpu information
info network # network informations
stop # pause vm
cont # start vm in status pause
system_powerdown # poweroff vm
system_reset # restart monitor


# Blocks
info block # block info
boot_set d # force boot iso
change ide1-cd0  /home/vagrant/isos/debian/debian-12.8.0-amd64-DVD-1.iso  # attach cdrom
eject ide1-cd0 # detach cdrom

# Snapshots
info snapshots # list snapshots
savevm snapshot-01  # create snapshot
loadvm snapshot-01 # restore snapshot
delvm snapshot-01
```

#### ğŸ¤– Agente Convidado

Para ativar, use:

```sh
qemu-system-x86_x64
 -chardev socket,path=/tmp/qga.sock,server=on,wait=off,id=qga0 \
 -device virtio-serial \
 -device virtserialport,chardev=qga0,name=org.qemu.guest_agent.0
```

<p align="right">(<a href="#topic-351.3">back to sub Topic 351.3</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351.4"></a>

### ğŸ¢ 351.4 Gerenciamento de mÃ¡quina virtual Libvirt

![libvirt](images/libvirt.png)

![libvirt-network](images/libvirt-default-network.jpg)

**Peso:**9

**DescriÃ§Ã£o:**Os candidatos devem ser capazes de gerenciar hosts de virtualizaÃ§Ã£o e mÃ¡quinas virtuais (â€œdomÃ­nios libvirtâ€) usando libvirt e ferramentas relacionadas.

**Principais Ã¡reas de conhecimento:**

-   Entenda a arquitetura da libvirt
-   Gerenciar conexÃµes e nÃ³s libvirt
-   Crie e gerencie domÃ­nios QEMU e Xen, incluindo snapshots
-   Gerencie e analise o consumo de recursos de domÃ­nios
-   Crie e gerencie pools de armazenamento e volumes
-   Crie e gerencie redes virtuais
-   Migrar domÃ­nios entre nÃ³s
-   Entenda como a libvirt interage com o Xen e o QEMU
-   Entenda como a libvirt interage com serviÃ§os de rede como dnsmasq e radvd
-   Entenda os arquivos de configuraÃ§Ã£o XML da libvirt
-   ConscientizaÃ§Ã£o sobre virtlogd e virtlockd

#### ğŸ“‹ 351,4 objetos citados

```sh
libvirtd
/etc/libvirt/
/var/lib/libvirt
/var/log/libvirt
virsh (including relevant subcommands) 
```

#### ğŸ› ï¸ 351,4 comandos importantes

##### ğŸ–¥ï¸VIRSH

```sh
# using env variable for set virsh uri (local or remotely)
export LIBVIRT_DEFAULT_URI=qemu:///system
export LIBVIRT_DEFAULT_URI=xen+ssh://vagrant@192.168.0.130
export LIBVIRT_DEFAULT_URI='xen+ssh://vagrant@192.168.0.130?keyfile=/home/vagrant/.ssh/skynet-key-ecdsa'

# COMMONS

# get helps
virsh help
virsh help pool-create

# view version
virsh version

# view system info
sudo virsh sysinfo

# view node info
virsh nodeinfo

# hostname
virsh hostname

# check vcn allocated port
virsh vncdisplay <domain_id>
virsh vncdisplay <domain_name>
virsh vncdisplay rocky9-server01 

# HYPERVISORS

# view libvirt hypervisor connection
virsh uri

# list valid hypervisors
virt-host-validate
virt-host-validate qemu

# test connection uri(vm test)
virsh -c test:///default list

# connect remotely
virsh -c xen+ssh://vagrant@192.168.0.130
virsh -c xen+ssh://vagrant@192.168.0.130 list
virsh -c qemu+ssh://vagrant@192.168.0.130/system list

# connect remotely without enter password
virsh -c 'xen+ssh://vagrant@192.168.0.130?keyfile=/home/vagrant/.ssh/skynet-key-ecdsa'

# STORAGE

# list storage pools
virsh pool-list --details

# list all storage pool
virsh pool-list --all --details

# get a pool configuration
virsh pool-dumpxml default

# get pool info
virsh pool-info default

# create a storage pool
virsh pool-define-as --name default --type dir --target /var/lib/libvirt/images

# create a storage pool with dumpxml
virsh pool-create --overwrite --file configs/kvm/libvirt/pool.xml

# start storage pool
virsh pool-start default

# set storage pool for autostart
virsh pool-autostart default

# stop storage pool
virsh pool-destroy linux

# delete xml storage pool file
virsh pool-undefine linux

# edit storage pool
virsh pool-edit linux

# list volumes
virsh vol-list linux

# get volume infos
virsh vol-info Debian_12.0.0.qcow2 os-images
virsh vol-info --pool os-images Debian_12.0.0.qcow2 

# get volume xml
virsh vol-dumpxml rocky9-disk1 default

# create volume
virsh vol-create-as default --format qcow2 disk1 10G

# delete volume
virsh vol-delete  disk1 default

# DOMAINS \ INSTANCES \ VIRTUAL MACHINES

# list domain\instance\vm
virsh list
virsh list --all

# create domain\instance\vm
virsh create configs/kvm/libvirt/rocky9-server03.xml

# view domain\instance\vm info
virsh dominfo rocky9-server01

# view domain\instance\vm xml
virsh dumpxml rocky9-server01

# edit domain\instance\vm xml
virsh edit rocky9-server01

# stop domain\instance\vm
virsh shutdown rocky9-server01 # gracefully
virsh destroy 1
virsh destroy rocky9-server01

# suspend domain\instance\vm
virsh suspend rocky9-server01

# resume domain\instance\vm
virsh resume rocky9-server01

# start domain\instance\vm
virsh start rocky9-server01

# remove domain\instance\vm
virsh undefine rocky9-server01

# remove domain\instance\vm and storage volumes
virsh undefine rocky9-server01 --remove-all-storage

# save domain\instance\vm
virsh save rocky9-server01 rocky9-server01.qcow2

# restore domain\instance\vm
virsh restore rocky9-server01.qcow2

# list snapshots
virsh snapshot-list rocky9-server01

# create snapshot
virsh snapshot-create rocky9-server01

# restore snapshot
virsh snapshot-revert rocky9-server01 1748983520

# view snapshot xml
virsh snapshot-info rocky9-server01 1748983520

# dumpxml snapshot
virsh snapshot-dumpxml rocky9-server01 1748983520

# xml snapshot path
/var/lib/libvirt/qemu/snapshot/rocky9-server01/

# view snapshot info
virsh snapshot-info rocky9-server01 1748983671

# edit snapshot
virsh snapshot-edit rocky9-server01 1748983520

# delete snapshot
virsh snapshot-delete rocky9-server01 1748983520

# DEVICES

# list block devices
virsh domblklist rocky9-server01 --details

# add cdrom media 
virsh change-media rocky9-server01 sda /home/vagrant/isos/rocky/Rocky-9.5-x86_64-minimal.iso
virsh attach-disk rocky9-server01 /home/vagrant/isos/rocky/Rocky-9.5-x86_64-minimal.iso sda --type cdrom --mode readonly

# remove cdrom media
virsh change-media rocky9-server01 sda --eject

# add new disk
virsh attach-disk rocky9-server01  /var/lib/libvirt/images/rocky9-disk2  vdb --persistent

# remove disk
virsh detach-disk rocky9-server01 vdb --persistent

# RESOURCES (CPU and Memory)

# get cpu infos
virsh vcpuinfo rocky9-server01 --pretty
virsh dominfo rocky9-server01 | grep 'CPU'

# get vcpu count
virsh vcpucount rocky9-server01

# set vcpus maximum config
virsh setvcpus rocky9-server01 --count 4 --maximum --config
virsh shutdown rocky9-server01
virsh start rocky9-server01

# set vcpu current config
virsh setvcpus rocky9-server01 --count 4 --config

# set vcpu current live
virsh setvcpus rocky9-server01 --count 3 --current
virsh setvcpus rocky9-server01 --count 3 --live

# configure vcpu affinity config
virsh vcpupin rocky9-server01 0 7 --config
virsh vcpupin rocky9-server01 1 5-6 --config

# configure vcpu affinity current
virsh vcpupin rocky9-server01 0 7
virsh vcpupin rocky9-server01 1 5-6

# set maximum memory config
virsh setmaxmem rocky9-server01 3000000 --config
virsh shutdown rocky9-server01
virsh start rocky9-server01

# set current memory config
virsh setmem rocky9-server01 2500000 --current

# NETWORK

# get netwwork bridges
brctl show

# get iptables rules for libvirt
sudo iptables -L -n -t  nat

# list network
virsh net-list --all

# set default network
virsh net-define /etc/libvirt/qemu/networks/default.xml

# get network infos
virsh net-info default

# get xml network
virsh net-dumpxml default

# xml file
cat /etc/libvirt/qemu/networks/default.xml

# dhcp config
sudo cat /etc/libvirt/qemu/networks/default.xml | grep -A 10 dhcp
sudo cat /var/lib/libvirt/dnsmasq/default.conf

# get domain ipp address
virsh net-dhcp-leases default
virsh net-dhcp-leases default --mac 52\:54\:00\:89\:19\:86

# edit network
virsh net-edit default

# get domain network details
virsh domiflist debian-server01

# path for network filter files
/etc/libvirt/nwfilter/

# list network filters
virsh nwfilter-list

# create network filter - block icmp traffic
virsh nwfilter-define block-icmp.xml
# virsh edit Debian-Server
    #  <interface type='network'>
    #        ...
    #        <filterref filter='block-icmp'/>
    #        ...
    # </interface>
# virsh destroy debian-server01
# virsh start debian-server01

# delete network filter
virsh nwfilter-undefine block-icmp

# get xml network filter
virsh nwfilter-dumpxml block-icmp
```

###### ğŸ—ï¸ virt-install

```sh
# list os variants
virt-install --os-variant list
osinfo-query os

# create domain\instance\vm with iso file
virsh vol-create-as default --format qcow2 rocky9-disk1 20G
virt-install --name rocky9-server01 \
--vcpus 2 \
--cpu host \
--memory 2048 \
--disk vol=default/rocky9-disk1 \
--cdrom /home/vagrant/isos/rocky/Rocky-9.5-x86_64-minimal.iso \
--os-variant=rocky9 \
--graphics vnc,listen=0.0.0.0,port=5905

# create debian domain\instance\vm with qcow2 file
virt-install --name debian-server01 \
--vcpus 2 \
--ram 2048 \
--disk vol=os-images/Debian_12.0.0.qcow2 \
--import \
--osinfo detect=on \
--graphics vnc,listen=0.0.0.0,port=5906 \
--network network=default \
--noautoconsole

# create rocky9 domain\instance\vm with qcow2 file
virt-install --name rocky9-server02 \
--vcpus 2 \
--ram 2048 \
--disk path=os-images/RockyLinux_9.4_VMG/RockyLinux_9.4.qcow2,format=qcow2,bus=virtio \
--import \
--osinfo detect=on \
--graphics vnc,listen=0.0.0.0,port=5907 \
--network bridge=qemubr0,model=virtio \
--noautoconsole

# open domain\instance\vm gui console
virt-viewer debian-server01

# check metadata domain\instance\vm file (if uri is qemu:////system)
less /etc/libvirt/qemu/debian-server01.xml
```

<p align="right">(<a href="#topic-351.4">back to sub Topic 351.4</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351.5"></a>

### ğŸ’¾ Gerenciamento de imagem de disco de mÃ¡quina virtual 351,5

![disk-management](images/virtual-machine-disk.png)

**Peso:**3

**DescriÃ§Ã£o:**Os candidatos devem ser capazes de gerenciar imagens de disco de mÃ¡quinas virtuais. Isso inclui a conversÃ£o de imagens de disco entre vÃ¡rios formatos e hipervisores e o acesso a dados armazenados em uma imagem.

**Principais Ã¡reas de conhecimento:**

-   Compreenda os recursos de vÃ¡rios formatos de imagem de disco virtual, como imagens brutas, qcow2 e VMDK
-   Gerencie imagens de disco de mÃ¡quinas virtuais usando qemu-img
-   Monte partiÃ§Ãµes e acesse arquivos em contÃªineres em imagens de disco de mÃ¡quinas virtuais usando libguestfish
-   Copie o conteÃºdo do disco fÃ­sico para uma imagem de disco de mÃ¡quina virtual
-   Migrar conteÃºdo de disco entre vÃ¡rios formatos de imagem de disco de mÃ¡quina virtual
-   ConscientizaÃ§Ã£o do Formato de VirtualizaÃ§Ã£o Aberto (OVF)

#### ğŸ“‹ 351,5 objetos citados

```sh
qemu-img
guestfish (including relevant subcommands)
guestmount
guestumount
virt-cat
virt-copy-in
virt-copy-out
virt-diff
virt-inspector
virt-filesystems
virt-rescue
virt-df
virt-sparsify
virt-p2v
virt-p2v-make-disk
virt-v2v
```

#### ğŸ› ï¸ 351,5 comandos importantes

##### ğŸ’¾ 351.5.1 qemu-img

```sh
# Display detailed information about a disk image
qemu-img info UbuntuServer_24.04.qcow2

# Create a new 22G raw disk image (default format is raw)
qemu-img create new-disk 22G

# Create a new 22G disk image in qcow2 format
qemu-img create -f qcow2 new-disk2 22G

# Convert a VDI image to raw format using 5 threads and show progress
qemu-img convert -f vdi -O raw Ubuntu-Server.vdk new-Ubuntu.raw -m5 -p

# Convert vmdk to qcow2 image
qemu-img convert \
-f vmdk \
-O qcow2 os-images/UbuntuServer_24.04_VM/UbuntuServer_24.04_VM_LinuxVMImages.COM.vmdk \
os-images/UbuntuServer_24.04_VM/UbuntuServer_24.04.qcow2 \
-p \
-m16

# Resize a raw image to 30G
qemu-img resize -f raw new-disk 30G

# Resize a qcow2 image to 15G(actual size 30Gdisk 30G)
qemu-img resize -f raw --shrink new-disk 15G

# Snapshots

# List all snapshots in the image
qemu-img snapshot -l new-disk2.qcow2

# Create a snapshot named SNAP1
qemu-img snapshot -c SNAP1 disk

# Apply a snapshot by ID or name
qemu-img snapshot -a 123456789 disk

# Delete the snapshot named SNAP1
qemu-img snapshot -d SNAP1 disk
```

##### ğŸŸ peixe convidado

```sh
# set environment variables for guestfish
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg

# Launch guestfish with a disk image
guestfish -a UbuntuServer_24.04.qcow2
#run
#list-partitions

# Run the commands in a script file
guestfish -a UbuntuServer_24.04.qcow2 -m /dev/sda -i < script.ssh

# Interactively run commands
guestfish --rw -a UbuntuServer_24.04.qcow2 <<'EOF'
run
list-filesystems
EOF

# Copy a file from the guest image to the host
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
sudo guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
copy-out /etc/hostname /tmp/
EOF

# Copy a file from the host into the guest image
echo "new-hostname" > /tmp/hostname
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
sudo guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
copy-in /tmp/hostname /etc/
EOF

# View contents of a file in the guest image
guestfish --ro -a UbuntuServer_24.04.qcow2 -i <<'EOF'
cat /etc/hostname
EOF

# List files in the guest image
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
ls /home/ubuntu
EOF

# Edit a file in the guest image
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
edit /etc/hosts
EOF
```

###### ğŸ—‚ï¸ montagem de convidados

```sh
# Mount a disk image to a directory
guestmount -a UbuntuServer_24.04.qcow2 -m /dev/ubuntu-vg/ubuntu-lv /mnt/ubuntu
# domain
guestmount -d rocky9-server02 -m /dev/ubuntu-vg/ubuntu-lv /mnt/ubuntu 

# Mount a specific partition from a disk image
guestmount -a UbuntuServer_24.04.qcow2 -m /dev/sda2 /mnt/ubuntu
# domain
guestmount -d debian-server01 --ro -m  /dev/debian-vg/root /mnt/debian
```

###### ğŸ—‘ï¸ convidado

```sh
# Umount a disk image to a directory
sudo guestunmount /mnt/ubuntu
```

##### ğŸ“Švirt-df

```sh
# Show free and used space on virtual machine filesystems
virt-df UbuntuServer_24.04.qcow2 -h
virt-df -d rocky9-server02 -h
```

##### ğŸ—ƒï¸ sistemas de arquivos virt

```sh
# List filesystems, partitions, and logical volumes in a VM disk image (disk image)
virt-filesystems -a UbuntuServer_24.04.qcow2 --all --long -h

# List filesystems, partitions, and logical volumes in a VM disk image (domain)
virt-filesystems -d debian-server01 --all --long -h
```

##### ğŸ” inspetor virtual

```sh
# Inspect and report on the operating system in a VM disk image
virt-inspector -a UbuntuServer_24.04.qcow2 #(disk)
virt-inspector -d debian-server01 #(domain) 
```

##### ğŸ± gato virt

```sh
# Display the contents of a file inside a VM disk image
virt-cat -a UbuntuServer_24.04.qcow2 /etc/hosts
virt-cat -d debian-server01 /etc/hosts #(domain)
```

##### ğŸ”€virt-diff

```sh
# Show differences between two VM disk images
virt-diff -a UbuntuServer_24.04.qcow2 -A Rocky-Linux.qcow2
```

##### ğŸ§¹virt-sparsify

```sh
# Make a VM disk image smaller by removing unused space
virt-sparsify UbuntuServer_24.04.qcow2 UbuntuServer_24.04-sparse.qcow2
```

##### ğŸ“ redimensionamento virt

```sh
# Resize a VM disk image or its partitions
virt-filesystems -a UbuntuServer_24.04.qcow2 --all --long -h #(check size of partitions)
qemu-img create -f qcow2 UbuntuServer_24.04-expanded.qcow2 100G #(create new disk image with 100G)
virt-resize --expand /dev/ubuntu-vg/ubuntu-lv \
UbuntuServer_24.04.qcow2 UbuntuServer_24.04-expanded.qcow2

```

##### ğŸ“¥ cÃ³pia virtual

```sh
# Copy files from the host into a VM disk image

virt-copy-in -a UbuntuServer_24.04.qcow2 ~vagrant/test-virt-copy-in.txt /home/ubuntu
```

##### ğŸ“¤ cÃ³pia virtual

```sh
# Copy files from a VM disk image to the host
virt-copy-out -a UbuntuServer_24.04.qcow2 /home/ubuntu/.bashrc /tmp
```

##### ğŸ“‹virt-ls

```sh
# List files and directories inside a VM disk image
virt-ls -a UbuntuServer_24.04.qcow2 /home/ubuntu
```

##### ğŸš‘ resgate virtual

```sh
# Launch a rescue shell on a VM disk image for recovery
virt-rescue -a UbuntuServer_24.04.qcow2
```

##### ğŸ§°virt-sysprep

```sh
# Prepare a VM disk image for cloning by removing system-specific data
virt-sysprep -a UbuntuServer_24.04.qcow2
```

##### ğŸ”„ virt-v2v

```sh
# Convert a VM from a foreign hypervisor to run on KVM
virt-v2v -i disk input-disk.img -o local -os /var/tmp
```

##### ğŸ”„ virt-p2v

```sh
# Convert a physical machine to use KVM
```

##### ğŸ’½ virt-p2v-make-disk

```sh
# Create a bootable disk image for physical to virtual conversion
sudo virt-p2v-make-disk -o output.img
```

#### ğŸ“ 351,5 Notas

##### ğŸ“¦ OVF: formato de virtualizaÃ§Ã£o aberto

OVF: Um formato aberto que define um padrÃ£o para empacotar e distribuir mÃ¡quinas virtuais em diferentes ambientes.

O pacote gerado possui a extensÃ£o .ova e contÃ©m os seguintes arquivos:

-   .ovf: arquivo XML com metadados que definem o ambiente da mÃ¡quina virtual
-   Arquivos de imagem: .vmdk, .vhd, .vhdx, .qcow2, .raw
-   Arquivos adicionais: metadados, instantÃ¢neos, configuraÃ§Ã£o, hash

<p align="right">(<a href="#topic-351.5">back to sub Topic 351.5</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-352"></a>

## ğŸ“¦ TÃ³pico 352: VirtualizaÃ§Ã£o de contÃªineres

* * *

<a name="topic-352.1"></a>

### ğŸ§  Conceitos de virtualizaÃ§Ã£o de contÃªiner 352.1

![virtualization-container](images/virtualization-container.png)

```mermaid
timeline
    title Time Line containers Evolution
    1979 : chroot
    2000 : FreeBSD Jails
    2002 : Linux Namespaces
    2005 : Solaris containers
    2007 : cgroups
    2008 : LXC
    2013 : Docker
    2015 : Kubernetes
```

* * *

**Peso:**7

**DescriÃ§Ã£o:**Os candidatos devem compreender o conceito de virtualizaÃ§Ã£o de contÃªineres. Isso inclui compreender os componentes do Linux usados â€‹â€‹para implementar a virtualizaÃ§Ã£o de contÃªineres, bem como usar ferramentas padrÃ£o do Linux para solucionar problemas desses componentes.

**Principais Ã¡reas de conhecimento:**

-   Compreenda os conceitos de sistema e contÃªiner de aplicativo
-   Compreender e analisar namespaces de kernel
-   Compreender e analisar grupos de controle
-   Compreender e analisar capacidades
-   Entenda a funÃ§Ã£o do seccomp, SELinux e AppArmor para virtualizaÃ§Ã£o de contÃªineres
-   Entenda como LXC e Docker aproveitam namespaces, cgroups, capacidades, seccomp e MAC
-   Entenda o princÃ­pio do runc
-   Entenda o princÃ­pio do CRI-O e do containerd
-   Conhecimento do tempo de execuÃ§Ã£o do OCI e das especificaÃ§Ãµes de imagem
-   Conhecimento da interface de tempo de execuÃ§Ã£o do contÃªiner Kubernetes (CRI)
-   ConscientizaÃ§Ã£o sobre Podman, Buildah e Scopeo
-   Conhecimento de outras abordagens de virtualizaÃ§Ã£o de contÃªineres no Linux e outros sistemas operacionais livres, como rkt, OpenVZ, systemd-nspawn ou BSD Jails

* * *

#### ğŸ“‹ 352,1 Objetos Citados

```sh
nsenter
unshare
ip (including relevant subcommands)
capsh
/sys/fs/cgroups
/proc/[0-9]+/ns
/proc/[0-9]+/status
```

* * *

#### ğŸ§  Compreendendo os contÃªineres

![container](images/containers1.png)

containers sÃ£o uma tecnologia de virtualizaÃ§Ã£o leve que empacota aplicativos junto com suas dependÃªncias necessÃ¡rias (cÃ³digo, bibliotecas, variÃ¡veis â€‹â€‹de ambiente e arquivos de configuraÃ§Ã£o) em unidades isoladas, portÃ¡teis e reproduzÃ­veis.

> Em termos simples: um contÃªiner Ã© uma caixa independente que executa seu aplicativo da mesma maneira, em qualquer lugar.

##### ğŸ’¡ O que Ã© um contÃªiner?

Ao contrÃ¡rio das MÃ¡quinas Virtuais (VMs), os contÃªineres nÃ£o virtualizam hardware. Em vez disso, eles virtualizam o sistema operacional. Os contÃªineres compartilham o mesmo kernel Linux com o host, mas cada um opera em um espaÃ§o de usuÃ¡rio totalmente isolado.

ğŸ“Œ contÃªineres vs mÃ¡quinas virtuais:

| Recurso                 | recipientes                     | MÃ¡quinas Virtuais                           |
| ----------------------- | ------------------------------- | ------------------------------------------- |
| OS Kernel               | Compartilhado com o anfitriÃ£o   | Cada VM tem seu prÃ³prio sistema operacional |
| Hora de inicializaÃ§Ã£o   | RÃ¡pido (segundos ou menos)      | Lento (minutos)                             |
| Tamanho da imagem       | Leve (MBs)                      | Pesado (GB)                                 |
| EficiÃªncia de recursos  | Alto                            | Mais baixo                                  |
| Mecanismo de isolamento | Recursos do kernel (namespaces) | Hipervisor                                  |

##### ğŸ”‘ Principais caracterÃ­sticas dos contÃªineres

ğŸ”¹**Leve**: compartilha o kernel do sistema operacional host, reduzindo a sobrecarga e permitindo uma inicializaÃ§Ã£o rÃ¡pida.

ğŸ”¹**PortÃ¡til**: execute consistentemente em diferentes ambientes (desenvolvimento, teste, produÃ§Ã£o, nuvem, local).

ğŸ”¹**Isolado**: Use namespaces para isolamento de processos, redes e sistemas de arquivos.

ğŸ”¹**Eficiente**: permite maior densidade e melhor utilizaÃ§Ã£o de recursos do que as VMs tradicionais.

ğŸ”¹**EscalÃ¡vel**: ajuste perfeito para microsserviÃ§os e arquitetura nativa da nuvem.

##### ğŸ§± Tipos de contÃªineres

1.  ContÃªineres do sistema

    -   Projetado para executar todo o sistema operacional, assemelha-se a mÃ¡quinas virtuais.
    -   Suporta vÃ¡rios processos e serviÃ§os de sistema (init, syslog).
    -   Ideal para aplicaÃ§Ãµes legadas ou monolÃ­ticas.
    -   Exemplo: LXC, libvirt-lxc.
2.  ContÃªineres de aplicativos

    -   Projetado para executar um Ãºnico processo.
    -   Sem estado, efÃªmero e escalÃ¡vel horizontalmente.
    -   Amplamente utilizado em ambientes modernos de DevOps e Kubernetes.
    -   Exemplo: Docker, containerd, CRI-O.

##### ğŸš€ Tempos de execuÃ§Ã£o de contÃªineres populares

| Tempo de execuÃ§Ã£o | DescriÃ§Ã£o                                                                                 |
| ----------------- | ----------------------------------------------------------------------------------------- |
| **Docker**        | CLI/daemon mais amplamente adotado para construir e executar contÃªineres.                 |
| **contÃªiner**     | Tempo de execuÃ§Ã£o leve alimentando Docker e Kubernetes.                                   |
| **CRI-O**         | Tempo de execuÃ§Ã£o nativo do Kubernetes para contÃªineres OCI.                              |
| **LXC**           | ContÃªineres de sistema Linux tradicionais, mais prÃ³ximos do sistema operacional completo. |
| **CTR**           | Tempo de execuÃ§Ã£o focado na seguranÃ§a (obsoleto).                                         |

##### ğŸ” Interiores do contÃªiner e elementos de seguranÃ§a

| Componente            | Papel                                                                       |
| --------------------- | --------------------------------------------------------------------------- |
| **EspaÃ§os para nome** | Isole processos, usuÃ¡rios, montagens, redes.                                |
| **grupos**            | Controle e limite o uso de recursos (CPU, memÃ³ria, IO).                     |
| **Capacidades**       | Controle de privilÃ©gios refinado dentro de contÃªineres.                     |
| **seccomp**           | As restriÃ§Ãµes permitiram que os syscalls reduzissem a superfÃ­cie de ataque. |
| **AppArmor/SELinux**  | AplicaÃ§Ã£o obrigatÃ³ria de controle de acesso no nÃ­vel do kernel.             |

* * *

#### ğŸ§  Compreendendo o chroot - Alterar o diretÃ³rio raiz no Unix/Linux

![chroot](images/chroot.png)

##### O que Ã© chroot?

chroot (abreviaÃ§Ã£o de change root) Ã© uma chamada e comando do sistema em sistemas operacionais do tipo Unix que altera o diretÃ³rio raiz aparente (/) do processo em execuÃ§Ã£o atual e seus filhos. Isso cria um ambiente isolado, comumente conhecido como prisÃ£o chroot.

##### ğŸ§± Finalidade e casos de uso

-   ğŸ”’ Isolar aplicativos para seguranÃ§a (prisÃ£o).
-   ğŸ§ª Crie ambientes de teste sem impactar o restante do sistema.
-   ğŸ› ï¸ RecuperaÃ§Ã£o do sistema (por exemplo, inicialize no LiveCD e faÃ§a chroot no sistema instalado).
-   ğŸ“¦ Construindo pacotes de software em um ambiente controlado.

##### ğŸ“ Estrutura mÃ­nima exigida

O ambiente chroot deve ter seus prÃ³prios arquivos e estrutura essenciais:

```sh
/mnt/myenv/
â”œâ”€â”€ bin/
â”‚   â””â”€â”€ bash
â”œâ”€â”€ etc/
â”œâ”€â”€ lib/
â”œâ”€â”€ lib64/
â”œâ”€â”€ usr/
â”œâ”€â”€ dev/
â”œâ”€â”€ proc/
â””â”€â”€ tmp/
```

Use ldd para identificar as bibliotecas necessÃ¡rias:

```sh
ldd /bin/bash
```

##### ğŸš¨ LimitaÃ§Ãµes e consideraÃ§Ãµes de seguranÃ§a

-   chroot nÃ£o Ã© um limite de seguranÃ§a como contÃªineres ou VMs.
-   Um usuÃ¡rio privilegiado (root) dentro da prisÃ£o pode potencialmente escapar.
-   Nenhum isolamento de namespaces de processos, dispositivos ou recursos em nÃ­vel de kernel.

Para um isolamento mais forte, considere alternativas como:

-   ContÃªineres Linux (LXC, Docker)
-   MÃ¡quinas virtuais (KVM, QEMU)
-   Namespaces e cgroups do kernel

##### ğŸ§ª Teste o chroot com debootstrap

```sh
# download debian files
sudo debootstrap stable ~vagrant/debian http://deb.debian.org/debian
sudo chroot ~vagrant/debian bash
```

##### :ğŸ§ª LaboratÃ³rio chroot

Use este script para laboratÃ³rio:[chroot.sh](scripts/container/chroot.sh)

[![asciicast](https://asciinema.org/a/PWkjazgTXll9678Qy6LLOaKdN.svg)](https://asciinema.org/a/PWkjazgTXll9678Qy6LLOaKdN)

* * *

#### ğŸ§  Compreendendo os namespaces do Linux

![linux-namespaces](images/linux-namespaces2.png)

Namespaces sÃ£o um recurso central do kernel Linux que permite o isolamento em nÃ­vel de processo. Eles criam "visualizaÃ§Ãµes" separadas dos recursos globais do sistema â€” como IDs de processos, redes, sistemas de arquivos e usuÃ¡rios â€” para que cada grupo de processos acredite que estÃ¡ sendo executado em seu prÃ³prio sistema.

> Em termos simples: os namespaces enganam um processo fazendo-o pensar que Ã© o dono da mÃ¡quina, mesmo que esteja apenas compartilhando-a.

Esta Ã© a base para o isolamento de contÃªineres.

##### ğŸ” O que os namespaces isolam?

Cada tipo de namespace isola um recurso especÃ­fico do sistema. Juntos, eles constituem a sandbox em que um contÃªiner opera:

| EspaÃ§o para nome | Isola...                                  | Exemplo do mundo real                                             |
| ---------------- | ----------------------------------------- | ----------------------------------------------------------------- |
| **PID**          | IDs de processo                           | Os processos dentro de um contÃªiner veem um espaÃ§o PID diferente  |
| **Montar**       | Pontos de montagem do sistema de arquivos | Cada contÃªiner vÃª seu prÃ³prio sistema de arquivos raiz            |
| **Rede**         | Pilha de rede                             | contÃªineres tÃªm IPs, interfaces e rotas isoladas                  |
| **UTS**          | Nome de host e nome de domÃ­nio            | Cada contÃªiner define seu prÃ³prio nome de host                    |
| **CIP**          | MemÃ³ria compartilhada e semÃ¡foros         | Impede a comunicaÃ§Ã£o entre processos entre contÃªineres            |
| **UsuÃ¡rio**      | IDs de usuÃ¡rio e grupo                    | Ativa raiz falsa (UID 0) dentro do contÃªiner                      |
| **Grupo C (v2)** | Controlar a adesÃ£o ao grupo               | Vincula-se a controles de recursos, como limites de CPU e memÃ³ria |

##### ğŸ§ª Analogia Visual

![linux-namespaces](images/linux-namespaces.png)

Imagine um prÃ©dio de escritÃ³rios compartilhado:

-   Todos os locatÃ¡rios compartilham a mesma base (kernel do Linux).
-   Cada empresa possui seu prÃ³prio escritÃ³rio (namespace): diferentes fechaduras, mÃ³veis, linhas telefÃ´nicas e nome da empresa.
-   Para cada inquilino, parece que Ã© o seu prÃ³prio edifÃ­cio.

Ã‰ exatamente assim que os contÃªineres vivenciam o sistema: isolados, mas eficientes.

##### ğŸ”§ Como os contÃªineres usam namespaces

Quando vocÃª executa um contÃªiner (por exemplo, com Docker ou Podman), o tempo de execuÃ§Ã£o cria um novo conjunto de namespaces:

```bash
docker run -it --rm alpine sh
```

Este comando fornece o processo:

-   Um novo namespace PID â†’ Ã© o processo 1 dentro do contÃªiner.
-   Um novo namespace de rede â†’ sua prÃ³pria Ethernet virtual.
-   Um namespace de montagem â†’ um sistema de arquivos raiz especÃ­fico do contÃªiner.
-   Outros namespaces dependendo da configuraÃ§Ã£o (usuÃ¡rio, IPC, etc.)

O resultado: um ambiente de execuÃ§Ã£o leve e isolado que se comporta como um sistema separado.

##### âš™ï¸ Recursos complementares do kernel

Namespaces ocultam recursos de contÃªineres. Mas para controlar quanto podem usar e o que podem fazer, precisamos de mecanismos adicionais:

###### ğŸ”© Cgroups (grupos de controle)

Os Cgroups permitem que o kernel limite, priorize e monitore o uso de recursos entre grupos de processos.

| Recurso      | Exemplos de casos de uso               |
| ------------ | -------------------------------------- |
| CPU          | Limite o tempo de CPU por contÃªiner    |
| MemÃ³ria      | Limitar o uso de RAM                   |
| E/S de disco | Acelerar operaÃ§Ãµes de leitura/gravaÃ§Ã£o |
| Rede (v2)    | RestriÃ§Ãµes de largura de banda         |

ğŸ›¡ï¸ Evita o problema do â€œvizinho barulhentoâ€, impedindo que um contÃªiner consuma todos os recursos do sistema.

###### ğŸ§± Capacidades

O Linux tradicional usa um modelo de privilÃ©gio binÃ¡rio: root (UID 0) pode fazer tudo, todo mundo Ã© limitado.

| Capacidade             | Permite...                                                  |
| ---------------------- | ----------------------------------------------------------- |
| `CAP_NET_BIND_SERVICE` | VinculaÃ§Ã£o a portas privilegiadas (por exemplo, 80, 443)    |
| `CAP_SYS_ADMIN`        | Um poderoso recurso para tarefas administrativas do sistema |
| `CAP_KILL`             | Enviando sinais para processos arbitrÃ¡rios                  |

Ao eliminar recursos desnecessÃ¡rios, os contÃªineres podem funcionar apenas com o que precisam, reduzindo o risco.

##### ğŸ” Mecanismos de seguranÃ§a

Usado em conjunto com namespaces e cgroups para bloquear o que um processo conteinerizado pode fazer:

| Recurso      | DescriÃ§Ã£o                                                                       |
| ------------ | ------------------------------------------------------------------------------- |
| **seccomp**  | Colocar na lista de permissÃµes ou bloquear chamadas do sistema Linux (syscalls) |
| **AppArmor** | Aplicar perfis de seguranÃ§a por aplicativo                                      |
| **SELinux**  | Aplique o controle de acesso obrigatÃ³rio com polÃ­ticas de sistema rÃ­gidas       |

##### ğŸ§  Resumo para iniciantes

> âœ… Namespaces isolam o que um contÃªiner pode ver
> âœ… Cgroups controlam o que pode usar
> âœ… Capacidades e mÃ³dulos de seguranÃ§a definem o que pode fazer

Juntos, esses recursos do kernel formam a espinha dorsal tÃ©cnica do isolamento de contÃªineres, permitindo a implantaÃ§Ã£o de aplicativos de alta densidade, segura e eficiente sem VMs completas.

##### ğŸ§ª Namespaces de laboratÃ³rio

Use este script para laboratÃ³rio:[namespace.sh](scripts/container/namespace.sh)

[![asciicast](https://asciinema.org/a/8H6iczCMO24VgjWqwCcXEKWBG.svg)](https://asciinema.org/a/8H6iczCMO24VgjWqwCcXEKWBG)

* * *

#### ğŸ§© Compreendendo Cgroups (grupos de controle)

![cgroups](images/cgroups1.png)

##### ğŸ“Œ DefiniÃ§Ã£o

Grupos de controle (cgroups) sÃ£o um recurso do kernel Linux introduzido em 2007 que permite limitar, contabilizar e isolar o uso de recursos (CPU, memÃ³ria, E/S de disco, etc.) de grupos de processos.

cgroups sÃ£o muito usados â€‹â€‹por tempos de execuÃ§Ã£o de contÃªineres de baixo nÃ­vel, como runc e crun, e aproveitados por mecanismos de contÃªineres como Docker, Podman e LXC para impor limites de recursos e fornecer isolamento entre contÃªineres.

Namespaces isolados, controle de cgroups.

Namespaces criam ambientes separados para processos (como PID, rede ou montagens), enquanto cgroups limitam e monitoram o uso de recursos (CPU, memÃ³ria, E/S) para esses processos.

âš™ï¸ Principais recursos

| Recurso                   | DescriÃ§Ã£o                                                                   |
| ------------------------- | --------------------------------------------------------------------------- |
| **LimitaÃ§Ã£o de recursos** | Impor limites sobre quanto de um recurso um grupo pode usar                 |
| **PriorizaÃ§Ã£o**           | Alocar mais prioridade de CPU/IO para alguns grupos em detrimento de outros |
| **Contabilidade**         | Rastreie o uso de recursos por grupo                                        |
| **Controlar**             | Suspender, retomar ou encerrar processos em massa                           |
| **Isolamento**            | Evite a falta de recursos entre grupos                                      |

##### ğŸ“¦ Subsistemas (Controladores)

cgroups operam atravÃ©s de controladores, cada um responsÃ¡vel por gerenciar um tipo de recurso:

| subsistema | DescriÃ§Ã£o                               |
| ---------- | --------------------------------------- |
| `cpu`      | Controla o agendamento da CPU           |
| `cpuacct`  | Gera relatÃ³rios de uso de CPU           |
| `memory`   | Limites e uso de memÃ³ria das contas     |
| `blkio`    | Limita a E/S do dispositivo de bloco    |
| `devices`  | Controla o acesso aos dispositivos      |
| `freezer`  | Suspende/retoma a execuÃ§Ã£o de tarefas   |
| `net_cls`  | Marca pacotes para modelagem de trÃ¡fego |
| `ns`       | Gerencia o acesso ao namespace (raro)   |

##### ğŸ“‚ Layout do sistema de arquivos

cgroups sÃ£o expostos atravÃ©s do sistema de arquivos virtual em /sys/fs/cgroup.

Dependendo da versÃ£o:

-   **cgroups v1**: hierarquias separadas para cada controlador (por exemplo, memÃ³ria, CPU, etc.)
-   **cgroups v2**: hierarquia unificada sob um Ãºnico ponto de montagem

Montado sob:

```sh
/sys/fs/cgroup/
```

Hierarquia tÃ­pica de cgroups v1:

```sh
/sys/fs/cgroup/
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ mygroup/
â”‚   â”‚   â”œâ”€â”€ tasks
â”‚   â”‚   â”œâ”€â”€ memory.limit_in_bytes
â”œâ”€â”€ cpu/
â”‚   â””â”€â”€ mygroup/
â””â”€â”€ ...
```

No cgroups v2, todos os recursos sÃ£o gerenciados sob uma hierarquia unificada:

```sh
/sys/fs/cgroup/
â”œâ”€â”€ cgroup.procs
â”œâ”€â”€ cgroup.controllers
â”œâ”€â”€ memory.max
â”œâ”€â”€ cpu.max
â””â”€â”€ ...
```

##### ğŸ§ª Uso comum (exemplos v1 e v2)

v1 â€“ Criar e atribuir limite de memÃ³ria:

```sh
# Mount memory controller (if needed)
mount -t cgroup -o memory none /sys/fs/cgroup/memory

# Create group
mkdir /sys/fs/cgroup/memory/mygroup

# Set memory limit (100 MB)
echo 104857600 | tee /sys/fs/cgroup/memory/mygroup/memory.limit_in_bytes

# Assign a process (e.g., current shell)
echo $$ | tee /sys/fs/cgroup/memory/mygroup/tasks
```

v2 â€“ Hierarquia unificada:

```sh
# Create subgroup
mkdir /sys/fs/cgroup/mygroup

# Enable controllers
echo +memory +cpu > /sys/fs/cgroup/cgroup.subtree_control

# Move shell into group
echo $$ > /sys/fs/cgroup/mygroup/cgroup.procs

# Set limits
echo 104857600 > /sys/fs/cgroup/mygroup/memory.max
echo "50000 100000" > /sys/fs/cgroup/mygroup/cpu.max  # 50ms quota per 100ms period
```

ğŸ§­ InspeÃ§Ã£o de Processo e Grupo

| Comando                 | DescriÃ§Ã£o                                  |
| ----------------------- | ------------------------------------------ |
| `cat /proc/self/cgroup` | Mostra a associaÃ§Ã£o atual do cgroup        |
| `cat /proc/PID/cgroup`  | cgroup de outro processo                   |
| `cat /proc/PID/status`  | InformaÃ§Ãµes de memÃ³ria e cgroup            |
| `ps -o pid,cmd,cgroup`  | Mostrar mapeamento de processo para cgroup |

##### ğŸ“¦ Uso em contÃªineres

mecanismos de contÃªiner como Docker, Podman e containerd delegam controle de recursos para cgroups (via runc ou crun), permitindo:

-   Limites de CPU e memÃ³ria por contÃªiner
-   Controle refinado sobre blkio e dispositivos
-   Contabilidade de recursos em tempo real

Exemplo do Docker:

```sh
docker run --memory=256m --cpus=1 busybox
```

Nos bastidores, isso cria regras de cgroup para memÃ³ria e limites de CPU para o processo do contÃªiner.

##### ğŸ§  Resumo de conceitos

| Conceito          | ExplicaÃ§Ã£o                                                          |
| ----------------- | ------------------------------------------------------------------- |
| **Controladores** | MÃ³dulos como`cpu`,`memory`,`blkio`, etc. aplicar limites e regras   |
| **Tarefas**       | PIDs (processos) atribuÃ­dos ao grupo de controle                    |
| **Hierarquia**    | Cgroups sÃ£o estruturados em uma Ã¡rvore pai-filho                    |
| **DelegaÃ§Ã£o**     | Systemd e serviÃ§os de usuÃ¡rio podem gerenciar subÃ¡rvores de cgroups |

##### ğŸ§ª Grupos de laboratÃ³rio

Use este script para laboratÃ³rio:[cgroups.sh](scripts/container/cgroups.sh)

[![asciicast](https://asciinema.org/a/WbudWJpHKPzBWMh8CGRxCIpZf.svg)](https://asciinema.org/a/WbudWJpHKPzBWMh8CGRxCIpZf)

* * *

#### ğŸ›¡ï¸ Compreendendo as capacidades

â“ Quais sÃ£o os recursos do Linux?

Tradicionalmente no Linux, o usuÃ¡rio root tem acesso irrestrito ao sistema. Os recursos do Linux foram introduzidos para dividir esses privilÃ©gios todo-poderosos em permissÃµes menores e discretas, permitindo que os processos executem operaÃ§Ãµes privilegiadas especÃ­ficas sem exigir acesso root completo.

Isso aumenta a seguranÃ§a do sistema ao impor o princÃ­pio do menor privilÃ©gio.

| ğŸ” Capacidade          | ğŸ“‹ DescriÃ§Ã£o                                                       |
| ---------------------- | ------------------------------------------------------------------ |
| `CAP_CHOWN`            | Alterar o proprietÃ¡rio do arquivo independentemente das permissÃµes |
| `CAP_NET_BIND_SERVICE` | Vincular a portas abaixo de 1024 (por exemplo, 80, 443)            |
| `CAP_SYS_TIME`         | Definir relÃ³gio do sistema                                         |
| `CAP_SYS_ADMIN`        | âš ï¸ Muito poderoso â€“ inclui montagem, BPF e muito mais              |
| `CAP_NET_RAW`          | Use soquetes brutos (por exemplo, ping, traceroute)                |
| `CAP_SYS_PTRACE`       | Rastrear outros processos (depuraÃ§Ã£o)                              |
| `CAP_KILL`             | Envie sinais para qualquer processo                                |
| `CAP_DAC_OVERRIDE`     | Modifique arquivos e diretÃ³rios sem permissÃ£o                      |
| `CAP_SETUID`           | Alterar ID do usuÃ¡rio (UID) do processo                            |
| `CAP_NET_ADMIN`        | Gerenciar interfaces de rede, roteamento, etc.                     |

ğŸ” Alguns tipos de recursos do Linux

| Tipo de capacidade     | DescriÃ§Ã£o                                                                         |
| ---------------------- | --------------------------------------------------------------------------------- |
| **CapInh (Inherited)** | Capacidades herdadas do processo pai.                                             |
| **CapPrm (Permitido)** | Capacidades que o processo pode ter.                                              |
| **CapEff (efetivo)**   | Capacidades que o processo estÃ¡ usando atualmente.                                |
| **CapBnd (limite)**    | Restringe o conjunto mÃ¡ximo de capacidades efetivas que um processo pode obter.   |
| **CapAmb (ambiente)**  | Permite que um processo defina explicitamente suas prÃ³prias capacidades efetivas. |

ğŸ“¦ Capacidades em contÃªineres e pods
os contÃªineres normalmente nÃ£o sÃ£o executados como root completo, mas recebem um conjunto limitado de recursos por padrÃ£o, dependendo do tempo de execuÃ§Ã£o.

Os recursos podem ser adicionados ou eliminados no Kubernetes usando o securityContext.

ğŸ“„ Exemplo de Kubernetes:

```yaml
securityContext:
  capabilities:
    drop: ["ALL"]
    add: ["NET_BIND_SERVICE"]
```

ğŸ” Isso garante que o contÃªiner comece com zero privilÃ©gios e receba apenas o que Ã© necessÃ¡rio.

##### ğŸ§ª Capacidades de laboratÃ³rio

Use este script para laboratÃ³rio:[capabilities.sh](scripts/container/capabilities.sh)

[![asciicast](https://asciinema.org/a/kCiUGvY0YGA5Mdzbj1NSdfLAx.svg)](https://asciinema.org/a/kCiUGvY0YGA5Mdzbj1NSdfLAx)

#### ğŸ›¡ï¸ Seccomp (modo de computaÃ§Ã£o segura)

**O que Ã©?**

-   Um recurso do kernel Linux para restringir quais syscalls (chamadas de sistema) um processo pode usar.
-   Comumente usado em contÃªineres (como Docker), navegadores, sandboxes, etc.

**Como funciona?**

-   Um processo habilita um perfil/filtro seccomp.
-   O kernel bloqueia, registra ou mata o processo se tentar syscalls proibidos.
-   Os filtros sÃ£o escritos no formato BPF (Berkeley Packet Filter).

**Comandos rÃ¡pidos**

```sh
# Check support
docker info | grep Seccomp

# Disable for a container:
docker run --security-opt seccomp=unconfined ...

# Inspect running process:
grep Seccomp /proc/$$/status
```

**Ferramentas**

```sh
# for analyzing
seccomp-tools 

# Profiles
/etc/docker/seccomp.json
```

#### ğŸ¦ºAppArmor

**O que Ã©?**

-   Um sistema de controle de acesso obrigatÃ³rio (MAC) para restringir o que programas especÃ­ficos podem acessar.
-   Os perfis sÃ£o baseados em texto, orientados a caminhos e fÃ¡ceis de ler e editar.

**Como funciona?**

-   Cada binÃ¡rio pode ter um perfil que define seus arquivos permitidos, rede e capacidades â€“ atÃ© mesmo como root!
-   FÃ¡cil de alternar entre os modos reclamar, aplicar e desabilitar.

**Comandos rÃ¡pidos:**

```sh
#Status
aa-status

# Put a program in enforce mode
sudo aa-enforce /etc/apparmor.d/usr.bin.foo

# Profiles
location: /etc/apparmor.d/
```

**Ferramentas:**

aa-genprof, aa-logprof para gerar/atualizar perfis

Registros

```sh
/var/log/syslog (search for apparmor)
```

#### ğŸ”’SELinux (Linux com seguranÃ§a aprimorada)

**O que Ã©?**

-   Um sistema MAC muito poderoso para controlar o acesso a tudo: arquivos, processos, usuÃ¡rios, portas, redes e muito mais.
-   Usa rÃ³tulos (contextos) e polÃ­ticas detalhadas.

**Como funciona?**

-   Tudo (processo, arquivo, porta, etc.) recebe um contexto de seguranÃ§a.
-   O kernel verifica cada aÃ§Ã£o em relaÃ§Ã£o Ã s regras de polÃ­tica.

**Comandos rÃ¡pidos:**

```sh
#Status
sestatus

#Set to enforcing/permissive:
setenforce 1  # Enforcing
setenforce 0  # Permissive

#List security contexts:
ls -Z  # Files
ps -eZ # Processes
```

**Ferramentas:**

-   audit2allow, semanage, chcon (para gerenciar polÃ­ticas/rÃ³tulos)
-   Registros: /var/log/audit/audit.log
-   PolÃ­ticas: /etc/selinux/

#### ğŸ“‹ Tabela resumida para sistemas de seguranÃ§a comuns

| Sistema  | Foco                          | Complexidade | LocalizaÃ§Ã£o da polÃ­tica                | Uso tÃ­pico              |
| -------- | ----------------------------- | ------------ | -------------------------------------- | ----------------------- |
| Seccomp  | Chamadas de sistema do kernel | MÃ©dio        | Por processo (via cÃ³digo/configuraÃ§Ã£o) | Docker, caixas de areia |
| AppArmor | Acesso por programa           | FÃ¡cil        | /etc/apparmor.d/                       | Ubuntu, Snap, SUSE      |
| SELinux  | MAC de sistema completo       | AvanÃ§ado     | /etc/selinux/ + rÃ³tulos                | RHEL, Fedora, CentOS    |

#### ğŸ—‚ï¸ ComparaÃ§Ã£o de isolamento e seguranÃ§a de contÃªiner Linux

| Tecnologia               | Objetivo / O que faz                                                                                                   | Principais diferenÃ§as                                                                                         | Exemplo em contÃªineres                                                                             |
| ------------------------ | ---------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- |
| **chroot ğŸ **            | Altera o diretÃ³rio raiz aparente de um processo. Isola o sistema de arquivos.                                          | Isolamento simples do sistema de arquivos; faz**nÃ£o**restringir recursos, privilÃ©gios ou chamadas de sistema. | Docker usa`chroot`internamente para construir imagens mÃ­nimas, mas nÃ£o para isolamento forte.      |
| **cgroups ğŸ“Š**           | Controla e limita o uso de recursos (CPU, memÃ³ria, E/S de disco, etc.) por grupo de processos.                         | Recurso do kernel; controle refinado de recursos, nÃ£o isolamento.                                             | Docker and Kubernetes use cgroups to limit CPU/mem per container/pod.                              |
| **espaÃ§os para nome ğŸŒ** | Isole os recursos do sistema: PID, montagem, UTS, rede, usuÃ¡rio, IPC, hora.                                            | Recurso do kernel; fornece diferentes tipos de isolamento.                                                    | Cada contÃªiner Ã© executado em seu prÃ³prio conjunto de namespaces (PID, net, mount, etc).           |
| **capacidades ğŸ›¡ï¸**      | Divida os privilÃ©gios de root em unidades refinadas (por exemplo, net_administrador, sistema_administrador).           | Mais granular do que raiz/nÃ£o raiz do tipo tudo ou nada; pode cancelar ou conceder privilÃ©gios especÃ­ficos.   | Os contÃªineres Docker geralmente sÃ£o executados com capacidades reduzidas (descarte os perigosos). |
| **seccomp ğŸ§±**           | Filtrar/restringir quais syscalls um processo pode fazer (lista branca/lista negra).                                   | Muito focado: bloqueia syscalls do kernel; nÃ£o Ã© possÃ­vel bloquear todas as aÃ§Ãµes.                            | O perfil padrÃ£o do Docker bloqueia syscalls perigosos (por exemplo,`ptrace`,`mount`).              |
| **AppArmor ğŸ§**          | Estrutura de controle de acesso obrigatÃ³rio (MAC): restringe o acesso a arquivos/rede de programas por meio de perfis. | Baseado em perfil, mais fÃ¡cil de gerenciar que o SELinux; menos refinado em alguns casos.                     | Os contÃªineres baseados no Ubuntu geralmente usam o AppArmor para perfis de processo de contÃªiner. |
| **SELinux ğŸ”’**           | Estrutura MAC mais complexa, baseada em rÃ³tulos, muito refinada. Pode confinar usuÃ¡rios, processos e arquivos.         | Mais poderoso e complexo que o AppArmor; aplicado no Fedora/RHEL/CentOS.                                      | No OpenShift/Kubernetes com RHEL, os rÃ³tulos SELinux sÃ£o usados â€‹â€‹para manter os pods separados.   |

Resumo

-   chroot: Isolamento bÃ¡sico, sem garantias de recursos/seguranÃ§a.
-   cgroups: Controle de recursos, nÃ£o isolamento.
-   namespaces: isolam "visualizaÃ§Ãµes" dos recursos do kernel.
-   capacidades: Ajuste os privilÃ©gios do processo.
-   seccomp: Restringe a superfÃ­cie de chamada do sistema.
-   AppArmor/SELinux: Limite quais processos podem tocar, mesmo como root (MAC).

#### ğŸ§© OCI, runc, containerd, CRI, CRI-O â€” O que sÃ£o no ecossistema de contÃªineres

##### VisÃ£o geral e funÃ§Ãµes

-   **OCI (Iniciativa de contÃªiner aberto) ğŸ›ï¸**

    Uma fundaÃ§Ã£o que cria padrÃµes abertos para**imagens de contÃªiner**e**tempos de execuÃ§Ã£o**.

    _Define como as imagens sÃ£o formatadas, armazenadas e como os contÃªineres sÃ£o iniciados/parados (especificaÃ§Ãµes de tempo de execuÃ§Ã£o)._
-   **âš™ï¸ runc**

    Uma ferramenta CLI universal, leve e de baixo nÃ­vel que pode executar contÃªineres de acordo com a especificaÃ§Ã£o de tempo de execuÃ§Ã£o do OCI.

    _â€œO mecanismoâ€ que transforma uma imagem + configuraÃ§Ã£o em um contÃªiner Linux real em execuÃ§Ã£o._
-   **contÃªiner ğŸ‹ï¸**

    Um daemon de tempo de execuÃ§Ã£o de contÃªiner principal para gerenciar o ciclo de vida completo do contÃªiner:**extrair imagens, gerenciar armazenamento, executar contÃªineres**(chama runc), plug-ins de rede, etc.

    _Usado por Docker, Kubernetes, nerdctl e outras ferramentas como back-end de tempo de execuÃ§Ã£o de contÃªiner principal._
-   **CRI (interface de tempo de execuÃ§Ã£o do contÃªiner) ğŸ”Œ**

    Uma API gRPC especÃ­fica do Kubernetes para conectar o Kubernetes a tempos de execuÃ§Ã£o de contÃªiner.

    _NÃ£o usado fora do Kubernetes, mas permite que K8s se comuniquem com containerd, CRI-O, etc._
-   **CRI-O ğŸ¥¤**

    Um tempo de execuÃ§Ã£o leve e focado no Kubernetes que**apenas**executa contÃªineres OCI, usando runc nos bastidores.

    _Usado principalmente em Kubernetes, mas demonstra como construir um tempo de execuÃ§Ã£o de contÃªiner mÃ­nimo focado em padrÃµes abertos._

##### ğŸ·ï¸ Tabelas de comparaÃ§Ã£o: Oci, Runc, Containerd, Cri, Cri-o

| Componente    | Emoji | O que Ã©?                                     | Quem usa?                               | Exemplo de uso                                                                                 |
| ------------- | ----- | -------------------------------------------- | --------------------------------------- | ---------------------------------------------------------------------------------------------- |
| **OCI**       | ğŸ›ï¸   | PadrÃµes/especificaÃ§Ãµes                       | Docker, Podman, CRI-O, containerd, runc | Garante que imagens/contÃªineres sejam compatÃ­veis entre ferramentas                            |
| **runc**      | âš™ï¸    | tempo de execuÃ§Ã£o do contÃªiner (CLI)         | containerd, CRI-O, Docker, Podman       | Executar diretamente um contÃªiner a partir de um pacote (por exemplo,`runc run`)               |
| **contÃªiner** | ğŸ‹ï¸   | daemon de tempo de execuÃ§Ã£o do contÃªiner     | Docker, Kubernetes, nerdctl             | Lida com extraÃ§Ã£o de imagens, gerenciamento de armazenamento/rede, inicia contÃªineres via runc |
| **IRC**       | ğŸ”Œ    | Interface de tempo de execuÃ§Ã£o (API) K8s     | Somente Kubernetes                      | Vamos kubelet falar com containerd/CRI-O                                                       |
| **CRI-O**     | ğŸ¥¤    | Tempo de execuÃ§Ã£o de contÃªiner leve para K8s | Kubernetes, OpenShift                   | Usado como mecanismo de contÃªiner K8s                                                          |

* * *

##### ğŸ› ï¸ Exemplos PrÃ¡ticos (Container Geral Mundial)

-   **Construindo imagens:**

    Qualquer ferramenta (Docker, Podman, Buildah) pode produzir imagens seguindo o**EspecificaÃ§Ãµes de imagem OCI**entÃ£o eles sÃ£o compatÃ­veis em todos os lugares.
-   **Executando contÃªineres:**

    Tanto o Podman quanto o Docker usam**runc**(via containerd ou diretamente) para criar contÃªineres.
-   **Gerenciando muitos contÃªineres:**

    **contÃªiner**pode ser usado sozinho (via`ctr`ou`nerdctl`) ou como back-end para Docker e Kubernetes.
-   **Tempos de execuÃ§Ã£o plug-and-play:**

    GraÃ§as a**OCI**, vocÃª pode trocar o runc por outro tempo de execuÃ§Ã£o compatÃ­vel com OCI (como contÃªineres Kata para VMs, gVisor para sandbox) sem alterar a forma como vocÃª cria ou gerencia imagens.

* * *

##### ğŸš¢ Pilha TÃ­pica

```plaintext
[User CLI / Orchestration]
           |
   [containerd / CRI-O]
           |
        [runc]
           |
[Linux Kernel: namespaces, cgroups, etc]
```

-   **Docker**: UsuÃ¡rio 151 â†’ containerd â†’ runc
-   **Subman**: UsuÃ¡rio 151 â†’ runc
-   **Kubernetes**: Kubelet (CRI) â†’ containerd ou cri-o â†’ runc

* * *

##### ğŸ§  Resumo

-   **OCI**= Linguagem comum para imagens/tempos de execuÃ§Ã£o (padrÃµes/especificaÃ§Ãµes)
-   **runc**= Ferramenta real que cria e gerencia processos de contÃªiner
-   **contÃªiner**= Daemon completo que gerencia imagens, contÃªineres, ciclo de vida
-   **IRC**= Somente para Kubernetes, para tornar os tempos de execuÃ§Ã£o conectÃ¡veis
-   **CRI-O**= Tempo de execuÃ§Ã£o leve focado em Kubernetes, baseado em padrÃµes OCI e runc

##### ğŸ§© Diagrama: ecossistema de contÃªineres

```mermaid
graph TD
    subgraph OCI_Standards
        OCI1["OCI Image Spec"]
        OCI2["OCI Runtime Spec"]
    end

    subgraph Orchestration_CLI
        Docker["Docker CLI"]
        Podman["Podman CLI"]
        Kubelet["Kubelet"]
        Nerdctl["nerdctl CLI"]
    end

    subgraph container_Runtimes
        containerd["containerd"]
        crio["CRI-O"]
    end

    runc["runc"]

    Kernel["Linux Kernel(namespaces, cgroups, seccomp, etc)"]

    %% Connections
    Docker --> containerd
    Podman --> runc
    Nerdctl --> containerd
    Kubelet --> CRI[CRI API]
    CRI --> containerd
    CRI --> crio
    containerd --> runc
    crio --> runc
    runc --> Kernel

    OCI1 -.-> containerd
    OCI1 -.-> crio
    OCI2 -.-> runc
```

##### ğŸ§ª laboratÃ³rio runc

Para runc lab, vocÃª pode usar este script:[runc.sh](scripts/container/runc.sh)

[![asciicast](https://asciinema.org/a/UDVnhKSxPFRXDcwg0HYFkZdlX.svg)](https://asciinema.org/a/UDVnhKSxPFRXDcwg0HYFkZdlX)

##### ğŸ§ª contÃªiner de laboratÃ³rio

Para containerd, vocÃª pode usar este script:[containerd.sh](scripts/container/container.sh)

[![asciicast](https://asciinema.org/a/fCJsiwcL2ePneQX1aafITtoGM.svg)](https://asciinema.org/a/fCJsiwcL2ePneQX1aafITtoGM)

* * *

#### ğŸš€ ContÃªineres Podman, Buildah, Skopeo, OpenVZ, crun e Kata â€“ Fast Track

* * *

##### ğŸ³**Subman**

-   **O que Ã©?**Um gerenciador de contÃªineres compatÃ­vel com Docker CLI, mas**sem daemon**e pode correr**sem raÃ­zes**.
-   **Usar:**Crie, execute, pare e inspecione contÃªineres e pods.
-   **Destaques:**Nenhum daemon central, mais seguro para multiusuÃ¡rio, integra-se ao systemd.
-   [Mais informaÃ§Ãµes](<>)

* * *

##### ğŸ“¦**Construir**

-   **O que Ã©?**Ferramenta para**construir e manipular imagens de contÃªiner**(OCI/Docker) sem daemon.
-   **Usar:**Construindo imagens em pipelines ou scripts de CI/CD.
-   **Destaques:**Suporte leve e sem raÃ­zes, usado por Podman sob o capÃ´.
-   [Mais informaÃ§Ãµes](https://www.redhat.com/en/topics/containers/what-is-buildah)

* * *

##### ğŸ”­**Escopo**

-   **O que Ã©?**UtilitÃ¡rio para**inspecionar, copiar e mover imagens de contÃªiner**entre registros**sem puxar ou correr**eles.
-   **Usar:**Mova imagens, verifique assinaturas e metadados.
-   **Destaques:**Sem daemon, ideal para automaÃ§Ã£o e seguranÃ§a.
-   [Mais informaÃ§Ãµes](<>)

* * *

##### ğŸ¢**OpenVZ**

-   **O que Ã©?****virtualizaÃ§Ã£o baseada em contÃªiner**soluÃ§Ã£o para Linux (prÃ©-datada de ferramentas de contÃªiner modernas).
-   **Usar:**VPS leves (servidores virtuais privados) compartilhando o mesmo kernel.
-   **Destaques:**Muito eficiente, mas menos isolado que VM (compartilha kernel).
-   [Mais informaÃ§Ãµes](https://en.wikipedia.org/wiki/OpenVZ)

* * *

##### âš¡**Crun**

-   **O que Ã©?**Tempo de execuÃ§Ã£o OCI mÃ­nimo e ultrarrÃ¡pido para contÃªineres, escrito em C (nÃ£o em Go).
-   **Usar:**Executa contÃªineres com sobrecarga mÃ­nima.
-   **Destaques:**Mais rÃ¡pido e mais leve que o runc, padrÃ£o para Podman em alguns sistemas.
-   [Mais informaÃ§Ãµes](https://www.redhat.com/sysadmin/introduction-crun)

* * *

##### ğŸ›¡ï¸**A palavra recipientes**

-   **O que Ã©?**Projeto de cÃ³digo aberto que combina contÃªineres e VMs: cada contÃªiner Ã© executado em uma micro-VM leve.
-   **Usar:**Forte isolamento para cargas de trabalho confidenciais ou ambientes multilocatÃ¡rios.
-   **Destaques:**SeguranÃ§a de nÃ­vel VM, desempenho prÃ³ximo ao contÃªiner.
-   [Mais informaÃ§Ãµes](https://katacontainers.io/)

* * *

##### ğŸ“Š**Tabela de comparaÃ§Ã£o**

| Projeto                   | Categoria                | Isolamento            | Daemon? | Uso principal                         | Sem raÃ­zes | Notas                                     |
| ------------------------- | ------------------------ | --------------------- | ------- | ------------------------------------- | ---------- | ----------------------------------------- |
| **Subman**                | OrquestraÃ§Ã£o             | recipiente            | No      | Gerenciar contÃªineres                 | Sim        | CLI semelhante ao Docker                  |
| **Construir**             | Construir                | N / D                 | No      | Construir imagens                     | Sim        | Para CI/CD, nenhuma execuÃ§Ã£o de contÃªiner |
| **Escopo**                | TransferÃªncia de imagem  | N / D                 | No      | Mover/verificar imagens               | Sim        | Nenhuma execuÃ§Ã£o de contÃªiner             |
| **OpenVZ**                | VirtualizaÃ§Ã£o            | contÃªiner/VPS         | Sim     | VPS leve                              | No         | Kernel compartilhado, tecnologia legada   |
| **Crun**                  | Tempo de execuÃ§Ã£o do OCI | recipiente            | No      | Tempo de execuÃ§Ã£o rÃ¡pido do contÃªiner | Sim        | Mais rÃ¡pido que runc                      |
| **A palavra recipientes** | Tempo de execuÃ§Ã£o/VM     | MicroVM por contÃªiner | No      | Isolamento forte                      | Sim        | SeguranÃ§a em nÃ­vel de VM                  |

* * *

##### â˜‘ï¸**RecapitulaÃ§Ã£o rÃ¡pida**

-   **Podman:**Alternativa Docker moderna e sem daemon.
-   **Construir:** Build images, doesn't run containers.
-   **Escopo:**Move/inspeciona imagens, nunca as executa.
-   **OpenVZ:**VPS legado baseado em contÃªiner.
-   **Cruel:**Tempo de execuÃ§Ã£o OCI super rÃ¡pido e leve.
-   **Dizer:**contÃªineres com isolamento em nÃ­vel de VM.

#### ğŸ› ï¸ 352.1 Comandos importantes

##### ğŸ”— cancelar o compartilhamento

```sh
# create a new namespaces and run a command in it
unshare --mount --uts --ipc --user --pid --net  --map-root-user --mount-proc --fork chroot ~vagrant/debian bash
# mount /proc for test
#mount -t proc proc /proc
#ps -aux
#ip addr show
#umount /proc
```

##### ğŸ” lsns

```sh
# show all namespaces
lsns

# show only pid namespace
lsns -p <pid>
lsns -p 3669

ls -l /proc/<pid>/ns
ls -l /proc/3669/ns

ps -o pid,pidns,netns,ipcns,utsns,userns,args -p <PID>
ps -o pid,pidns,netns,ipcns,utsns,userns,args -p 3669
```

##### ğŸšª nsenter

```sh
# get PID docker container
# execute a command in namespace Network
sudo nsenter -t 3669 -n ip link show

# execute a command in namespace UTS
sudo nsenter -t 3669 -u hostname

# execute a command in namespace mount
nsenter -t 3669 -m ls

# execute a command in all namespaces
sudo nsenter -t 3669 -a ps
```

##### ğŸŒ 252,1 ip

```sh
# create a new network namespace
sudo ip netns add lxc1

# list network list
ip netns list

# exec command in network namespace
sudo ip netns exec lxc1 ip addr show
```

##### ğŸ“Š estatÃ­stica

```sh
# get cgroup version
stat -fc %T /sys/fs/cgroup
```

##### ğŸ› ï¸ systemctl e systemd

```sh
# get cgroups of system
systemctl status
systemd-cgls
```

##### ğŸ—ï¸ cgcriar

```sh
cgcreate -g memory,cpu:lsf
```

##### ğŸ·ï¸ cgclassificar

```sh
cgclassify -g memory,cpu:lsf <PID>
```

##### ğŸ›¡ï¸ pscap - Listar capacidades do processo

```sh
# List capabilities of all process
pscap
```

##### ğŸ›¡ï¸ getcap /usr/bin/tcpdump

```sh
getcap /usr/bin/tcpdump
```

##### ğŸ›¡ï¸ setcap cap_net_raw=ep /usr/bin/tcpdump

```sh
# add capabilities to tcpdump
sudo setcap cap_net_raw=ep /usr/bin/tcpdump

# remove capabilities from tcpdump
sudo setcap -r /usr/bin/tcpdump
sudo setcap '' /usr/bin/tcpdump
```

##### ğŸ›¡ï¸ verifique os recursos por processo

```sh
grep Cap /proc/<PID>/status
```

##### ğŸ›¡ï¸ capsh - capacidade de wrapper de shell

```sh
# use grep Cap /proc/<PID>/statusfor get hexadecimal value(Example CApEff=0000000000002000)
capsh --decode=0000000000002000
```

##### ğŸ¦º AppArmor â€“ aprimoramento do kernel para confinar programas a um conjunto limitado de recursos

```sh
# check AppArmor status
sudo aa-status

#  unload all AppArmor profiles
aa-teardown

# loads AppArmor profiles into the kernel
aaparmor_parser
```

##### ğŸ”’ SELinux - Linux com seguranÃ§a aprimorada

```sh
# check SELinux status
sudo sestatus

# check SELinux mode
sudo getenforce 

# set SELinux to enforcing mode
sudo setenforce 1
```

##### âš™ï¸ runc

```sh
#create a spec file for runc
runc spec

# run a container using runc
sudo runc run mycontainer
```

* * *

<p align="right">(<a href="#topic-352.1">back to sub topic 352.1</a>)</p>
<p align="right">(<a href="#topic-352">back to topic 352</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-352.2"></a>

### ğŸ“¦ 352,2 LXC

**Peso:**6

**DescriÃ§Ã£o:**Os candidatos devem ser capazes de usar contÃªineres de sistema usando LXC e LXD. A versÃ£o do LXC coberta Ã© 3.0 ou superior.

**Principais Ã¡reas de conhecimento:**

-   Entenda a arquitetura do LXC e LXD
-   Gerencie contÃªineres LXC com base em imagens existentes usando LXD, incluindo rede e armazenamento
-   Configurar propriedades do contÃªiner LXC
-   Limitar o uso de recursos do contÃªiner LXC
-   Use perfis LXD
-   Entenda as imagens LXC
-   Conhecimento das ferramentas LXC tradicionais

#### ğŸ“‹ 352,2 objetos citados

```sh
lxd
lxc (including relevant subcommands)
/etc/lxc/
/etc/default/lxc
/var/log/lxc/
/usr/share/lxc/templates
```

#### ğŸ§© LXC e LXD â€“ O pacote de contÃªineres do sistema Linux

* * *

##### ğŸ“¦ LXC (contÃªineres Linux)

-   **O que Ã©?**

    O_essencial_conjunto de ferramentas de espaÃ§o do usuÃ¡rio para gerenciar contÃªineres de aplicativos e sistemas no Linux. Pense no LXC como**"chroot com esterÃ³ides"**â€“ fornece isolamento leve de processos usando recursos do kernel (namespaces, cgroups, AppArmor, seccomp, etc).
-   **Usar:**

    -   Execute distribuiÃ§Ãµes completas do Linux como contÃªineres (nÃ£o apenas aplicativos individuais).
    -   Ãštil para testes, aplicativos legados ou simulaÃ§Ã£o de servidores.
-   **Destaques:**

    -   Focado em CLI:`lxc-create`,`lxc-start`,`lxc-attach`, etc.
    -   Controle refinado sobre os recursos do contÃªiner.
    -   Sem daemon â€“ executa processos por contÃªiner.
-   **Melhor para:**

    Especialistas em Linux que desejam controle total e sensaÃ§Ã£o â€œbare-metalâ€ para contÃªineres.

##### ğŸ§ª laboratÃ³rio LXC

Para o laboratÃ³rio LXC, vocÃª pode usar este script:[lxc.sh](scripts/container/lxc.sh)

[![asciicast](https://asciinema.org/a/CpjDAXRnaKH5kExg9eWSBJGHI.svg)](https://asciinema.org/a/CpjDAXRnaKH5kExg9eWSBJGHI)

* * *

##### ğŸŒLXD

-   **O que Ã©?**

    **LXD**Ã© um_prÃ³xima geraÃ§Ã£o_contÃªiner e gerenciador de VM,**construÃ­do em cima do LXC**. Ele oferece uma experiÃªncia poderosa, mas fÃ¡cil de usar, para gerenciar contÃªineres e mÃ¡quinas virtuais por meio de API REST, CLI ou atÃ© mesmo uma interface da Web.
-   **Usar:**

    -   Gerencie contÃªineres de sistema e mÃ¡quinas virtuais em escala.
    -   â€œContÃªiner como serviÃ§oâ€ em rede com fÃ¡cil orquestraÃ§Ã£o.
-   **Destaques:**

    -   **API REST**: gerencia contÃªineres/VMs pela rede.
    -   **Imagens:**ImplantaÃ§Ã£o instantÃ¢nea de muitas distribuiÃ§Ãµes Linux.
    -   **InstantÃ¢neos, pools de armazenamento, clustering, migraÃ§Ã£o em tempo real.**
    -   Suporta a execuÃ§Ã£o de contÃªineres sem privilÃ©gios por padrÃ£o.
    -   CLI:`lxc launch`,`lxc exec`,`lxc snapshot`, etc._(Sim, mesmo prefixo do LXC, mas back-end diferente!)_
-   **Melhor para:**

    DevOps, administradores de sistemas, configuraÃ§Ãµes nativas da nuvem, ambientes de laboratÃ³rio.

##### ğŸ“**Armazenamento LXD: tabela de recursos (por back-end)**

| Recurso                  | VocÃª          | zfs                   | BRFS                  | lvm/lvmfino           | ceph/cepfs        |
| ------------------------ | ------------- | --------------------- | --------------------- | --------------------- | ----------------- |
| **InstantÃ¢neos**         | âŒ             | âœ…                     | âœ…                     | âœ…                     | âœ…                 |
| **Provisionamento fino** | âŒ             | âœ…                     | âœ…                     | âœ… (lvmfino)           | âœ…                 |
| **Redimensionar**        | âŒ             | âœ…                     | âœ…                     | âœ…                     | âœ…                 |
| **Cotas**                | âŒ             | âœ…                     | âœ…                     | âœ… (lvmfino)           | âœ…                 |
| **MigraÃ§Ã£o ao vivo**     | âŒ             | âœ…                     | âœ…                     | âœ…                     | âœ…                 |
| **DesduplicaÃ§Ã£o**        | âŒ             | âœ…                     | âŒ                     | âŒ                     | âœ… (Cef)           |
| **CompressÃ£o**           | âŒ             | âœ…                     | âœ…                     | âŒ                     | âœ… (Cef)           |
| **Criptografia**         | âŒ             | âœ…                     | âŒ                     | âœ… (luxo)              | âœ…                 |
| **Cluster/Remoto**       | âŒ             | âŒ                     | âŒ                     | âŒ                     | âœ…                 |
| **Melhor caso de uso**   | Desenvolvedor | LaboratÃ³rios/produÃ§Ã£o | LaboratÃ³rios/produÃ§Ã£o | LaboratÃ³rios/produÃ§Ã£o | Clusters, Empresa |

##### ğŸ”**Resumo rÃ¡pido de armazenamento LXD**

-   **Conjuntos de armazenamento:**Abstrai o back-end: vÃ¡rios pools, diferentes drivers por pool.
-   **Drivers disponÃ­veis:**dir, zfs, btrfs, lvm, lvmthin, ceph, cephfs (mais atravÃ©s de plugins).
-   **Volumes personalizados:**Crie, monte e desmonte contÃªineres/VMs.
-   **InstantÃ¢neos e clones:**Nativo, rÃ¡pido, suporta backup/restauraÃ§Ã£o e migraÃ§Ã£o de cÃ³pia na gravaÃ§Ã£o.
-   **Cotas e redimensionamento:**FÃ¡cil gerenciamento em tempo real para pools, contÃªineres ou volumes.
-   **MigraÃ§Ã£o ao vivo:**Mova contÃªineres/VMs entre hosts sem tempo de inatividade.
-   **SeguranÃ§a:**Criptografia integrada (ZFS, LVM, Ceph), ACLs, backup/restauraÃ§Ã£o, etc.
-   **Pronto para empresas:**Adequado para configuraÃ§Ãµes em cluster e de alta disponibilidade.

* * *

##### ğŸ“Š Tabela de comparaÃ§Ã£o LXC vs LXD

| Recurso           | ğŸ·ï¸LXC                                                       | ğŸŒLXD                                                         |
| ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------- |
| **Tipo**          | Gerenciador de contÃªiner de espaÃ§o do usuÃ¡rio de baixo nÃ­vel | Gerente de alto nÃ­vel (contÃªineres + VMs)                     |
| **Interface**     | Somente CLI                                                  | API REST, CLI, UI da Web                                      |
| **Daemon?**       | No (runs as processes)                                       | Sim (daemon/serviÃ§o central)                                  |
| **OrquestraÃ§Ã£o**  | Manual, programÃ¡vel                                          | Clustering e API integrados                                   |
| **Imagens**       | Baseado em modelo                                            | RepositÃ³rio completo de imagens, muitos sistemas operacionais |
| **InstantÃ¢neos**  | Manual                                                       | Nativo, integrado                                             |
| **Suporte a VMs** | No                                                           | Sim (QEMU/KVM)                                                |
| **Caso de uso**   | Controle refinado, â€œbare metalâ€                              | EscalÃ¡vel, fÃ¡cil de usar e multi-host                         |
| **SeguranÃ§a**     | Pode ser sem privilÃ©gios, mas faÃ§a vocÃª mesmo                | PadrÃ£o sem privilÃ©gios, mais isolamento                       |
| **Melhor para**   | Profissionais do Linux, scripts avanÃ§ados                    | DevOps, nuvem, equipes, autoatendimento                       |

* * *

##### â˜‘ï¸ RecapitulaÃ§Ã£o rÃ¡pida

-   **LXC**= Os blocos de construÃ§Ã£o de baixo nÃ­vel. PotÃªncia e flexibilidade para_puristas de contÃªineres_.
-   **LXD**= Plataforma moderna, baseada em API e escalÃ¡vel sobre LXC para_fÃ¡cil_gerenciamento de contÃªineres e VMs (nÃ³ Ãºnico ou clusters).

##### ğŸ—ƒï¸ LXC vs LXD - Suporte de armazenamento (resumo)

| Recurso                             | **LXC**                                       | **LXD**                                                                                                       |
| ----------------------------------- | --------------------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| **Back-ends de armazenamento**      | Sistema de arquivos local (somente padrÃ£o)    | **VocÃª**(sistema de arquivos),**zfs**,**BRFS**,**lvm**,**ceph**,**cephfs**,**lvmfino**                        |
| **Conjuntos de armazenamento**      | âŒ (apenas caminhos locais, sem pools nativos) | âœ… VÃ¡rios pools de armazenamento, cada um com drivers diferentes                                               |
| **InstantÃ¢neos**                    | Dependente de manual/FS                       | âœ… Snapshots nativos, rÃ¡pidos, automÃ¡ticos, programados e consistentes                                         |
| **Provisionamento fino**            | âŒ (nÃ£o suportado nativamente)                 | âœ… CompatÃ­vel com ZFS, Btrfs, LVM thin, Ceph                                                                   |
| **Cotas**                           | âŒ                                             | âœ… CompatÃ­vel por contÃªiner/volume (em ZFS, Btrfs, Ceph, LVMthin)                                              |
| **MigraÃ§Ã£o ao vivo**                | Limitado                                      | âœ… MigraÃ§Ã£o de armazenamento ao vivo entre hosts, cÃ³pia na gravaÃ§Ã£o                                            |
| **Criptografia**                    | âŒ                                             | âœ… (ZFS, LVM, Ceph)                                                                                            |
| **Volumes personalizados**          | âŒ                                             | âœ… Crie, anexe/desconecte volumes de armazenamento personalizados para contÃªineres/VMs                         |
| **Armazenamento remoto**            | âŒ                                             | âœ… Suporte Ceph, CephFS, NFS, SMB                                                                              |
| **Recursos do sistema de arquivos** | Dependente do host                            | ZFS: desduplicaÃ§Ã£o, compactaÃ§Ã£o, instantÃ¢neos, envio/recebimento, cache, cotas. LVM: fino, instantÃ¢neos, etc. |
| **Redimensionar**                   | Manual (via host)                             | âœ… Volumes e pools podem ser redimensionados ao vivo                                                           |
| **Drivers de armazenamento**        | BÃ¡sico/local apenas                           | Plug-ins extensÃ­veis, vÃ¡rios drivers prontos para uso empresarial                                             |

##### ğŸ“Š Tabela de comparaÃ§Ã£o de armazenamento final

|                                | **LXC**         | **LXD**                                                     |
| ------------------------------ | --------------- | ----------------------------------------------------------- |
| **Back-end de armazenamento**  | Somente locais  | dir, zfs, btrfs, lvm, lvmthin, ceph, cephfs                 |
| **Conjuntos de armazenamento** | âŒ               | âœ… MÃºltiplos, independentes, hot-pluggable                   |
| **InstantÃ¢neos**               | Limitado/manual | âœ… RÃ¡pido, automÃ¡tico, consistente                           |
| **Provisionamento fino**       | âŒ               | âœ… (zFS, BTRFS, LVMthain, Cepph)                             |
| **Cotas**                      | âŒ               | âœ…                                                           |
| **Redimensionar**              | Manual          | âœ…                                                           |
| **Armazenamento remoto**       | âŒ               | âœ… (Ceph, NFS, SMB)                                          |
| **Volumes personalizados**     | âŒ               | âœ…                                                           |
| **Cluster pronto**             | âŒ               | âœ…                                                           |
| **Empresa**                    | No              | Sim â€” HA, backup, migraÃ§Ã£o, seguranÃ§a, pronto para produÃ§Ã£o |

##### ğŸŒ LXC vs LXD - Suporte de rede (resumo)

| Recurso                  | **LXC**                          | **LXD**                                                                     |
| ------------------------ | -------------------------------- | --------------------------------------------------------------------------- |
| **Tipos de rede**        | ponte, veth, macvlan, phys, vlan | ponte, ovn, macvlan, sriov, fÃ­sico, vlan, ventilador, tÃºneis                |
| **Redes Gerenciadas**    | âŒ Manual (configuraÃ§Ã£o do host)  | âœ… Gerenciado nativamente via API/CLI, fÃ¡cil de criar e editar               |
| **API de rede**          | âŒ Somente comandos CLI           | âœ… API REST, CLI, integraÃ§Ã£o com ferramentas externas                        |
| **Suporte de ponte**     | âœ… Manual                         | âœ… AutomÃ¡tico e avanÃ§ado (L2, Open vSwitch, ponte nativa)                    |
| **NAT e DHCP**           | âŒ Manual (iptables/dnsmasq)      | âœ… NAT integrado, DHCP, DNS, configurÃ¡vel por rede                           |
| **DNS**                  | âŒ Manual                         | âœ… DNS integrado, domÃ­nios personalizados, integraÃ§Ã£o resolvida pelo sistema |
| **IPVSH**                | âœ… (manual, limitado)             | âœ… Suporte completo, automÃ¡tico, DHCPv6, NAT6, roteamento                    |
| **VLAN**                 | âœ… (manual, anfitriÃ£o)            | âœ… VLANs nativas, fÃ¡cil configuraÃ§Ã£o                                         |
| **SR-Iov**               | âŒ                                | âœ… Suporte nativo                                                            |
| **ACLs de rede**         | âŒ                                | âœ… ACLs, encaminhamentos, zonas, peerings, regras de firewall                |
| **Agrupamento**          | âŒ                                | âœ… Redes replicadas e gerenciadas em clusters                                |
| **Anexar/Desanexar**     | Manual (anfitriÃ£o)               | âœ… CLI/API, hotplug, fÃ¡cil para contÃªineres/VMs                              |
| **SeguranÃ§a**            | Manual (anfitriÃ£o)               | âœ… Isolamento, firewall, ACL, integraÃ§Ã£o com firewalld, regras por rede      |
| **Rotas personalizadas** | Manual                           | âœ… Suporte a rotas personalizadas, vÃ¡rios gateways                           |
| **Perfis de rede**       | âŒ                                | âœ… Perfis de rede reutilizÃ¡veis                                              |
| **Monitoramento**        | Manual                           | âœ… Status, IPAM, logs, informaÃ§Ãµes detalhadas via CLI/API                    |
| **Empresa**              | No                               | Sim: multilocatÃ¡rio, ACL, clustering, integraÃ§Ã£o na nuvem                   |

##### ğŸ“Š Tabela final de comparaÃ§Ã£o de redes

|                   | **LXC**           | **LXD**                                                      |
| ----------------- | ----------------- | ------------------------------------------------------------ |
| **Tipos de rede** | ponte, veth, vlan | ponte, ovn, macvlan, sriov, fÃ­sico, vlan, ventilador, tÃºneis |
| **Gerenciou**     | âŒ                 | âœ…                                                            |
| **NAT/DHCP/DNS**  | Manual            | âœ… Integrado                                                  |
| **VLAN**          | Manual            | âœ…                                                            |
| **SR-Iov**        | âŒ                 | âœ…                                                            |
| **API**           | âŒ                 | âœ…                                                            |
| **Agrupamento**   | âŒ                 | âœ…                                                            |
| **SeguranÃ§a/ACL** | Manual            | âœ…                                                            |
| **Perfis**        | âŒ                 | âœ…                                                            |
| **Empresa**       | No                | Sim                                                          |

##### ğŸ§ª laboratÃ³rio LXD

Para o laboratÃ³rio LXD, vocÃª pode usar este script:[lxd.sh](scripts/container/lxd.sh)

#### ğŸ› ï¸ 352,2 comandos importantes

##### ğŸ“¦ lxc

```sh

# lxc configuration
/etc/default/lxc
/etc/default/lxc-net
/etc/lxc/default.conf
/usr/share/lxc/

# lxc container configuration
/var/lib/lxc/

# check lxc version
lxc-create --version

# list containers
sudo lxc-ls --fancy
sudo lxc-ls -f

# create a priveleged container
sudo lxc-create -n busybox -t busybox

# create a priveleged container with template
sudo lxc-create -n debian01 -t download
sudo lxc-create --name server2 --template download -- --dist alpine --release 3.19 --arch amd64

# get container info
sudo lxc-info -n debian01

# get container PID
sudo lxc-info -n debian01 -pH

# get container config
sudo lxc-checkconfig -n debian01

# start container
sudo lxc-start -n debian01

# stop container
sudo lxc-stop -n debian01

# connect to container
sudo lxc-attach -n debian01

# execute a command in container
sudo lxc-attach -n debian01 --  echo "Hello from"
sudo lxc-attach -n debian01 -- bash -c ls

# delete container
sudo lxc-destroy -n debian01

# delete container and snapshot
sudo lxc-destroy -n -s debian01

# rootfs of a container
sudo ls -l /var/lib/lxc/server1/rootfs

# modify rootfs of a container
sudo touch  /var/lib/lxc/server1/rootfs/tmp/test_roofs_file
sudo lxc-attach server1
ls /tmp

# get lxc namespaces
sudo lsns -p <LXC_container_PID>
sudo lsns -p $(sudo lxc-info server2 -pH)
sudo lsns -p $(sudo lxc-info -n server1 | awk '/PID:/ { print $2 }')

# unprivileged container namespaces
lsns -p $(lxc-info -n ubuntu | awk '/PID:/ { print $2 }')

# get container resource 
sudo lxc-top

# create a container snapshot
sudo lxc-stop -k -n debian01
sudo lxc-snapshot -n debian01

# list snapshots
sudo lxc-snapshot -n debian01 -L

# restore snapshot
sudo lxc-stop -n debian01
sudo lxc-snapshot -n debian01 -r snap0

# delete snapshot
sudo lxc-snapshot -n debian01 -d snap0

# create a new container with snapshot
sudo lxc-snapshot -n debian01 -r snap0 -N debian02

# create container checkpoint (privileged container)
sudo lxc-checkpoint -n debian01 -s -D /home/vagrant/.config/lxc/checkpoints/debian01-checkpoint01.file 

# define memory container limits with cgroups
sudo lxc-cgroup -n debian01 memory.max 262144000 #(250 MB Ã— 1.048.576 bytes = 262144000 bytes)

# define CPU cores of container  with cgroups
sudo lxc-cgroup -n debian01 cpuset.cpus 0-2

# get container cgroup limits
sudo cgget -g :lxc.payload.debian01 -a |grep memory.max
sudo cgget -g :lxc.payload.debian01 -a |grep cpuset

# set container cgroup vcpus range in file
sudo vim /var/lib/lxc/debian01/config
# add the following lines
lxc.cgroup2.cpuset.cpus = "5-6"

######## create unprivileged container #######

## create directory for unprivileged container
mkdir -p /home/vagrant/.config/lxc

## copy default config
cp /etc/lxc/default.conf /home/vagrant/.config/lxc/

## get subordinate user and group IDs
cat /etc/subuid

## configure subordinate user and group IDs
vim /home/vagrant/.config/lxc/default.conf

## add the following lines
lxc.idmap = u 0 100000 65536
lxc.idmap = g 0 100000 65536

## configure lxc-usernet
sudo vim /etc/lxc/lxc-usernet

## add the following line
vagrant veth lxcbr0 10

## create unprivileged container
lxc-create -n unprivileged -t download -- -d ubuntu -r jammy -a amd64

## set permissions for unprivileged container
sudo setfacl -m u:100000:--x /home/vagrant
sudo setfacl -m u:100000:--x /home/vagrant/.config
sudo setfacl -m u:100000:--x /home/vagrant/.local
sudo setfacl -m u:100000:--x /home/vagrant/.local/share

## start unprivileged container
lxc-start -n unprivileged --logpriority=DEBUG --logfile=lxc.log

## check container status
lxc-ls -f

## unprivileged container files
ls .local/share/lxc/unprivileged/
```

##### ğŸŒ lxd

```sh
# lxd configuration files
/var/lib/lxd
/var/log/lxd

# initialize lxd
sudo lxd init
sudo lxd init --auto
sudo cat lxd-init.yaml | lxd init --preseed

# check lxd version
sudo lxd --version

# check lxd status
systemctl status lxd

#### LXD STORAGE MANAGEMENT ####

# lxd list storage
lxc storage list

# show lxd storage pools
lxc storage show default

# lxd storage info
lxc storage info default

# create a new storage pool dir
lxc storage create lpic3-dir dir 

# create a new storage pool lvm
lxc storage create lpic3-lvm lvm source=/dev/sdb1

# create a new storage pool btrfs
lxc storage create lpic3-btrfs btrfs
lxc storage create lpic3-btrfs btrfs size=10GB
lxc storage create lpic3-btrfs btrfs source=/dev/sdb2

# create a new storage pool zfs
lxc storage create lpic3-zfs zfs source=/dev/sdb3

# delete storage pool
lxc storage delete lpic3-btrfs

# edit storage pool
lxc storage edit lpic3-btrfs

# get storage pool properties
lxc storage  get lpic3-btrfs size

# set storage pool properties
lxc storage set lpic3-btrfs size 20GB

# list storage volumes
lxc storage volume list lpic3-btrfs

# create a new storage volume
lxc storage volume create lpic3-btrfs vol-lpic3-btrfs

# delete storage volume
lxc storage volume delete lpic3-btrfs vol-lpic3-btrfs

### Management lxd storage buckets ####

# create lxd bucket
lxc storage bucket create lpic3-btrfs bucket-lpic3-btrfs
lxc storage bucket create lpic3-zfs bucket-lpic3-zfs

# list lxd buckets
lxc storage bucket list lpic3-btrfs

# set lxd bucket properties
lxc storage bucket set lpic3-btrfs bucket-lpic3-btrfs size 10GB

# edit lxd bucket 
lxc storage bucket edit lpic3-btrfs bucket-lpic3-btrfs

# delete lxd bucket
lxc storage bucket delete lpic3-btrfs bucket-lpic3-btrfs

# show ldx storage bucket
lxc storage bucket show lpic3-btrfs bucket-lpic3-btrfs

# create storage bucket keys
lxc storage bucket key create lpic3-btrfs bucket-lpic3-btrfs key-bucket-lpic3-btrfs

# edit storage bucket keys
lxc storage bucket key edit lpic3-btrfs bucket-lpic3-btrfs key-bucket-lpic3-btrfs

# list storage bucket keys
lxc storage bucket key list lpic3-btrfs bucket-lpic3-btrfs

# show storage bucket keys
lxc storage bucket key show lpic3-btrfs bucket-lpic3-btrfs key-bucket-lpic3-btrfs

# delete storage bucket keys
lxc storage bucket key delete lpic3-btrfs bucket-lpic3-btrfs key-bucket-lpic3-btrfs

### LXD IMAGE MANAGEMENT ###

# list lxd repositories
lxc remote list

# add lxd remote repository
lxc remote add lpic3-images https://images.lxd.canonical.com --protocol=simplestreams

# remove lxd remote repository
lxc remote remove lpic3-images 

# list lxd images
lxc image list

# list lxd images from remote repository
lxc image list images:
lxc image list images: os=Ubuntu
lxc image list images: os=Ubuntu release=jammy
lxc image list images: os=Ubuntu release=jammy architecture=amd64
lxc image list images: architecture=amd64 type=container
lxc image list images: d kal

# download lxd image to local
lxc image copy images:centos/9-Stream local: --alias centos-9

# export lxd remote image
lxc image export aed8a3749942  ./lxd-images/centos-9

# export lxd remote image
lxc image export images:f8fadb0d1b28 ./lxd-images/alma-9

# remove lxd image
lxc image delete centos-9

# mount lxd rootfs
mkdir -p /mnt/lxd-rootfs/centos-9
sudo mount lxd-images/centos-9/aed8a374994230243aaa82e979ac7d23f379e511556d35af051b1638662d47ae.squashfs  /mnt/lxd-rootfs/centos-9/
ls /mnt/lxd-rootfs/centos-9/

### LXD INSTANCES MANAGEMENT ###

# create a new container from image
lxc launch images:ubuntu/jammy ubuntu-lxd
lxc launch images:debian/12 debian12lxc
lxc launch images:fedora/41 fedora41
lxc launch images:opensuse/15.6 opensuse15

# create a new container from image with storage pool
lxc launch images:alpine/3.19 alpine --storage lpic3-lvm
lxc launch images:kali kali --storage lpic3-zfs

# create a new container from image local
lxc launch 757b2a721e9d kali-local-image

# create new vm
lxc launch --vm  images:debian/13 debian13 --storage lpic3-zfs
lxc launch --vm  images:e44d713a71b6 rocky9 --storage lpic3-btrfs

# list container\instances
lxc list

# stop container\instance
lxc stop alpine

# start container\instance
lxc start alpine

# delete container\instance
lxc delete alpine --force

# show container\instance
lxc info alpine

# show container\instance config
lxc config show alpine

# edit container\instance config
lxc config edit alpine

# view container\instance config
lxc config get alpine boot.autostart

# set container\instance config
lxc config set alpine boot.autostart=false

# set limit for container\instance
lxc config set alpine limits.cpu 2
lxc config set alpine limits.memory 10%

# unset limit for container\instance
lxc config unset alpine limits.cpu  
lxc config unset alpine limits.memory

# execute command in container\instance
lxc --exec alpine -- /bin/bash
lxc exec alpine -- uname -a || dhclient
lxc exec alpine -- sh -c "echo 'Hello from Alpine'"

# lxd copy file to container\instance
lxc file push /etc/hosts alpine/etc/hosts

# lxd edit file in container\instance
lxc file edit alpine/etc/hosts

# download file from container\instance
lxc file pull alpine/etc/hosts /tmp/alpine-hosts

### LXD NETWORK MANAGEMENT ###

# list networks
lxc network list

# show network details
lxc network show lxdbr0

# create a new network
lxc network create lxdbr1

# delete a network
lxc network delete lxdbr0

# show network details
lxc network show lxdbr0

# set ipv4.dhcp.ranges
lxc network set lxdbr0 ipv4.dhcp.ranges=10.119.220.100-10.119.220.200

# attach a network to a container
lxc network attach lxdbr0 alpine

# detach a network from a container
lxc network detach lxdbr0 alpine

### LXD SNAPSHOT MANAGEMENT ###

# snapshot files
/var/lib/lxd/snapshots/
/var/snap/lxd/common/lxd/snapshots

# create a snapshot
lxc snapshot debian12

# create a snapshot
lxc snapshot debian12 nome-snapshot

# restore a snapshot
lxc restore debian12 nome-snapshot

# delete a snapshot
lxc delete debian12/snap0

# show snapshot info
lxc info debian12

# copy a snapshot
lxc copy debian12/snap0 debian12-2

### LXD PROFILES MANAGEMENT ###

# list profiles
lxc profile list

# show profile details
lxc profile show default

# copy profile
lxc profile copy default production

# edit profile
lxc profile edit production

#set environment variables
lxc profile set production environment.EDITOR vim

# unset memory limit
lxc profile unset production limits.memory

# set boot autostart
lxc profile set production boot.autostart true

# add profile to container
lxc profile add debian12 production

# remove profile from container
lxc profile remove debian12 production

# launch container with profile
lxc launch 1u1u1u1u1u1 rockylinux9-2 -p production
```

<p align="right">(<a href="#topic-352.2">back to sub topic 352.2</a>)</p>
<p align="right">(<a href="#topic-352">back to topic 352</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-352.3"></a>

### ğŸ³ 352,3 Docker

![docker-architecture](images/docker.png)

![docker-runtime](images/docker-containerd.png)

**Peso:**9

**DescriÃ§Ã£o:**O candidato deve ser capaz de gerenciar nÃ³s Docker e contÃªineres Docker. Isso inclui compreender a arquitetura do Docker, bem como compreender como o Docker interage com o sistema Linux do nÃ³.

**Principais Ã¡reas de conhecimento:**

-   Entenda a arquitetura e os componentes do Docker
-   Gerencie contÃªineres do Docker usando imagens de um registro do Docker
-   Compreenda e gerencie imagens e volumes para contÃªineres Docker
-   Compreenda e gerencie o registro em log para contÃªineres Docker
-   Compreenda e gerencie redes para Docker
-   Use Dockerfiles para criar imagens de contÃªiner
-   Execute um registro Docker usando a imagem Docker do registro

#### ğŸ“‹ 352,3 Objetos Citados

```sh
dockerd
/etc/docker/daemon.json
/var/lib/docker/
docker
Dockerfile
```

#### ğŸ“– DefiniÃ§Ã£o

Docker Ã© um**plataforma de contÃªiner de cÃ³digo aberto**que permite aos desenvolvedores e operadores empacotar aplicativos e suas dependÃªncias em**recipientes**.

Esses contÃªineres garantem**consistÃªncia entre ambientes**, acelerar implantaÃ§Ãµes e reduzir a complexidade da infraestrutura.

* * *

#### ğŸ”‘ Conceitos-chave

-   ğŸ“¦**recipiente**â†’ Tempo de execuÃ§Ã£o leve e isolado, compartilhando o kernel do host.
-   ğŸ–¼ï¸**Imagem**â†’ Modelo somente leitura contendo o aplicativo e dependÃªncias.
-   âš™ï¸**Motor Docker (dockerd)**â†’ Daemon gerenciando contÃªineres, imagens e volumes.
-   âŒ¨ï¸**CLI do Docker**â†’ Ferramenta de linha de comando (`docker`) comunicando-se com o daemon.
-   â˜ï¸**DockerHub**â†’ Registro padrÃ£o para armazenamento e distribuiÃ§Ã£o de imagens.

* * *

#### ğŸš€ Vantagens

-   âš¡**Leve e rÃ¡pido**â†’ Muito mais rÃ¡pido que mÃ¡quinas virtuais.
-   ğŸŒ**Portabilidade**â†’ Executa em qualquer lugar que o Docker seja compatÃ­vel.
-   ğŸ› ï¸**Rico ecossistema**â†’ Compose, Swarm, Hub, Desktop UI, registros.
-   ğŸ”„**DevOps amigÃ¡vel**â†’ IntegraÃ§Ã£o CI/CD e alinhamento IaC.

* * *

#### ğŸ“‘ Registros Docker

-   â˜ï¸**DockerHub**â†’ PadrÃ£o, registro pÃºblico.
-   ğŸ¢**Registros Privados**â†’ Harbor, Artifactory, registro de contÃªiner GitHub.
-   ğŸ”’ Usar`docker login`para autenticar, enviar e extrair imagens.

* * *

#### Imagens Docker

![docker-images](images/docker-images.png)

-   Conceito: pacote imutÃ¡vel com aplicativo, dependÃªncias e metadados.
-   Camadas e cache: cada instruÃ§Ã£o Dockerfile se torna uma camada reutilizÃ¡vel
-   ConstrÃ³i e extrai camadas de compartilhamento.
-   SABER:`registry/namespace/repo:tag`(por exemplo,`docker.io/library/nginx:1.27`).
-   Digerir: usar`@sha256:...`para fixar o conteÃºdo exato (bom para produÃ§Ã£o).
-   Imagem vs contÃªiner: a imagem Ã© somente leitura; container Ã© uma instÃ¢ncia com uma camada de gravaÃ§Ã£o efÃªmera.
-   Comandos bÃ¡sicos:`docker image ls`,`docker pull`,`docker run`,`docker inspect`,`docker history`,`docker tag`,`docker push`,`docker rmi`,`docker image prune -a`,`docker save`/`docker load`.
-   PrÃ¡ticas recomendadas: base mÃ­nima (alpine/distroless), compilaÃ§Ãµes em vÃ¡rios estÃ¡gios, fixar versÃµes/tags, executar como nÃ£o-root`USER`.

##### Camadas de imagem Docker

Neste exemplo, demonstro camadas de imagem do Docker.

Na primeira imagem temos uma imagem base alpina e adicionamos uma camada.

```dockerfile
# syntax=docker/dockerfile:1
FROM alpine
RUN apk add --no-cache bash
```

A segunda imagem tenho uma my-base-image:1.0 e adiciono duas camadas, gerando uma nova imagem com o nome acme/my-final-image:1.0.

```dockerfile
# syntax=docker/dockerfile:1
FROM acme/my-base-image:1.0
COPY . /app
RUN chmod +x /app/hello.sh
CMD /app/hello.sh
```

![docker-image-layers](images/docker-image-layers.png)

##### CÃ³pia na gravaÃ§Ã£o da imagem Docker (CoW)

Neste exemplo, demonstro uma imagem docker Copy-on-Write (CoW).

Crie 5 contÃªineres a partir da mesma imagem.

```sh
docker run -dit --name my_container_1 acme/my-final-image:1.0 bash \
  && docker run -dit --name my_container_2 acme/my-final-image:1.0 bash \
  && docker run -dit --name my_container_3 acme/my-final-image:1.0 bash \
  && docker run -dit --name my_container_4 acme/my-final-image:1.0 bash \
  && docker run -dit --name my_container_5 acme/my-final-image:1.0 bash
```

Veja o tamanho dos contÃªineres.

```sh
docker ps --size --format "table {{.ID}}\t{{.Image}}\t{{.Names}}\t{{.Size}}"
```

Para demonstrar isso, execute o seguinte comando para escrever a palavra 'hello' em um arquivo na camada gravÃ¡vel do contÃªiner nos contÃªineres my_container_1, my_container_2 e my_container_3:

```sh
for i in {1..3}; do docker exec my_container_$i sh -c 'printf hello > /out.txt'; done
```

Verifique novamente o tamanho dos recipientes.

```sh
docker ps --size --format "table {{.ID}}\t{{.Image}}\t{{.Names}}\t{{.Size}}"
```

![docker-image-cow](images/docker-image-cow.png)

##### ğŸ³ InstruÃ§Ãµes e camadas de imagem Dockerfile

**ğŸ“Š Tabela: InstruÃ§Ã£o vs. GeraÃ§Ã£o de Camada**

| InstruÃ§Ã£o     | Cria uma camada de sistema de arquivos? | Notas                                                                                                         |
| ------------- | --------------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| `FROM`        | âŒ No                                    | Define a imagem base; camadas subjacentes vÃªm dele.                                                           |
| `RUN`         | âœ… Sim                                   | Executa alteraÃ§Ãµes no sistema de arquivos; adiciona conteÃºdo que persiste.                                    |
| `COPY`        | âœ… Sim                                   | Adiciona arquivos do contexto de construÃ§Ã£o ao sistema de arquivos de imagem.                                 |
| `ADD`         | âœ… Sim                                   | Semelhante ao COPY, com recursos adicionais (URLs, extraÃ§Ã£o de alcatrÃ£o).                                     |
| `LABEL`       | âŒ No                                    | Adiciona apenas metadados; nÃ£o altera o conteÃºdo do sistema de arquivos.                                      |
| `ENV`         | âŒ No                                    | Define variÃ¡veis â€‹â€‹de ambiente; armazenados como metadados.                                                   |
| `ARG`         | âŒ No                                    | Somente em tempo de construÃ§Ã£o; nÃ£o afeta a imagem final, a menos que seja usado posteriormente.              |
| `WORKDIR`     | âŒ No                                    | Altera o diretÃ³rio de trabalho; apenas metadados.                                                             |
| `USER`        | âŒ No                                    | Define o usuÃ¡rio; apenas metadados.                                                                           |
| `EXPOSE`      | âŒ No                                    | Declara porta(s) exposta(s); apenas metadados.                                                                |
| `ENTRYPOINT`  | âŒ No                                    | Define como o contÃªiner Ã© iniciado; configuraÃ§Ã£o de metadados.                                                |
| `CMD`         | âŒ No                                    | Comando ou argumentos padrÃ£o; apenas metadados.                                                               |
| `VOLUME`      | âœ… Sim / Parcial                         | Declara pontos de montagem; metadados + volumes em tempo de execuÃ§Ã£o; tem implicaÃ§Ãµes no sistema de arquivos. |
| `HEALTHCHECK` | âŒ No                                    | Define a configuraÃ§Ã£o da verificaÃ§Ã£o de integridade; armazenados como metadados.                              |
| `STOPSIGNAL`  | âŒ No                                    | Define sinal para parar o container; apenas metadados.                                                        |
| `SHELL`       | âŒ No                                    | Muda o shell para mais tarde`RUN`; apenas metadados.                                                          |
| `ONBUILD`     | âŒ No                                    | Gatilhos para compilaÃ§Ãµes futuras; apenas metadados.                                                          |

**ğŸ” Principais insights**

-   A maioria das instruÃ§Ãµes do Dockerfile**crie uma nova camada de imagem**- atÃ© mesmo alteraÃ§Ãµes de metadados (`CMD`,`EXPOSE`, etc.) sÃ£o armazenados como parte da configuraÃ§Ã£o final da imagem.
-   **Camadas pesadas**vÃªm de instruÃ§Ãµes que**modificar o sistema de arquivos**(`RUN`,`COPY`,`ADD`).
-   **Camadas leves/metadados**vÃªm de instruÃ§Ãµes como`ENV`,`CMD`,`LABEL`.
-   **`ARG`Ã© especial**: existe apenas no momento da construÃ§Ã£o e Ã© descartado na imagem final, a menos que seja usado em outras instruÃ§Ãµes.
-   Para minimizar o tamanho da imagem:
    -   Combine vÃ¡rios`RUN`comandos em um.
    -   Usar`.dockerignore`para evitar copiar arquivos desnecessÃ¡rios.
    -   InstruÃ§Ãµes de pedido para maximizar o Docker**construir eficiÃªncia de cache**.

* * *

#### ğŸ³ Dockerfile

##### ğŸ” O que Ã© um Dockerfile?

UM**Dockerfile**Ã© um**arquivo de texto declarativo**que contÃ©m uma sequÃªncia de**instruÃ§Ãµes de construÃ§Ã£o**para construir uma imagem Docker.

Cada instruÃ§Ã£o especifica como configurar a imagem: qual base usar, quais arquivos copiar, quais comandos executar, qual ambiente definir e como o contÃªiner resultante deve se comportar em tempo de execuÃ§Ã£o.

Ã‰ essencialmente o**receita**para construir imagens de contÃªiner imutÃ¡veis â€‹â€‹e reproduzÃ­veis.

ğŸ§© Principais caracterÃ­sticas

-   **Declarativo**: em vez de executar etapas manuais, vocÃª declara o estado desejado da imagem.
-   **Em camadas**: Cada instruÃ§Ã£o pode produzir uma camada de imagem, que permite armazenamento em cache, reutilizaÃ§Ã£o e distribuiÃ§Ã£o eficiente.
-   **PortÃ¡til**: Dockerfiles garantem consistÃªncia entre ambientes (desenvolvimento, preparaÃ§Ã£o, produÃ§Ã£o).
-   **CombinÃ¡vel**: com compilaÃ§Ãµes de vÃ¡rios estÃ¡gios, vocÃª pode encadear vÃ¡rios`FROM`declaraÃ§Ãµes para otimizar imagens menores e prontas para produÃ§Ã£o.

##### ğŸ› ï¸ InstruÃ§Ãµes bÃ¡sicas

Algumas das instruÃ§Ãµes mais comuns incluem:

-   `FROM`: especifica a imagem base.
-   `RUN`: executa comandos para instalar ou configurar software.
-   `COPY`/`ADD`: move arquivos do contexto de construÃ§Ã£o para a imagem.
-   `ENV`,`WORKDIR`,`USER`: define variÃ¡veis â€‹â€‹de ambiente, diretÃ³rios e contexto de execuÃ§Ã£o.
-   `CMD`/`ENTRYPOINT`: define comandos ou processos padrÃ£o quando o contÃªiner Ã© iniciado.
-   `EXPOSE`,`VOLUME`,`HEALTHCHECK`: configure rede, armazenamento persistente e monitoramento.

##### ğŸš€ Por que Ã© importante

-   **Reprodutibilidade**: Mesmo Dockerfile â†’ mesma imagem â†’ mesmo comportamento em todos os lugares.
-   **AutomaÃ§Ã£o**: permite que pipelines de CI/CD criem, testem e implantem contÃªineres automaticamente.
-   **OtimizaÃ§Ã£o**: Dockerfiles adequadamente estruturados minimizam o tamanho da imagem e aceleram as compilaÃ§Ãµes.
-   **Conformidade**: imagens padronizadas com Dockerfiles fixos simplificam auditoria, aplicaÃ§Ã£o de patches e governanÃ§a.

âœ… Resumindo:

UM**Dockerfile**Ã© o**planta**para imagens Docker â€” a base da entrega de aplicativos em contÃªineres.

**Exemplo de Dockerfile**

```dockerfile
# syntax=docker/dockerfile:1
FROM nginx:latest
COPY ./html /usr/share/nginx/html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

* * *

#### ğŸ§© Docker Compor

##### ğŸ“˜ ReferÃªncia do comando Docker Compose

Docker Compose Ã© uma ferramenta para definir e gerenciar aplicativos Docker de vÃ¡rios contÃªineres usando um arquivo YAML (`docker-compose.yml`).

Abaixo segue uma tabela estruturada dos principais comandos e suas finalidades.

**ğŸ“Š Tabela: Comandos Docker Compose**

| Comando                         | PropÃ³sito                                                                              | Exemplo                                                                  |
| ------------------------------- | -------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ |
| â–¶ï¸**`docker compose up`**       | Construir, (re)criar, iniciar e anexar a contÃªineres definidos em`docker-compose.yml`. | `docker compose up -d`                                                   |
| â¹ï¸**`docker compose down`**     | Pare e remova contÃªineres, redes, volumes e imagens criadas por`up`.                   | `docker compose down --volumes`                                          |
| ğŸ”„**`docker compose restart`**  | Reinicie os serviÃ§os em execuÃ§Ã£o.                                                      | `docker compose restart web`                                             |
| ğŸŸ¢**`docker compose start`**    | Inicie contÃªineres existentes sem recriÃ¡-los.                                          | `docker compose start db`                                                |
| ğŸ”´**`docker compose stop`**     | Pare de executar contÃªineres sem removÃª-los.                                           | `docker compose stop db`                                                 |
| ğŸ§¹**`docker compose rm`**       | Remova os contÃªineres de serviÃ§o parados.                                              | `docker compose rm -f`                                                   |
| ğŸ—ï¸**`docker compose build`**   | Crie ou recrie imagens de serviÃ§o.                                                     | `docker compose build web`                                               |
| ğŸ“¥**`docker compose pull`**     | Extraia imagens de serviÃ§o de um registro.                                             | `docker compose pull redis`                                              |
| ğŸ“¤**`docker compose push`**     | Envie imagens de serviÃ§o para um registro.                                             | `docker compose push api`                                                |
| ğŸ“„**`docker compose config`**   | Valide e visualize o arquivo Compose.                                                  | `docker compose config`                                                  |
| ğŸ“‹**`docker compose ps`**       | Listar contÃªineres gerenciados pelo Compose.                                           | `docker compose ps`                                                      |
| ğŸ“Š**`docker compose top`**      | Exibir processos em execuÃ§Ã£o de contÃªineres.                                           | `docker compose top`                                                     |
| ğŸ“œ**`docker compose logs`**     | Visualize logs de saÃ­da de serviÃ§os.                                                   | `docker compose logs -f api`                                             |
| ğŸ”**`docker compose exec`**     | Execute um comando em um contÃªiner de serviÃ§o em execuÃ§Ã£o.                             | `docker compose exec db psql -U postgres`                                |
| ğŸš**`docker compose run`**      | Execute comandos Ãºnicos em um novo contÃªiner.                                          | `docker compose run web sh`                                              |
| ğŸ”§**`docker compose override`** | Usar`-f`para especificar vÃ¡rios arquivos do Compose (substituiÃ§Ãµes).                   | `docker compose -f docker-compose.yml -f docker-compose.override.yml up` |
| ğŸŒ**Rede**                      | As redes sÃ£o criadas automaticamente; pode ser declarado explicitamente em YAML.       | `docker network ls`                                                      |
| ğŸ“¦**Volumes**                   | Gerenciar dados persistentes; pode ser declarado em YAML e usado em vÃ¡rios serviÃ§os.   | `docker volume ls`                                                       |

##### ğŸ”‘ Notas principais

-   **`up`contra`start`**:`up`constrÃ³i/recria contÃªineres,`start`executa apenas os existentes.
-   **`run`contra`exec`**:`run`lanÃ§a um_novo_recipiente,`exec`Ã© executado dentro de um existente.
-   **ValidaÃ§Ã£o de configuraÃ§Ã£o**: Sempre corra`docker compose config`para verificar se hÃ¡ erros de sintaxe.
-   **Modo de desconexÃ£o**: Usar`-d`para executar serviÃ§os em segundo plano.

##### **ğŸ“„`docker-compose.yml`**

```yaml
version: "3.9"  # Compose file format

services:
  web:
    image: nginx:latest
    container_name: my-nginx
    ports:
      - "8080:80"             # host:container
    volumes:
      - ./html:/usr/share/nginx/html:ro
    networks:
      - app-network

  api:
    build:
      context: ./api          # build from Dockerfile in ./api
      dockerfile: Dockerfile
    container_name: my-api
    environment:
      - NODE_ENV=production
      - API_KEY=${API_KEY}    # read from .env file
    depends_on:
      - db
    ports:
      - "3000:3000"
    networks:
      - app-network

  db:
    image: postgres:15
    container_name: my-postgres
    restart: always
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: secret
      POSTGRES_DB: appdb
    volumes:
      - db-data:/var/lib/postgresql/data
    networks:
      - app-network

volumes:
  db-data:

networks:
  app-network:
    driver: bridge

```

**ğŸ” ExplicaÃ§Ã£o**

-   **`services`**: Define contÃªineres (`web`,`api`,`db`) que compÃµem o aplicativo.
-   **`ports`**: mapeia portas de host para portas de contÃªiner (`8080:80`).
-   **`volumes`**:
-   Volume nomeado (`db-data`) para dados de banco de dados persistentes.
-   Montagem de ligaÃ§Ã£o (`./html:/usr/share/nginx/html`) para veicular conteÃºdo estÃ¡tico.
-   **`build`**: permite construir uma imagem personalizada a partir de um Dockerfile.
-   **`depends_on`**: Garante a ordem de inicializaÃ§Ã£o do serviÃ§o (`api`espera por`db`).
-   **`networks`**: Define uma rede virtual isolada para comunicaÃ§Ã£o.

**ğŸš€ Uso**

Iniciar no modo desanexado

```sh
docker compose up -d
docker compose logs -f api
docker compose down -v
```

#### Arquitetura Docker + containerd + shim + runc

![Docker shim architecture example](images/docker-shim.png)

##### ğŸ”¹ Componentes Principais

-   **Docker CLI / Docker Daemon (`dockerd`)**

    O`docker`O comando se comunica com o daemon Docker, que orquestra o ciclo de vida do contÃªiner, imagens, redes e volumes.
-   **contÃªiner**

    Um tempo de execuÃ§Ã£o de contÃªiner de alto nÃ­vel que gerencia todo o ciclo de vida do contÃªiner: extraÃ§Ã£o de imagens, gerenciamento de armazenamento, rede e execuÃ§Ã£o.
-   **calÃ§o de contÃªiner**

    -   Atua como o_processo pai_de cada recipiente uma vez`runc`fez o seu trabalho.
    -   MantÃ©m**stdin/stdout/stderr**streams abertos, mesmo se o Docker ou o containerd forem reiniciados (entÃ£o`docker logs`/`kubectl logs`ainda funciona).
    -   Coleta o cÃ³digo de saÃ­da do contÃªiner e o reporta ao gerente.
    -   Evita que os contÃªineres se tornem Ã³rfÃ£os se o daemon travar ou for reiniciado.
-   **runc**

    Um tempo de execuÃ§Ã£o de baixo nÃ­vel (compatÃ­vel com OCI) que cria contÃªineres usando namespaces e cgroups Linux.

    Depois de lanÃ§ar o contÃªiner,`runc`saÃ­das, e`containerd-shim`assume como o processo pai.

* * *

##### ğŸ”¹ Fluxo de execuÃ§Ã£o

1.  **UsuÃ¡rio**corre`docker run ...`â†’ o**Daemon Docker**Ã© chamado.
2.  **Daemon Docker**delegados para**contÃªiner**.
3.  **contÃªiner**gera**runc**, que configura o contÃªiner.
4.  Assim que o contÃªiner for iniciado,**SaÃ­das Runc**.
5.  **calÃ§o de contÃªiner**permanece como o**processo pai do contÃªiner**, lidando com cÃ³digos de registro e saÃ­da.

* * *

##### ğŸ”¹ BenefÃ­cios da camada de calÃ§o

-   **ResiliÃªncia**â†’ Os contÃªineres continuam funcionando mesmo se`dockerd`ou`containerd`travar ou reiniciar.
-   **Registro**â†’ MantÃ©m fluxos de log de contÃªiner para`docker logs`ou`kubectl logs`.
-   **Isolamento**â†’ Cada contÃªiner possui seu prÃ³prio calÃ§o, simplificando o gerenciamento do ciclo de vida.
-   **Conformidade com padrÃµes**â†’ Funciona com o**EspecificaÃ§Ã£o de tempo de execuÃ§Ã£o do OCI**, garantindo compatibilidade.

#### âš–ï¸ Docker x contÃªiner

| ğŸ”¹ Recurso/Componente | ğŸ³ Docker (dockerd)                                  | ğŸ‹ contÃªiner                                         |
| --------------------- | ---------------------------------------------------- | ---------------------------------------------------- |
| Escopo                | Plataforma completa (build, CLI, UI, Hub)            | Somente ambiente de execuÃ§Ã£o do contÃªiner principal  |
| API                   | API Docker de alto nÃ­vel                             | API CRI/tempo de execuÃ§Ã£o de baixo nÃ­vel             |
| ConstruÃ­do sobre      | Usa containerd internamente                          | Tempo de execuÃ§Ã£o independente                       |
| CaracterÃ­sticas       | Construir, Compor, Swarm, Hub, Desktop               | Ciclo de vida da imagem, pull/run, tempo de execuÃ§Ã£o |
| Casos de uso          | Fluxos de trabalho de desenvolvimento, testes locais | Kubernetes, tempos de execuÃ§Ã£o de produÃ§Ã£o           |
| Pegada                | Mais pesado e com mais ferramentas                   | Leve, eficiente                                      |
| Ecossistema           | Ferramentas avanÃ§adas para desenvolvedores           | Projeto CNCF, padrÃ£o do Kubernetes                   |

#### Armazenamento Docker

##### ğŸ§± Conceitos BÃ¡sicos

| ğŸ” Foco       | Detalhes                                                                                                                                                                                                 |
| ------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| UniÃ£o FS      | Camadas de imagem somente leitura + camada gravÃ¡vel do contÃªiner formam um sistema de arquivos de uniÃ£o; remover o contÃªiner elimina alteraÃ§Ãµes efÃªmeras.                                                |
| Raiz de dados | Os drivers de armazenamento persistem os dados em`/var/lib/docker/<driver>/`; inspecionar o driver ativo via`docker info --format "{{.Driver}}"`.                                                        |
| PersistÃªncia  | Mova dados com estado para**volumes**(persistente),**vincular montagens**(caminho do host) ou**montagens tmpfs**(na memÃ³ria, efÃªmero) para sobreviver Ã  recriaÃ§Ã£o do contÃªiner ou otimizar o desempenho. |

##### âš™ï¸ Drivers de armazenamento

| Motorista                        | Quando usar                                           | Notas                                                                              |
| -------------------------------- | ----------------------------------------------------- | ---------------------------------------------------------------------------------- |
| sobreposiÃ§Ã£o2                    | PadrÃ£o em kernels Linux modernos.                     | CÃ³pia na gravaÃ§Ã£o rÃ¡pida; o sistema de arquivos de backup deve suportar`d_type`.   |
| sobreposiÃ§Ã£o de fusÃ­veis         | ImplantaÃ§Ãµes sem raiz ou de namespace de usuÃ¡rio.     | Adiciona uma fina camada FUSE; permite fluxos de trabalho nÃ£o raiz.                |
| btrfs/zfs                        | Precisa de instantÃ¢neos nativos, cotas e compactaÃ§Ã£o. | ForneÃ§a pools dedicados e use ferramentas de plataforma para gerenciamento.        |
| devicemapper (lvm direto) / aufs | Apenas configuraÃ§Ãµes legadas.                         | Modo de manutenÃ§Ã£o; planejar migraÃ§Ãµes para overlay2.                              |
| filtro de janelas                | Imagens de contÃªiner do Windows.                      | Use LCOW/WSL 2 para expor overlay2 para cargas de trabalho Linux em hosts Windows. |

##### ğŸ§­ Selecionando o driver

-   Confirme os mÃ³dulos do kernel (`modprobe overlay`) e prÃ©-requisitos do sistema de arquivos antes de trocar de driver.
-   Combine os recursos do driver com as cargas de trabalho: muitas camadas pequenas favorecem`overlay2`; instantÃ¢neos em nÃ­vel de sistema de arquivos podem justificar`btrfs`ou`zfs`.
-   Atenha-se aos padrÃµes do provedor no Docker Desktop, EKS, GKE, etc., para permanecer dentro dos limites de suporte.
-   Manter`/var/lib/docker`em armazenamento confiÃ¡vel e de baixa latÃªncia â€“ drivers de cÃ³pia na gravaÃ§Ã£o amplificam discos lentos.

Para testar drivers de volume, use o script:[docker-storage-driver.sh](scripts/docker/docker-storage-driver.sh).

##### ğŸ“¦ Tipos de armazenamento Docker

**Volumes:**

-   Gerenciado pelo Docker, localizado fora da camada gravÃ¡vel do contÃªiner (`/var/lib/docker/volumes`).
-   Persistir apÃ³s a remoÃ§Ã£o do contÃªiner, pode ser compartilhado entre contÃªineres.
-   Usado para dados que devem sobreviver ao ciclo de vida do contÃªiner.
-   Exemplos:
    -   Criar volume:`docker volume create data`
    -   Usar volume:`docker run -v data:/app/data ...`

**Vincular montagens:**

-   Monte um diretÃ³rio/arquivo host diretamente no contÃªiner.
-   Ãštil para desenvolvimento, sincronizaÃ§Ã£o de cÃ³digo ou acesso a dados de host existentes.
-   Menos portÃ¡til (caminhos absolutos, permissÃµes de host).
-   Exemplos:
    -   `docker run -v /home/user/app:/app ...`
    -   `docker run --mount type=bind,source=/data,target=/app/data ...`

**Montagens Tmpfs:**

-   A montagem na memÃ³ria (RAM) nÃ£o persiste apÃ³s a parada ou reinicializaÃ§Ã£o do contÃªiner.
-   Ideal para dados temporÃ¡rios, caches ou informaÃ§Ãµes confidenciais.
-   Nada Ã© gravado no disco, desempenho mÃ¡ximo.
-   Exemplos:
    -   `docker run --mount type=tmpfs,target=/tmp/cache ...`
    -   `docker run --tmpfs /tmp/cache ...`

**Resumo rÃ¡pido:**

| Tipo              | PersistÃªncia | LocalizaÃ§Ã£o | Portabilidade | Uso tÃ­pico                            |
| ----------------- | ------------ | ----------- | ------------- | ------------------------------------- |
| Volume            | Sim          | Docker      | Alto          | Dados de aplicativos, bancos de dados |
| Vincular montagem | Opcional     | Hospedar    | Baixo         | Desenvolvimento, integraÃ§Ã£o           |
| Tmpfs             | No           | BATER       | Alto          | Cache, efÃªmero                        |

##### ğŸ› ï¸ Exemplos de uso de tipos de armazenamento

```sh
# Persistent volume
docker run -d --name pg -v pgdata:/var/lib/postgresql/data postgres:16

# Bind mount
docker run -d -v /home/user/html:/usr/share/nginx/html nginx:latest

# Tmpfs mount
docker run -d --mount type=tmpfs,target=/tmp nginx:latest
docker run -d --tmpfs /tmp nginx:latest
```

##### âœ… PrÃ¡ticas recomendadas de armazenamento Docker

-   Prefira volumes para dados persistentes e de backup.
-   Use tmpfs para dados confidenciais ou temporÃ¡rios.
-   Documente volumes e montagens em arquivos Compose/Stack.
-   Monitore o uso do disco com`docker system df`e limpar volumes Ã³rfÃ£os.
-   Verifique sempre o[documentaÃ§Ã£o oficial do Docker Storage](https://docs.docker.com/storage/)e[drivers de armazenamento](https://docs.docker.com/storage/storagedriver/select-storage-driver/).

Para testar volumes de armazenamento, use o script:[docker-storage-volumes.sh](scripts/docker/docker-storage-volumes.sh).

#### Rede Docker

##### ğŸŒ Conceitos BÃ¡sicos

| ğŸ” Foco                           | Detalhes                                                                                                                                                                                       |
| --------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Redes definidas pelo usuÃ¡rio      | Crie topologias isoladas (`docker network create`) e anexe/desconecte contÃªineres sob demanda com`docker network connect`ou o`--network`bandeira.                                              |
| Compartilhamento de pilha de rede | Por padrÃ£o, cada contÃªiner recebe seu prÃ³prio namespace;`--network container:<id>`reutiliza a pilha de outro contÃªiner, mas desativa sinalizadores como`--publish`,`--dns`, e`--hostname`.     |
| DNS incorporado                   | Docker injeta um servidor DNS interno por rede; nomes de contÃªineres e`--network-alias`as entradas sÃ£o resolvidas automaticamente e retornam ao resolvedor do host para pesquisas externas.    |
| Prioridade do gateway             | Quando um contÃªiner se junta a mÃºltiplas redes, o Docker seleciona a rota padrÃ£o atravÃ©s da rota mais alta.`--gw-priority`; substituir IPs por`--ip`/`--ip6`para endereÃ§amento determinÃ­stico. |

##### ğŸš Drivers padrÃ£o

| Motorista    | Usar quando                                                                            | Destaques                                                                                                                                  |
| ------------ | -------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| ponte        | Cargas de trabalho autÃ´nomas em um Ãºnico host precisam de trÃ¡fego leste-oeste simples. | PadrÃ£o`bridge`a rede vem com Docker; crie pontes definidas pelo usuÃ¡rio para DNS, isolamento e escopo por projeto.                         |
| hospedar     | VocÃª precisa de rede de host nativa com isolamento zero.                               | Compartilha a pilha do host; nÃ£o Ã© necessÃ¡rio mapeamento de porta; ideal para cargas de trabalho de alto rendimento ou dinÃ¢micas de porta. |
| sobreposiÃ§Ã£o | Os serviÃ§os devem abranger vÃ¡rios hosts Docker ou nÃ³s Swarm.                           | Suportado por VXLAN; requer o plano de controle Swarm (ou armazenamento KV externo) para coordenar redes entre motores.                    |
| macvlan      | Os contÃªineres devem aparecer como dispositivos fÃ­sicos na LAN.                        | Atribui pares MAC/IP exclusivos da interface pai; Ã³timo para integraÃ§Ãµes legadas ou segmentaÃ§Ã£o estrita de VLAN.                           |
| ipvlan       | Underlay restringe endereÃ§os MAC, mas permite roteamento L3.                           | Fornece IPv4/IPv6 por contÃªiner sem MACs extras; suporta L2 (`ipvlan -l2`) e modos L3 com marcaÃ§Ã£o de VLAN.                                |
| nenhum       | Ã‰ necessÃ¡rio isolamento total.                                                         | Remove totalmente a pilha de rede; somente fiaÃ§Ã£o manual de namespace (nÃ£o compatÃ­vel com serviÃ§os Swarm).                                 |
| Plug-ins     | Os drivers integrados ficam aquÃ©m das necessidades do SDN ou do fornecedor.            | Instale plug-ins de rede de terceiros do ecossistema Docker para integraÃ§Ã£o com estruturas especializadas.                                 |

##### ğŸ•¹ï¸ Trabalhando com Redes

-   Infraestrutura de escopo com pontes definidas pelo usuÃ¡rio para componentes de aplicativos, sobreposiÃ§Ãµes para pilhas distribuÃ­das ou macvlan/ipvlan estilo L2 para presenÃ§a direta de LAN.
-   Combine redes frontend/backend por contÃªiner; definir`--internal`em uma ponte para bloquear a saÃ­da e ainda permitir o trÃ¡fego de serviÃ§o para serviÃ§o.
-   Inspecione a conectividade com`docker network ls`,`docker network inspect`, e`docker exec <ctr> ip addr`para validar a fiaÃ§Ã£o do namespace.
-   Limpe redes nÃ£o utilizadas regularmente com`docker network prune`para evitar sub-redes obsoletas e configuraÃ§Ãµes Ã³rfÃ£s.

##### ğŸš¦ Portas e acessos publicados

-   As redes bridge mantÃªm as portas privadas, a menos que vocÃª as publique com`-p`/`--publish`; incluir`127.0.0.1:`(ou`[::1]:`para IPv6) para restringir a exposiÃ§Ã£o apenas ao host.
-   A publicaÃ§Ã£o de porta nÃ£o Ã© necessÃ¡ria para acesso de contÃªiner a contÃªiner na mesma ponte definida pelo usuÃ¡rio â€“ o DNS e o IP interno sÃ£o suficientes.
-   Os drivers Overlay e MacVlan ignoram o proxy da Ã¡rea do usuÃ¡rio; planeje firewalls upstream ou roteamento de acordo.

##### ğŸ” EndereÃ§amento e DNS

-   O IPv4 estÃ¡ habilitado por padrÃ£o em novas redes; adicionar`--ipv6`para provisionar intervalos de pilha dupla e usar`--ip`/`--ip6`para fixar endereÃ§os.
-   Cada operaÃ§Ã£o de junÃ§Ã£o pode fornecer identidades extras via`--alias`; Docker os anuncia por meio do serviÃ§o DNS incorporado.
-   Substitua os resolvedores por contÃªiner usando`--dns`,`--dns-search`, ou`--dns-option`ou importe hosts extras com`--add-host`.
-   Os contÃªineres herdam uma curadoria`/etc/hosts`; entradas em nÃ­vel de host nÃ£o sÃ£o sincronizadas automaticamente.

##### ğŸ› ï¸ Exemplos de uso de rede Docker

```sh
# Create dedicated frontend and backend bridges
docker network create --driver bridge frontend_net
docker network create --driver bridge --internal backend_net

# Launch services with deterministic addressing and aliases
docker run -d --name api \
  --network backend_net --ip 10.18.0.10 \
  --network-alias api.internal \
  ghcr.io/example/api:latest

docker run -d --name web \
  --network frontend_net \
  --network backend_net --alias web-backend \
  -p 443:8443 \
  ghcr.io/example/web:latest

# Attach a troubleshooting container temporarily
docker run -it --rm \
  --network container:web \
  alpine:latest sh
```

##### âœ… Melhores prÃ¡ticas da rede Docker

-   Modele os limites da rede antecipadamente; documente quais contÃªineres compartilham pontes, sobreposiÃ§Ãµes ou segmentos macvlan.
-   Usar`--internal`ou firewalls para bloquear saÃ­das nÃ£o intencionais e preferir o isolamento no nÃ­vel da rede em vez da publicaÃ§Ã£o de portas ad-hoc.
-   Ao misturar drivers, verifique as rotas padrÃ£o (`ip route`) para garantir que o gateway correto ganhe o`--gw-priority`.
-   Monitore conflitos de alocaÃ§Ã£o de sub-redes quando vÃ¡rios hosts criam redes; definido explicitamente`--subnet`/`--gateway`para CIDRs previsÃ­veis.
-   Verifique os documentos oficiais para atualizaÃ§Ãµes:[VisÃ£o geral da rede](https://docs.docker.com/network/)e[Drivers de rede](https://docs.docker.com/engine/network/drivers/).

Para testar o script de uso da rede docker:[docker-network.sh](scripts/docker/docker-network.sh).

#### ğŸ› ï¸ 352,3 comandos importantes

##### ğŸ³ janela de encaixe

```sh
############ FILES ############
/var/lib/docker
/etc/docker/daemon.json

############ DAEMON ############
# get version
docker --version

# docker infos
docker info

############ MANAGE IMAGES ############
# pull image from docker hub
docker pull nginx:latest

# list images
docker image ls
docker images
docker images -a
docker images --format "{{.Repository}}: {{.Tag}} {{.Size}}"

# docker image inspect
docker image inspect nginx:latest
docker inspect nginx:latest
docker inspect --format '{{.Id}}' nginx:latest
docker image inspect --format "{{json .RootFS.Layers}}" acme/my-base-image:1.0

# remove image
docker image rm nginx:latest
docker rmi nginx:latest
docker rmi -f nginx:latest
docker image prune -a

# docker history
docker history nginx:latest

############ MANAGE CONTAINERS ############

# list containers running
docker container ls
docker ps

# list all containers
docker container ls -a
docker ps -a

# list containers id
docker container ls -q

# list last created container
docker container ls -l

# list containers with size
docker ps -s
docker ps --size --format "table {{.ID}}\t{{.Image}}\t{{.Names}}\t{{.Size}}"

# create container
docker container run hello-world

# create container as daemon
docker container run -d --name my-nginx -p 8080:80 nginx:latest

# create container and run interactively
docker container run -it ubuntu bash

# docker container port
docker container port my-nginx

# create container and expose port 80 to host port 8080
docker container run -d --name my-nginx -p 8080:80 nginx:latest

# create container and publish all exposed ports to random ports
docker container run -d --name my-nginx -P nginx:latest

# create container and expose tcp port 8080 and udp port 8080 to host
docker container run -d --name my-nginx -p 8080:80/tcp -p 8080:80/udp nginx:latest

# create a container and expose port 8888
docker container run -d --name my-nginx -p 9082:80 --expose 8888 nginx:latest

# create a container and define hostname, dns
docker container run -dit --name ubuntu --dns=8.8.8.8 --dns=1.1.1.1 --hostname ubuntu ubuntu

# create container in detached mode
docker container run -d -it --name alpine alpine

# pause container
docker container pause <container_id|name>

# unpause container
docker container unpause <container_id|name>

# stop container
docker container stop <container_id|name>

# start container
docker container start <container_id|name>

# remove container
docker container rm <container_id|name>

# remove container force
docker container rm -f <container_id|name>

# prune all stopped containers
docker container prune

# remove all containers
docker container rm -f $(docker container ps -a -q)

# inspect container
docker container inspect <container_id|name>

# get PID of container
docker container inspect --format '{{.State.Pid}}' <container_id|name>

# get ID of container
docker container inspect --format '{{.Id}}' <container_id|name>
docker container inspect --format '{{.Id}}' <container_id|name>

# execute command in container
docker container exec -it <container_id|name> bash
docker container exec -it <container_id|name> ls /
docker container exec -it <container_id|name> sh -c "echo 'Hello from container'"

# copy file to container
docker container cp /etc/hosts <container_id|name>:/etc/hosts

# copy file from container
docker container cp <container_id|name>:/etc/hosts /tmp/container-hosts

############ MANAGE STORAGE #############

# Docker Storage Files
/var/lib/docker/overlay/
/var/lib/docker/containers/
/var/lib/docker/volumes/

# list volumes
docker volume ls

# create volume
docker volume create my-volume

# inspect volume
docker volume inspect my-volume

# remove volume
docker volume rm my-volume

# prune all unused volumes
docker volume prune

# create container with bind mount
docker container run -d --name my-nginx -p 8080:80 --mount type=bind,source=/home/vagrant/html,target=/usr/share/nginx/html nginx:latest
docker container run -d --name my-nginx -p 8080:80 --volume /home/vagrant/html:/usr/share/nginx/html nginx:latest
docker container run -d --name my-nginx -p 8080:80 -v /home/vagrant/html:/usr/share/nginx/html nginx:latest
docker container run -d --name my-nginx -p 8080:80 -v /home/vagrant/html:/usr/share/nginx/html:ro nginx:latest

# create container with volume
docker container run -d --name my-nginx -p 8080:80 --mount type=volume,source=my-volume,target=/usr/share/nginx/html nginx:latest
docker container run -d --name my-nginx -p 8080:80 --volume my-volume:/usr/share/nginx/html nginx:latest

# create a container with volume-from another container
docker container run -d --name my-nginx2 -p 8086:80 --volumes-from my-nginx1 nginx:latest

# create container with tmpfs mount
docker container run -d --name my-nginx -p 8080:80 --mount type=tmpfs,target=/usr/share/nginx/html nginx:latest
docker container run -d --name my-nginx -p 8080:80 --tmpfs /usr/share/nginx/html nginx:latest

# remove volume
docker volume rm my-volume

# remove volumes not used by any containers
docker volume prune

# remove all volumes
docker volume rm $(docker volume ls -q)

########### MANAGE LOGS ############

# view container logs
docker container logs <container_id|name>

# follow container logs
docker container logs -f <container_id|name>

# docker system events
docker system events --since "2h"
docker system events --since "20h" --filter 'container=<container_id|name>'
docker system events --since "20h" --filter type=container  --filter 'event=start' --filter 'event=stop'

# docker stats
docker container stats
docker container stats <container_id|name>

# docker top
docker container top <container_id|name>

########### DOCKER NETWORKING ###########

# list networks
docker network ls

# inspect network
docker network inspect bridge
docker network inspect --format '{{json .Containers}}' bridge | jq

# create network
docker network create my-bridge

# create network with specific driver
docker network create --driver bridge my-bridge

# create network with specific subnet
docker network create --subnet 192.168.1.0/24 my-bridge

# remove network
docker network rm my-bridge

# prune all unused networks
docker network prune

# connect container to network
docker network connect my-bridge <container_id|name>

# create a network and define: subnet,gateway,bridge name
docker network create \
  --driver bridge \
  --subnet 192.168.3.0/24 \
  --gateway 192.168.3.1 \
  --opt "com.docker.network.bridge.name"="br-mybridge" \
  my-bridge3

# create a container and connect it to a specific network
docker container run -d --name my-nginx --network my-bridge3 -p

# disconnect container from network
docker network disconnect my-bridge <container_id|name>

# create a network with specific options
docker network create \
  --driver bridge \
  --opt com.docker.network.bridge.enable_icc=false \
  --opt com.docker.network.bridge.enable_ip_masquerade=true \
  --opt com.docker.network.bridge.host_binding_ipv4="192.168.1.1" \
  my-bridge

############ OTHERS COMMANDS ############

# inspect namespaces
ls -l /proc/<PID>/ns
sudo lsns -p <PID>
ps -o pid,ppid,cmd,netns,mntns,pidns,utsns <PID>

# inspect cgroups
lscgroup | grep <PID> # cgroup v1
cat /proc/<PID>/cgroup # cgroup v2
ls -l /sys/fs/cgroup/system.slice/docker-<FULL_ID_CONTAINER>.scope
cat /sys/fs/cgroup/system.slice/docker-<FULL_ID_CONTAINER>.scope/cgroup.procs
```

<p align="right">(<a href="#topic-352.3">back to sub topic 352.3</a>)</p>
<p align="right">(<a href="#topic-352">back to topic 352</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-352.4"></a>

### ğŸ—‚ï¸ Plataformas de orquestraÃ§Ã£o de contÃªineres 352,4

**Peso:**3

**DescriÃ§Ã£o:**Os candidatos devem compreender a importÃ¢ncia da orquestraÃ§Ã£o de contÃªineres e os conceitos-chave que Docker Swarm e Kubernetes fornecem para implementar a orquestraÃ§Ã£o de contÃªineres.

**Principais Ã¡reas de conhecimento:**

-   Entenda a relevÃ¢ncia da orquestraÃ§Ã£o de contÃªineres
-   Entenda os principais conceitos do Docker Compose e do Docker Swarm
-   Compreenda os principais conceitos de Kubernetes e Helm
-   ConscientizaÃ§Ã£o sobre OpenShift, Rancher e Mesosphere DC/OS

<p align="right">(<a href="#topic-352.4">back to sub topic 352.4</a>)</p>
<p align="right">(<a href="#topic-352">back to topic 352</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-353"></a>

## â˜ï¸ TÃ³pico 353: ImplantaÃ§Ã£o e provisionamento de VM

* * *

<a name="topic-353.1"></a>

### â˜ï¸ Ferramentas de gerenciamento de nuvem 353.1

**Peso:**2

**DescriÃ§Ã£o:**Os candidatos devem compreender as ofertas comuns em nuvens pÃºblicas e ter conhecimento bÃ¡sico dos recursos das ferramentas de gerenciamento de nuvem comumente disponÃ­veis.

**Principais Ã¡reas de conhecimento:**

-   Entenda as ofertas comuns em nuvens pÃºblicas
-   Conhecimento bÃ¡sico de recursos do OpenStack
-   Conhecimento bÃ¡sico de recursos do Terraform
-   ConscientizaÃ§Ã£o sobre CloudStack, Eucalyptus e OpenNebula

#### ğŸ“‹ 353,1 Objetos Citados

```sh
IaaS, PaaS, SaaS
OpenStack
Terraform
```

#### ğŸ› ï¸ 353.1 Comandos importantes

##### ğŸ“ foo

```sh
# examples
```

<p align="right">(<a href="#topic-353.1">back to sub topic 353.1</a>)</p>
<p align="right">(<a href="#topic-353">back to topic 353</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-353.2"></a>

### ğŸ“¦ Empacotador 353,2

**Peso:**2

**DescriÃ§Ã£o:**Os candidatos devem ser capazes de usar o Packer para criar imagens de sistema. Isso inclui a execuÃ§Ã£o do Packer em vÃ¡rios ambientes de nuvem pÃºblica e privada, bem como a construÃ§Ã£o de imagens de contÃªiner para LXC/LXD.

**Principais Ã¡reas de conhecimento:**

-   Entenda a funcionalidade e os recursos do Packer
-   Criar e manter arquivos de modelo
-   Crie imagens a partir de arquivos de modelo usando diferentes construtores

#### ğŸ“‹ 353,2 objetos citados

```sh
packer
```

#### ğŸ› ï¸ 353,2 comandos importantes

##### ğŸ“¦ empacotador

```sh
# examples
```

<p align="right">(<a href="#topic-353.2">back to sub topic 353.2</a>)</p>
<p align="right">(<a href="#topic 353">back to topic 353</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-353.3"></a>

### â˜ï¸ 353,3 nuvem de inicializaÃ§Ã£o

**Peso:**3

**DescriÃ§Ã£o:**Os candidatos devem ser capazes de usar o cloud-init para configurar mÃ¡quinas virtuais criadas a partir de imagens padronizadas. Isso inclui ajustar as mÃ¡quinas virtuais para corresponder aos recursos de hardware disponÃ­veis, especificamente espaÃ§o em disco e volumes.
AlÃ©m disso, os candidatos devem ser capazes de configurar instÃ¢ncias para permitir logins SSH seguros e instalar um conjunto especÃ­fico de pacotes de software.
AlÃ©m disso, os candidatos devem ser capazes de criar novas imagens de sistema com suporte para cloud-init.

**Principais Ã¡reas de conhecimento:**

-   Compreender os recursos e conceitos do cloud-init, incluindo dados do usuÃ¡rio, inicializaÃ§Ã£o e configuraÃ§Ã£o do cloud-init
-   Use cloud-init para criar, redimensionar e montar sistemas de arquivos, configurar contas de usuÃ¡rio, incluindo credenciais de login, como chaves SSH e instalar pacotes de software do repositÃ³rio da distribuiÃ§Ã£o
-   Integre o cloud-init Ã s imagens do sistema
-   Use a fonte de dados da unidade de configuraÃ§Ã£o para teste

#### ğŸ“‹ 353,3 Objetos Citados

```sh
cloud-init
user-data
/var/lib/cloud/
```

#### ğŸ› ï¸ 353,3 comandos importantes

##### ğŸ“ nuvem-init

```sh
# examples
```

<p align="right">(<a href="#topic-353.3">back to sub topic 353.3</a>)</p>
<p align="right">(<a href="#topic 353">back to topic 353</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-353.4"></a>

### ğŸ“¦ 353,4 Vagabundo

**Peso:**3

**DescriÃ§Ã£o:**O candidato deverÃ¡ ser capaz de usar o Vagrant para gerenciar mÃ¡quinas virtuais, incluindo o provisionamento da mÃ¡quina virtual.

**Principais Ã¡reas de conhecimento:**

-   Entenda a arquitetura e os conceitos do Vagrant, incluindo armazenamento e rede
-   Recuperar e usar caixas do Atlas
-   Crie e execute Vagrantfiles
-   Acesse mÃ¡quinas virtuais Vagrant
-   Compartilhe e sincronize pastas entre uma mÃ¡quina virtual Vagrant e o sistema host
-   Entenda o provisionamento do Vagrant, ou seja, provisionadores de arquivos e Shell
-   Entenda a configuraÃ§Ã£o de vÃ¡rias mÃ¡quinas

#### ğŸ“‹ 353,4 objetos citados

```sh
vagrant
Vagrantfile
```

#### ğŸ› ï¸ 353,4 comandos importantes

##### ğŸ“¦ vagabundo

```sh
# examples
```

<p align="right">(<a href="#topic-353.4">back to sub topic 353.4</a>)</p>
<p align="right">(<a href="#topic 353">back to topic 353</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

## ğŸ¤ Contribuindo

As contribuiÃ§Ãµes sÃ£o o que tornam a comunidade de cÃ³digo aberto um lugar incrÃ­vel para
aprender, inspirar e criar. Qualquer contribuiÃ§Ã£o que vocÃª fizer serÃ¡**muito apreciado**.

Se vocÃª tiver uma sugestÃ£o que possa melhorar isso, bifurque o repositÃ³rio e
crie uma solicitaÃ§Ã£o pull. VocÃª tambÃ©m pode simplesmente abrir um problema com a tag â€œaprimoramentoâ€.
NÃ£o se esqueÃ§a de dar uma estrela ao projeto! Obrigado novamente!

1.  Bifurque o projeto
2.  Crie sua ramificaÃ§Ã£o de recursos (`git checkout -b feature/AmazingFeature`)
3.  Confirme suas alteraÃ§Ãµes (`git commit -m 'Add some AmazingFeature'`)
4.  Empurre para a filial (`git push origin feature/AmazingFeature`)
5.  Abra uma solicitaÃ§Ã£o pull

* * *

## ğŸ“„ LicenÃ§a

-   Este projeto estÃ¡ licenciado sob a licenÃ§a MIT \* consulte o arquivo LICENSE.md para obter detalhes

* * *

## ğŸ“¬ Contato

Marcos Silvestrini[marcos.silvestrini@gmail.com](mailto:marcos.silvestrini@gmail.com)[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/mrsilvestrini.svg?style=social&label=Follow%20%40mrsilvestrini)](https://twitter.com/mrsilvestrini)

Link do projeto:<https://github.com/marcossilvestrini/learning-lpic-3-305-300>

<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

## ğŸ™ Agradecimentos

-   [Richard Stallman'Ã©](http://www.stallman.org/)

-   [GNU](<>)

    -   [Perguntas frequentes sobre GNU/Linux por Richard Stallman](https://www.gnu.org/gnu/gnu-linux-faq.html)
    -   [GNU](https://www.gnu.org/)
    -   [Sistema operacional GNU](https://www.gnu.org/gnu/thegnuproject.html)
    -   [Compilador GCC](https://gcc.gnu.org/wiki/History)
    -   [GNU alcatrÃ£o](https://www.gnu.org/software/tar/)
    -   [GNU Make](https://www.gnu.org/software/make/)
    -   [GNU Emacs](https://en.wikipedia.org/wiki/Emacs)
    -   [Pacotes GNU](https://www.gnu.org/software/)
    -   [ColeÃ§Ã£o GNU/Linux](https://directory.fsf.org/wiki/Collection:GNU/Linux)
    -   [Carregador de inicializaÃ§Ã£o GNU Grub](https://www.gnu.org/software/grub/)
    -   [GNU Hurd](https://www.gnu.org/software/hurd/hurd/what_is_the_gnu_hurd.html)

-   [NÃºcleo](<>)

    -   [NÃºcleo](https://www.kernel.org/)
    -   [PÃ¡ginas de manual do kernel Linux](https://www.kernel.org/doc/man-pages/)
    -   [Compile seu kernel](https://wiki.linuxquestions.org/wiki/How_to_build_and_install_your_own_Linux_kernel)

-   [Base PadrÃ£o Linux](<>)

    -   [Base PadrÃ£o Linux](https://en.wikipedia.org/wiki/Linux_Standard_Base)
    -   [PadrÃ£o de hierarquia do sistema de arquivos](https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard)
    -   [Estrutura de hierarquia de arquivos](https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.pdf)

-   [Software Livre](<>)

    -   [FSF](https://www.fsf.org)
    -   [DiretÃ³rio de software gratuito](https://directory.fsf.org/wiki/Free_Software_Directory:Free_software_replacements)

-   [LicenÃ§a](<>)

    -   [Software Livre](https://www.gnu.org/philosophy/free-sw.html)
    -   [Copyleft](https://www.gnu.org/licenses/copyleft.en.html)
    -   [GPL](https://www.gnu.org/licenses/quick-guide-gplv3.html)
    -   [LicenÃ§a PÃºblica Geral Menor GNU](https://www.gnu.org/licenses/lgpl-3.0.html)
    -   [BSD](https://opensource.org/licenses/BSD-3-Clause)
    -   [Iniciativa de cÃ³digo aberto](https://opensource.org/)
    -   [Creative Commons](https://creativecommons.org/)
    -   [LicenÃ§a LTS](https://en.wikipedia.org/wiki/Long-term_support)

-   [DistribuiÃ§Ãµes](<>)

    -   [Diretrizes de Software Livre Debian](https://www.debian.org/social_contract#guidelines)
    -   [Listar distribuiÃ§Ã£o Linux](https://en.wikipedia.org/wiki/List_of_Linux_distributions)
    -   [Distrowatch](https://distrowatch.com/)
    -   [ComparaÃ§Ã£o de distribuiÃ§Ãµes Linux](https://en.wikipedia.org/wiki/Comparison_of_Linux_distributions)

-   [Ambientes de Ã¡rea de trabalho](<>)

    -   [OrganizaÃ§Ã£o X11](https://www.x.org/wiki/)
    -   [Wayland](https://wayland.freedesktop.org/)
    -   [GNU GNOME](https://www.gnu.org/press/gnome-1.0.html)
    -   [GNOMO](https://www.gnome.org/)
    -   [XFCE](https://xfce.org/)
    -   [Onde o plasma](https://kde.org/plasma-desktop/)
    -   [Harmonia](https://en.wikipedia.org/wiki/Harmony_(toolkit))

-   [Protocolos](<>)

    -   [HTTP](<>)
        -   [W3Techs](https://w3techs.com/)
        -   [Apache](https://www.apache.org/)
        -   [Diretivas Apache](https://httpd.apache.org/docs/2.4/mod/directives.html)
        -   [CÃ³digos de status HTTP](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)
        -   [Cifras fortes para Apache, nginx e Lighttpd](https://cipherlist.eu/)
        -   [Tutoriais SSL](https://www.golinuxcloud.com/blog/)
        -   [ConfiguraÃ§Ã£o SSL Mozilla](https://ssl-config.mozilla.org/)
    -   [xRDP](https://bytexd.com/xrdp-centos/)
    -   [NTP](https://www.ntppool.org/en/)

-   [DNS](<>)

    -   [Vincular](https://www.isc.org/bind/)
    -   [Vincular registro](https://www.zytrax.com/books/dns/ch7/logging.html)
    -   [Lista de tipos de registro DNS](https://en.wikipedia.org/wiki/List_of_DNS_record_types)
    -   [Lista de tipos de registro DNS](https://en.wikipedia.org/wiki/List_of_DNS_record_types)

-   [Gerenciador de pacotes](<>)

    -   [Baixar pacotes](https://pkgs.org/)
    -   [Instalar pacotes](https://installati.one/)
    -   [Guia de instalaÃ§Ã£o de pacotes](https://installati.one/)

-   [Script de shell](<>)

    -   [Bourne Novamente Concha](https://www.gnu.org/software/bash/manual/)
    -   [Shebang](https://bash.cyberciti.biz/guide/Shebang)
    -   [VariÃ¡veis â€‹â€‹de ambiente](https://linuxize.com/post/how-to-set-and-list-environment-variables-in-linux/)
    -   [GlobulaÃ§Ã£o GNU](https://man7.org/linux/man-pages/man7/glob.7.html)
    -   [GlobulaÃ§Ã£o](https://linuxhint.com/bash_globbing_tutorial/)
    -   [Citando](https://www.gnu.org/software/bash/manual/html_node/Quoting.html)
    -   [ExpressÃµes Regulares](https://www.gnu.org/software/grep/manual/html_node/Regular-Expressions.html)
    -   [Comando nÃ£o encontrado](https://command-not-found.com/)
    -   [Gerador de prompt Bash](https://bash-prompt-generator.org/)
    -   [Explique](https://explainshell.com/)
    -   [Tutorial Vim](https://www.openvim.com/)
    -   [Tutorial de script de shell do Linux](https://bash.cyberciti.biz/guide/Main_Page)
    -   [Exemplos de comandos](https://www.geeksforgeeks.org/)

-   [Outras ferramentas](<>)

    -   [Bugzila](https://bugzilla.kernel.org/)
    -   [Emblemas do GitHub](https://github.com/alexandresanlim/Badges4-README.md-Profile)

-   [DefiniÃ§Ãµes de virtualizaÃ§Ã£o](<>)

    -   [ChapÃ©u Vermelho](https://www.redhat.com/pt-br/topics/virtualization/what-is-virtualization/)
    -   [AWS](https://aws.amazon.com/pt/what-is/virtualization/)
    -   [IBM](https://www.ibm.com/topics/virtualization)
    -   [OpenSource.com](https://opensource.com/resources/virtualization)

-   [Xen](<>)

    -   [XenServer](https://www.xenserver.com/)
    -   [Wiki XenProject](https://wiki.xenproject.org/wiki/Main_Page)
    -   [Interfaces de rede](https://wiki.xenproject.org/wiki/Xen_Networking#Virtual_Network_Interfaces)
    -   [Ferramentas Xen](https://xen-tools.org/software/)
    -   [Blog LPI: VirtualizaÃ§Ã£o Xen e ComputaÃ§Ã£o em Nuvem #01: IntroduÃ§Ã£o](https://www.lpi.org/pt-br/blog/2020/10/01/xen-virtualization-and-cloud-computing-01-introduction/)
    -   [Blog do LPI: VirtualizaÃ§Ã£o Xen e ComputaÃ§Ã£o em Nuvem #02: Como o Xen faz o trabalho](https://www.lpi.org/blog/2020/10/08/xen-virtualization-and-cloud-computing-02-how-xen-does-job/)
    -   [Blog LPI: VirtualizaÃ§Ã£o Xen e computaÃ§Ã£o em nuvem #04: contÃªineres, OpenStack e outras plataformas relacionadas](https://www.lpi.org/pt-br/blog/2020/10/22/xen-virtualization-and-cloud-computing-04-containers-openstack-and-other-related/)
    -   [VirtualizaÃ§Ã£o Xen e ComputaÃ§Ã£o em Nuvem #05: O Projeto Xen, Unikernels e o Futuro](https://www.lpi.org/pt-br/blog/2020/10/29/xen-virtualization-and-cloud-computing-05-xen-project-unikernels-and-future/)
    -   [Guia para iniciantes do projeto Xen](https://wiki.xenproject.org/wiki/Xen_Project_Beginners_Guide#Installing_the_Xen_Project_Software)
    -   [Livro maluco](https://wiki.xenproject.org/wiki/Book/HelloXenProject/0-Contents)

-   [Unicernel](https://www.lpi.org/blog/2020/10/29/xen-virtualization-and-cloud-computing-05-xen-project-unikernels-and-future/)

    -   [ForÃ§a Ãºnica](https://github.com/unikraft/unikraft)
    -   [Mirage OS](https://mirage.io/docs/hello-world)
    -   [Ruim](https://galois.com/project/halvm/)
    -   [Exclusivo](https://github.com/solo-io/unik/blob/master/docs/providers/virtualbox.md)

-   [KVM](<>)

    -   [Documento Oficial](https://linux-kvm.org/page/Main_Page)
    -   [KVM (mÃ¡quinas virtuais de kernel da RedHat)](https://www.redhat.com/pt-br/topics/virtualization/what-is-KVM)
    -   [Ferramentas de gerenciamento KVM](https://www.linux-kvm.org/page/Management_Tools)
    -   [Rede KVM](https://www.linux-kvm.org/page/Networking)

-   [QEMU](<>)

    -   [Documento Oficial](https://www.qemu.org/)
    -   [Baixar imagens osboxes](https://www.osboxes.org/)
    -   [Baixar imagens linuximages](https://www.linuxvmimages.com/)
    -   [Urbano](https://en.wikibooks.org/wiki/QEMU/Devices/Virtio)
    -   [Agente Convidado](https://wiki.qemu.org/Features/GuestAgent)

-   [Libvirt](<>)

    -   [Documento Oficial](https://libvirt.org/)
    -   [AtivaÃ§Ã£o do soquete do sistema](https://libvirt.org/manpages/libvirtd.html#system-socket-activation)
    -   [ConexÃµes](https://libvirt.org/uri.html)
    -   [Armazenar](https://libvirt.org/storage.html)
    -   [Rede](https://wiki.libvirt.org/Networking.html)
    -   [Rede Virtual](https://wiki.libvirt.org/VirtualNetworking.html)
    -   [virtlogd](https://libvirt.org/manpages/virtlogd.html)
    -   [virtlockd](https://libvirt.org/manpages/virtlockd.html)
    -   [gerenciador de virt](https://virt-manager.org/)

-   [Gerenciamento de disco](<>)

    -   [Imagens de disco](https://qemu-project.gitlab.io/qemu/system/images.html)
    -   [copiar na gravaÃ§Ã£o](https://sempreupdate.com.br/linux/tutoriais/sistema-de-arquivos-copy-on-write-saiba-o-que-e-e-quais-as-vantagens-e-desvantagens/)
    -   [RAM x QCOW2](https://docs.redhat.com/en/documentation/red_hat_virtualization/4.3/html/technical_reference/qcow2)
    -   [Libguestfs](https://libguestfs.org/)

-   [recipientes](<>)

    -   [ContÃªineres AWS Doc](https://aws.amazon.com/pt/containers/)
    -   [ContÃªineres de documentos do GCP](https://cloud.google.com/learn/what-are-containers?hl=pt-br)
    -   [ContÃªiner IBM Doc](https://www.ibm.com/br-pt/topics/containers)
    -   [ContÃªineres do Red Hat Docs](https://www.redhat.com/en/topics/containers/whats-a-linux-container)
    -   [EspaÃ§os para nome](https://manpages.ubuntu.com/manpages/noble/man7/namespaces.7.html)
    -   [Namespaces mais importantes](https://www.redhat.com/en/blog/7-linux-namespaces)
    -   [Aulas de Cgroups](https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/6/html/resource_management_guide/ch01)
    -   [Grupos humanos](https://manpages.ubuntu.com/manpages/noble/man7/cgroups.7.html)
    -   [Documento de capacidades](https://linux-audit.com/kernel/capabilities/linux-capabilities-101/)
    -   [Capacidades do homem](https://manpages.ubuntu.com/manpages/noble/man7/capabilities.7.html)
    -   [Perfis Seccomp no Docker](https://docs.docker.com/engine/security/seccomp/)
    -   [Perfis AppArmor no Docker](https://docs.docker.com/engine/security/apparmor/)
    -   [SElinux](https://pt.wikipedia.org/wiki/SELinux)
    -   [Comparador Apparmor SElinux](https://www.redhat.com/en/blog/apparmor-selinux-isolation)
    -   [runc](https://www.docker.com/blog/runc/)
    -   [Executar GitHub](https://github.com/opencontainers/runc)
    -   [OCI](https://opencontainers.org/about/overview/)
    -   [IRC](https://kubernetes.io/docs/concepts/architecture/cri/)
    -   [CRI-O](https://cri-o.io/)
    -   [contÃªiner](https://containerd.io/)
    -   [Subman](https://www.redhat.com/pt-br/topics/containers/what-is-podman)
    -   [Escopo](https://www.redhat.com/pt-br/topics/containers/what-is-skopeo)
    -   [Construir](https://www.redhat.com/en/topics/containers/what-is-buildah)
    -   [OpenVZ](https://openvz.org/)
    -   [Crun](https://www.redhat.com/en/blog/introduction-crun)
    -   [dizer](https://katacontainers.io/)

-   [LXC - contÃªineres Linux](<>)

    -   [LXC](https://linuxcontainers.org/lxc/introduction/)
    -   [Imagens de contÃªiner Linux](https://images.linuxcontainers.org/)

-   [LXD](<>)

    -   [LXD canÃ´nico](https://canonical.com/lxd)
    -   [Github CanÃ´nico LXD](https://github.com/canonical/lxd)
    -   [DocumentaÃ§Ã£o LXD](https://linuxcontainers.org/lxd/docs/master/)
    -   [InstalaÃ§Ã£o LXD](https://documentation.ubuntu.com/lxd/stable-4.0/instances/)
    -   [Imagens LDX](https://images.lxd.canonical.com/)
    -   [Armazenamento LXD](https://documentation.ubuntu.com/lxd/stable-4.0/storage/)
    -   [Pools, volumes e buckets de armazenamento LXD](https://documentation.ubuntu.com/lxd/stable-5.21/explanation/storage/#exp-storage)
    -   [Tipos de rede LXD](https://documentation.ubuntu.com/lxd/latest/explanation/networks/)
    -   [ParÃ¢metros de rede LXD](https://documentation.ubuntu.com/lxd/stable-4.0/networks/)
    -   [ConfiguraÃ§Ã£o de rede LXD](https://documentation.ubuntu.com/lxd/latest/howto/network_create/)
    -   [Perfis LXD](https://documentation.ubuntu.com/lxd/to/latest/profiles/)
    -   [InstÃ¢ncias LXD](https://documentation.ubuntu.com/lxd/en/stable-4.0/instances/)

-   [Docker](https://www.docker.com/)

    -   [VisÃ£o geral do Docker](https://docs.docker.com/get-started/overview/)
    -   [ContÃªiner x Docker](https://www.docker.com/blog/containerd-vs-docker/)
    -   [Instalar](https://docs.docker.com/engine/install/)
    -   [ConfiguraÃ§Ã£o do Daemon](https://docs.docker.com/engine/daemon/)
    -   [Imagens Docker](https://docs.docker.com/engine/storage/drivers/#images-and-layers)
    -   [DockerHub](https://hub.docker.com/)
    -   [Armazenamento no Docker](https://docs.docker.com/storage/)
    -   [Volumes](https://docs.docker.com/storage/volumes/)
    -   [Vincular montagens](https://docs.docker.com/storage/bind-mounts/)
    -   [Drivers de armazenamento](https://docs.docker.com/storage/storagedriver/select-storage-driver/)
    -   [ContÃªineres de teste](https://testcontainers.com/)
    -   [Rede Docker](https://docs.docker.com/network/)
    -   [Drivers de rede Docker](https://docs.docker.com/network/drivers)

-   [Documentos Openstack](<>)

    -   [ChapÃ©u Vermelho](https://www.redhat.com/pt-br/topics/openstack)

-   [Abra o vSwitch](<>)

    -   [OVS Documento 4Linux](https://blog.4linux.com.br/open-vswitch-o-que-e-o-que-come-onde-vive)

-   [Exame LPIC-3 305-300](<>)

    -   [Objetivos LPIC-3 305-300](https://www.lpi.org/our-certifications/exam-305-objectives/)
    -   [Wiki LPIC-3 305-300](https://wiki.lpi.org/wiki/LPIC-305_Objectives_V3.0)
    -   [Material de aprendizagem LPIC-3 305-300](https://cursos.linuxsemfronteiras.com.br/courses/preparatorio-para-certificacao-lpic-3-305/)
    -   [Exame simulado LPIC-3 305-300 por ITexams](https://www.itexams.com/info/305-300)

<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<!-- MARKDOWN LINKS & IMAGES -->

<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->

[contributors-shield]: https://img.shields.io/github/contributors/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[contributors-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/graphs/contributors

[forks-shield]: https://img.shields.io/github/forks/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[forks-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/network/members

[stars-shield]: https://img.shields.io/github/stars/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[stars-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/stargazers

[issues-shield]: https://img.shields.io/github/issues/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[issues-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/issues

[license-shield]: https://img.shields.io/github/license/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[license-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/blob/main/LICENSE

[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555

[linkedin-url]: https://linkedin.com/in/marcossilvestrini

[def]: https://httpd.apache.org/docs/2.4/mod/directives.html
