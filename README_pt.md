<h1><a name="readme-top"></a></h1>

[![Create Release](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/release.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/release.yml)[![Translate README](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/translate.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/translate.yml)[![Generate HTML and PDF](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/generate-html.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/generate-html.yml)[![Deploy Webpage](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/deploy-webpage.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/deploy-webpage.yml)[![Generate GitBook Docs](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/generate-docs.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/generate-docs.yml)[![PSScriptAnalyzer](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/powershell.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/powershell.yml)[![Slack Notification](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/slack.yml/badge.svg)](https://github.com/marcossilvestrini/learning-lpic-3-305-300/actions/workflows/slack.yml)

* * *

[Minha licen√ßa][license-url][Garfos][forks-url][Stargazers][stars-url][Colaboradores][contributors-url][Problemas][issues-url][LinkedIn][linkedin-url]

* * *

# Aprendendo LPIC-3 305-300

[![English](https://img.shields.io/badge/lang-English-blue?logo=readme&logoColor=white)](./README.md)[![Portugu√™s](https://img.shields.io/badge/lang-Portugu√™s-green?logo=readme&logoColor=white)](README_pt.md)

![LPIC3-305-300](images/lpic3-305-300.jpg)

<p align="center">
<strong>Explore the docs ¬ª</strong></a>
    <br />
    <a href="https://marcossilvestrini.github.io/learning-lpic-3-305-300/">Web Site</a>
    -
    <a href="https://github.com/marcossilvestrini/learning-lpic-3-305-300">Code Page</a>
    -
    <a href="https://skynet-8.gitbook.io/learning-lpic-3-305-300">Gitbook</a>
    -
    <a href="https://github.com/marcossilvestrini/learning-lpic-3-305-300/issues">Report Bug</a>
    -
    <a href="https://github.com/marcossilvestrini/learning-lpic-3-305-300/issues">Request Feature</a>
</p>

* * *

## Resumo

<details>
  <summary><b>TABLE OF CONTENT</b></summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
    </li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#prerequisites">Prerequisites</a></li>
        <li><a href="#installation">installation</a></li>
      </ul>
    </li>
    <li><a href="#usage">Usage</a></li>
    <li><a href="#roadmap">Roadmap</a></li>
    <li><a href="#freedoms">Four Essential Freedoms</a></li>
    <li>
      <a href="#topic-351">Topic 351: Full Virtualization</a>
      <ul>
        <li><a href="#topic-351.1">351.1 Virtualization Concepts and Theory </a></li>
        <li><a href="#topic-351.2">351.2 Xen</a></li>
        <li><a href="#topic-351.3">351.3 QEMU</a></li>
        <li><a href="#topic-351.4">351.4 Libvirt Virtual Machine</a></li>
        <li><a href="#topic-351.5">351.5 Virtual Machine Disk Image Management</a></li>
      </ul>
    </li>
    <li>
      <a href="#topic-352">Topic 352: Container Virtualization</a>
      <ul>
        <li><a href="#topic-352.1">352.1 Container Virtualization Concepts</a></li>
        <li><a href="#topic-352.2">352.2 LXC</a></li>
        <li><a href="#topic-352.3">352.3 Docker</a></li>
        <li><a href="#topic-352.4">352.4 Container Orchestration Platforms</a></li>
      </ul>
    </li>
    <li>
      <a href="#topic-353">Topic 353: VM Deployment and Provisioning</a>
      <ul>
        <li><a href="#topic-353.1">353.1 Cloud Management Tools</a></li>
        <li><a href="#topic-353.2">353.2 Packer</a></li>
        <li><a href="#topic-353.3">353.3 cloud-init</a></li>
        <li><a href="#topic-353.4">353.4 Vagrant</a></li>
      </ul>
    </li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
    <li><a href="#acknowledgments">Acknowledgments</a></li>
  </ol>
</details><br>

* * *

<a name="about-the-project"></a>

## Sobre o projeto

> Este projeto tem como objetivo ajudar estudantes ou profissionais a aprender os principais conceitos de gnulinux
> e software livre
> Algumas distribui√ß√µes de Gnulinux como Debian e RPM ser√£o cobertas
> Instala√ß√£o e configura√ß√£o de alguns pacotes tamb√©m ser√£o cobertas
> Ao fazer isso, voc√™ pode dar a toda a comunidade a chance de se beneficiar de suas mudan√ßas.
> O acesso ao c√≥digo -fonte √© uma condi√ß√£o pr√©via para isso.
> Use o Vagrant para m√°quinas UP e execute laborat√≥rios e pratique o conte√∫do deste artigo.
> Eu publiquei na pasta Vagrant um VagrantFile com o que √© necess√°rio
> para voc√™ fazer upload de um ambiente para estudos

* * *

<p align="right">(<a href="#readme-top">back to top</a>)</p>

<a name="getting-started"></a>

## Come√ßando

Para iniciar o aprendizado, consulte a documenta√ß√£o acima.

<a name="prerequisites"></a>

### Pr√© -requisitos

-   [Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
-   [VMware WorkStation](https://blogs.vmware.com/workstation/2024/05/vmware-workstation-pro-now-available-free-for-personal-use.html)
-   [Utilit√°rio VMware Vagrant](https://developer.hashicorp.com/vagrant/install/vmware)
-   [Vagabundo](https://developer.hashicorp.com/vagrant/install)

<a name="installation"></a>

### Instala√ß√£o

Clone o repo

```sh
git clone https://github.com/marcossilvestrini/learning-lpic-3-305-300.git
cd learning-lpic-3-305-300
```

Personalize um modelo_VagrantFile-Topic-xxx_. Este arquivo cont√©m uma configura√ß√£o VMS para laborat√≥rios. Exemplo:

-   Arquivo[VagrantFile-Topic-351](vagrant/Vagrantfile-topic-351)
    -   vm.clone_directory = "&lt;your_driver_letter>:\\`<folder>`\\&lt;para_machine>\\#{Vm_name} -instance-1 "
        Exemplo: vm.clone_directory = "e:\\Servidores\\VMware\\#{Vm_name} -instance-1 "
    -   vm.vmx["Memsize"]= ""
    -   vm.vmx[‚ÄúNumVCPus‚Äù"]= ""
    -   vm.vmx["CPUID.CRERSESCOUT"]= ""

Personalize a configura√ß√£o de rede em arquivos[Configs/Network](configs/network/).

* * *

<a name="usage"></a>

## Uso

Use este reposit√≥rio para obter aprendizado sobre o exame LPIC-3 305-300

### Para cima e para baixo

Mudar a_VagrantFile-Topic-xxx_modelo e c√≥pia para um novo arquivo com nome_VagrantFile_

```sh
cd vagrant && vagrant up
cd vagrant && vagrant destroy -f
```

### Para reiniciar VMs

```sh
cd vagrant && vagrant reload
```

**Importante:**_Se voc√™ reiniciar VMs sem vag√£o, a pasta compartilhada n√£o √© montada ap√≥s a inicializa√ß√£o._

### Use PowerShell para cima e para baixo

Se voc√™ usa a plataforma Windows, crio um script PowerShell para VMs para cima e para baixo.

```powershell
vagrant/up.ps1
vagrant/destroy.ps1
```

### Esquema de infraestrutura T√≥pico 351

![topic-351](images/infraestructure-topic-351.png)

<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="roadmap"></a>

## Roteiro

-   [x] Criar reposit√≥rio
-   [x] Crie scripts para provisioning laborat√≥rios
-   [x] Crie exemplos sobre o t√≥pico 351
-   [x] Crie exemplos sobre o t√≥pico 352
-   [ ] Crie exemplos sobre o t√≥pico 353
-   [ ] Carregue o ITEXAM simulado

* * *

<a name="freedoms"></a>

## Quatro liberdades essenciais

> 0.a liberdade para executar o programa como desejar, para qualquer finalidade (liberdade 0).
> 1.A liberdade para estudar como o programa funciona e muda para
> sua computa√ß√£o como desejar (liberdade 1).
> O acesso ao c√≥digo -fonte √© uma condi√ß√£o pr√©via para isso.
> 2.A liberdade para redistribuir c√≥pias para que voc√™ possa ajudar os outros (liberdade 2).
> 3.Freedom para distribuir c√≥pias de suas vers√µes modificadas para outras pessoas (liberdade 3).

* * *

## Inspecionar comandos

```sh
type COMMAND
apropos COMMAND
whatis COMMAND --long
whereis COMMAND
COMMAND --help, --h
man COMMAND
```

<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351"></a>

## T√≥pico 351: Virtualiza√ß√£o completa

![LPIC3-305-300](images/virtualization-351.png)

* * *

<a name="topic-351.1"></a>

### 351.1 Conceitos e teoria de virtualiza√ß√£o

**Peso:**6

**Descri√ß√£o:**Os candidatos devem conhecer e entender os conceitos gerais, a teoria e a terminologia da virtualiza√ß√£o. Isso inclui terminologia Xen, Qemu e Libvirt.

**Principais √°reas de conhecimento:**

-   üñ•Ô∏è entender a terminologia da virtualiza√ß√£o
-   ‚öñÔ∏è entender os pr√≥s e contras da virtualiza√ß√£o
-   üõ†Ô∏è Entenda as v√°rias varia√ß√µes de hipervisores e monitores de m√°quinas virtuais
-   üîÑ Entenda os principais aspectos da migra√ß√£o de m√°quinas f√≠sicas para virtuais
-   üöÄ Entenda os principais aspectos da migra√ß√£o de m√°quinas virtuais entre os sistemas host
-   üì∏ Entenda as caracter√≠sticas e implica√ß√µes da virtualiza√ß√£o para uma m√°quina virtual, como instant√¢neos, pausas, clonagem e limites de recursos
-   üåê Consci√™ncia de ovirt, proxmox, Systemd Machined e VirtualBox
-   üîó Consci√™ncia do Vswitch aberto

#### 351.1 Objetos citados

```sh
Hypervisor
Hardware Virtual Machine (HVM)
Paravirtualization (PV)
Emulation and Simulation
CPU flags
/proc/cpuinfo
Migration (P2V, V2V)
```

#### Hipervisores

##### Hypervisor tipo 1 (hipervisor nua-metal)

###### Defini√ß√£o do tipo 1

Executa diretamente no hardware f√≠sico do host, fornecendo uma camada base para gerenciar VMs sem a necessidade de um sistema operacional host.

###### Caracter√≠sticas do tipo 1

-   ‚ö° Alto desempenho e efici√™ncia.
-   Lat√™ncia mais baixa e sobrecarga.
-   üè¢ Freq√ºentemente usado em ambientes corporativos e data centers.

###### Exemplos do tipo 1

-   VMware ESXi: um hipervisor robusto e amplamente usado em configura√ß√µes corporativas.
-   Microsoft Hyper-V: integrado ao Windows Server, oferecendo fortes recursos de desempenho e gerenciamento.
-   Xen: Um hipervisor de c√≥digo aberto usado por muitos provedores de servi√ßos em nuvem.
-   KVM (m√°quina virtual baseada em kernel): integrada ao kernel Linux, fornecendo alto desempenho para sistemas baseados em Linux.

##### Hypervisor tipo 2 (hipervisor hospedado)

###### Defini√ß√£o do tipo 2

Executa em cima de um sistema operacional convencional, contando com o sistema operacional host para gerenciamento de recursos e suporte ao dispositivo.

###### Caracter√≠sticas do tipo 2

-   üõ†Ô∏è mais f√°cil de configurar e usar, especialmente em computadores pessoais.
-   üîß Mais flex√≠vel para desenvolvimento, teste e implanta√ß√µes em menor escala.
-   üê¢ Normalmente menos eficiente que os hipervisores do tipo 1 devido a uma sobrecarga adicional do sistema operacional do host.

###### Exemplos do tipo 2

-   VMware Workstation: um poderoso hipervisor para executar v√°rios sistemas operacionais em uma √∫nica √°rea de trabalho.
-   Oracle VirtualBox: um hipervisor de c√≥digo aberto conhecido por sua flexibilidade e facilidade de uso.
-   Paralels Desktop: Projetado para usu√°rios de Mac para executar o Windows e outros sistemas operacionais ao lado de MacOS.
-   Qemu (emulador r√°pido): um emulador de c√≥digo aberto e virtualizador, geralmente usado em conjunto com o KVM.

##### Diferen√ßas -chave entre os hipervisores do tipo 1 e do tipo 2

-   Ambiente de implanta√ß√£o:
    -   Os hipervisores tipo 1 s√£o comumente implantados em data centers e ambientes corporativos devido √† sua intera√ß√£o direta com hardware e alto desempenho.
    -   Os hipervisores do tipo 2 s√£o mais adequados para tarefas de uso pessoal, desenvolvimento, teste e virtualiza√ß√£o em pequena escala.
-   Desempenho:
    -   Os hipervisores do tipo 1 geralmente oferecem melhor desempenho e menor lat√™ncia porque n√£o confiam em um sistema operacional host.
    -   Os hipervisores do tipo 2 podem experimentar alguma degrada√ß√£o do desempenho devido √† sobrecarga de execu√ß√£o no topo de um sistema operacional host.
-   Gerenciamento e facilidade de uso:
    -   Os hipervisores do tipo 1 requerem configura√ß√£o e gerenciamento mais complexos, mas fornecem recursos avan√ßados e escalabilidade para implanta√ß√µes em larga escala.
    -   Os hipervisores tipo 2 s√£o mais f√°ceis de instalar e usar, tornando -os ideais para usu√°rios individuais e projetos menores.

##### Tipos de migra√ß√£o

No contexto dos hipervisores, que s√£o tecnologias usadas para criar e gerenciar m√°quinas virtuais, os termos migra√ß√£o de P2V e migra√ß√£o V2V s√£o comuns em ambientes de virtualiza√ß√£o.
Eles se referem a processos de sistemas de migra√ß√£o entre diferentes tipos de plataformas.

##### P2V - Migra√ß√£o f√≠sica para virtual

A migra√ß√£o de P2V refere-se ao processo de migra√ß√£o de um servidor f√≠sico para uma m√°quina virtual. Em outras palavras, um sistema operacional e seus aplicativos, executando em hardware f√≠sico dedicado, s√£o "convertidos" e movidos para uma m√°quina virtual que √© executada em um hipervisor (como VMware, Hyper-V, KVM, etc.).

-   Exemplo: voc√™ tem um servidor f√≠sico executando um sistema Windows ou Linux e deseja mov√™ -lo para um ambiente virtual, como uma infraestrutura em nuvem ou um servidor de virtualiza√ß√£o interna.
    O processo envolve copiar todo o estado do sistema, incluindo o sistema operacional, drivers e dados, para criar uma m√°quina virtual equivalente que possa funcionar como se estivesse no hardware f√≠sico.

##### V2V - Migra√ß√£o virtual para virtual

A migra√ß√£o V2V refere-se ao processo de migra√ß√£o de uma m√°quina virtual de um hipervisor para outro. Nesse caso, voc√™ j√° tem uma m√°quina virtual em execu√ß√£o em um ambiente virtualizado (como o VMware) e deseja mov√™-lo para outro ambiente virtualizado (por exemplo, para Hyper-V ou um novo servidor VMware).

-   Exemplo: voc√™ tem uma m√°quina virtual em execu√ß√£o em um servidor de virtualiza√ß√£o do VMware, mas decide migr√°-lo para uma plataforma Hyper-V. Nesse caso, a migra√ß√£o V2V converte a m√°quina virtual de um formato ou hipervisor para outro, garantindo que ela possa continuar funcionando corretamente.

#### HVM e paravirtualiza√ß√£o

##### Virtualiza√ß√£o assistida por hardware (HVM)

###### Defini√ß√£o de HVM

A HVM aproveita as extens√µes de hardware fornecidas pelas CPUs modernas para virtualizar o hardware, permitindo a cria√ß√£o e o gerenciamento de VMs com o m√≠nimo de sobrecarga de desempenho.

###### Caracter√≠sticas -chave da HVM

-   üñ•Ô∏è**Suporte de hardware**: Requer suporte √† CPU para extens√µes de virtualiza√ß√£o, como Intel VT-X ou AMD-V.
-   üõ†Ô∏è**Virtualiza√ß√£o completa:**As VMs podem executar sistemas operacionais de h√≥spedes n√£o modificados, pois o hipervisor fornece uma emula√ß√£o completa do ambiente de hardware.
-   ‚ö°**Desempenho:**Normalmente, oferece desempenho quase nativo devido √† execu√ß√£o direta do c√≥digo de convidado na CPU.
-   üîí**Isolamento:**Fornece um forte isolamento entre as VMs, pois cada VM opera como se tivesse seu pr√≥prio hardware dedicado.

###### Exemplo de HVM

VMware Esxi, Microsoft Hyper-V, KVM (m√°quina virtual baseada em kernel).

###### Vantagens de HVM

-   ‚úÖ**Compatibilidade:**Pode executar qualquer sistema operacional sem modifica√ß√£o.
-   ‚ö°**Desempenho:**Alto desempenho devido ao suporte de hardware.
-   üîí**Seguran√ßa:**Recursos aprimorados de isolamento e seguran√ßa fornecidos pelo hardware.

###### Desvantagens de HVM

-   üõ†Ô∏è**Depend√™ncia de hardware:**Requer recursos espec√≠ficos de hardware, limitando a compatibilidade com sistemas mais antigos.
-   üîß**Complexidade:**Pode envolver configura√ß√£o e gerenciamento mais complexos.

##### Paravirtualiza√ß√£o

###### Defini√ß√£o de paravirtualiza√ß√£o

A paravirtualiza√ß√£o envolve a modifica√ß√£o do sistema operacional convidado para estar ciente do ambiente virtual, permitindo que ele interaja com mais efici√™ncia com o hipervisor.

###### Caracter√≠sticas -chave da paravirtualiza√ß√£o

-   üõ†Ô∏è**Modifica√ß√£o de convidados:**Requer altera√ß√µes no sistema operacional convidado para se comunicar diretamente com o hipervisor usando hipercalls.
-   ‚ö°**Desempenho:**Pode ser mais eficiente que a virtualiza√ß√£o completa tradicional, pois reduz a sobrecarga associada ao hardware emulando.
-   üîó**Compatibilidade:**Limitado a sistemas operacionais que foram modificados para paravirtutualiza√ß√£o.

###### Exemplos de paravirtualiza√ß√£o

Xen com convidados paravirtualizados, ferramentas VMware em determinadas configura√ß√µes e algumas configura√ß√µes de KVM.

###### Vantagens de paravirtualiza√ß√£o

-   ‚ö°**Efici√™ncia:**Reduz a sobrecarga de virtualizar hardware, potencialmente oferecendo melhor desempenho para determinadas cargas de trabalho.
-   ‚úÖ**Utiliza√ß√£o de recursos:**Uso mais eficiente dos recursos do sistema devido √† comunica√ß√£o direta entre o sistema operacional convidado e o hipervisor.

###### Desvantagens de paravirtualiza√ß√£o

-   üõ†Ô∏è**Modifica√ß√£o do sistema operacional convidado:**Requer modifica√ß√µes para o sistema operacional convidado, limitando a compatibilidade aos sistemas operacionais suportados.
-   üîß**Complexidade:**Requer complexidade adicional no sistema operacional convidado para implementa√ß√µes de hipercall.

##### Principais diferen√ßas

###### Requisitos do sistema operacional convidado

-   **HVM:**Pode executar sistemas operacionais de convidados n√£o modificados.
-   **Paravirtutualiza√ß√£o:**Requer que os sistemas operacionais de convidados sejam modificados para trabalhar com o hipervisor.

###### Desempenho

-   **HVM:**Normalmente, fornece desempenho quase nativo devido √† execu√ß√£o assistida por hardware.
-   **Paravirtutualiza√ß√£o:**Pode oferecer desempenho eficiente, reduzindo a sobrecarga da emula√ß√£o de hardware, mas depende do sistema operacional convidado modificado.

###### Depend√™ncia de hardware

-   **HVM:**Requer recursos espec√≠ficos da CPU (Intel VT-X, AMD-V).
-   **Paravirtutualiza√ß√£o:**N√£o requer recursos espec√≠ficos da CPU, mas precisa de um sistema operacional de convidado modificado.

###### Isolamento

-   **HVM:**Fornece um isolamento forte usando recursos de hardware.
-   **Paravirtutualiza√ß√£o:**Depende do isolamento baseado em software, que pode n√£o ser t√£o robusto quanto o isolamento baseado em hardware.

###### Complexidade

-   **HVM:**Geralmente mais simples de implantar, pois suporta o sistema operacional n√£o modificado.
-   **Paravirtutualiza√ß√£o:**Requer configura√ß√£o e modifica√ß√µes adicionais para o sistema operacional convidado, aumentando a complexidade.

#### NUMA (acesso n√£o uniforme de mem√≥ria)

O NUMA (acesso n√£o uniforme de mem√≥ria) √© uma arquitetura de mem√≥ria usada em sistemas multiprocessadores para otimizar o acesso √† mem√≥ria pelos processadores.
Em um sistema NUMA, a mem√≥ria √© distribu√≠da de maneira desigual entre os processadores, o que significa que cada processador tem acesso mais r√°pido a uma parte da mem√≥ria (sua "mem√≥ria local") do que √† mem√≥ria que est√° fisicamente mais distante (referida como "mem√≥ria remota") e associada a outros processadores.

##### Principais recursos da arquitetura NUMA

1.  **Mem√≥ria local e remota**: Cada processador tem sua pr√≥pria mem√≥ria local, que pode acessar mais rapidamente. No entanto, tamb√©m pode acessar a mem√≥ria de outros processadores, embora isso leve mais tempo.
2.  **Lat√™ncia diferenciada**: A lat√™ncia do acesso √† mem√≥ria varia dependendo se o processador est√° acessando sua mem√≥ria local ou a mem√≥ria de outro n√≥. O acesso √† mem√≥ria local √© mais r√°pido, enquanto o acesso √† mem√≥ria de outro n√≥ (remoto) √© mais lento.
3.  **Escalabilidade**: A arquitetura da NUMA foi projetada para melhorar a escalabilidade em sistemas com muitos processadores. √Ä medida que mais processadores s√£o adicionados, a mem√≥ria tamb√©m √© distribu√≠da, evitando o gargalo que ocorreria em uma arquitetura uniforme de acesso √† mem√≥ria (Uma).

##### Advantages of NUMA

-   ‚ö° Melhor desempenho em sistemas grandes: como cada processador possui mem√≥ria local, ele pode funcionar com mais efici√™ncia sem competir tanto com outros processadores pelo acesso √† mem√≥ria.
-   Scalability: O NUMA permite sistemas com muitos processadores e grandes quantidades de mem√≥ria para escalar com mais efic√°cia em compara√ß√£o com uma arquitetura Uma.

##### Desvantagens

-   Complexidade da programa√ß√£o: os programadores precisam estar cientes de quais regi√µes de mem√≥ria s√£o locais ou remotas, otimizando o uso da mem√≥ria local para obter um melhor desempenho.
-   üê¢ Penalidades potenciais de desempenho: se um processador acessar frequentemente a mem√≥ria remota, o desempenho poder√° sofrer devido √† maior lat√™ncia.
    Essa arquitetura √© comum em sistemas multiprocessadores de alto desempenho, como servidores e supercomputadores, onde a escalabilidade e a otimiza√ß√£o da mem√≥ria s√£o cr√≠ticas.

#### Solu√ß√µes OpenSource

-   üåê Ovirt:<https://www.ovirt.org/>
-   üåê Proxmox:<https://www.proxmox.com/en/proxmox-virtual-environment/overview>
-   üåê Oracle VirtualBox:<https://www.virtualbox.org/>
-   üåê Open Vswitch:<https://www.openvswitch.org/>

#### Tipos de virtualiza√ß√£o

##### Virtualiza√ß√£o de hardware (virtualiza√ß√£o do servidor)

###### Defini√ß√£o de HV

Abstraia o hardware f√≠sico para criar m√°quinas virtuais (VMs) que executam sistemas e aplicativos operacionais separados.

###### Casos de uso de HV

Data centers, computa√ß√£o em nuvem, consolida√ß√£o do servidor.

###### Exemplos de HV

VMware Esxi, Microsoft Hyper-V, KVM.

##### Virtualiza√ß√£o do sistema operacional (cont√™ineriza√ß√£o)

###### Defini√ß√£o de cont√™ineriza√ß√£o

Permite que v√°rias inst√¢ncias isoladas do espa√ßo do usu√°rio (cont√™ineres) sejam executadas em um √∫nico kernel do sistema operacional.

###### Casos de uso de cont√™ineriza√ß√£o

Ambientes de arquitetura, desenvolvimento e teste de microsservi√ßos.

###### Exemplos de cont√™ineriza√ß√£o

Docker, Kubernetes, LXC.

##### Virtualiza√ß√£o de rede

###### Defini√ß√£o de virtualiza√ß√£o de rede

Combina recursos de rede de hardware e software em uma √∫nica entidade administrativa baseada em software.

###### Casos de uso da virtualiza√ß√£o de rede

Networking definido por software (SDN), Virtualiza√ß√£o da Fun√ß√£o de Rede (NFV).

###### Exemplos de virtualiza√ß√£o de rede

VMware NSX, Cisco ACI, OpenStack Neutron.

##### Virtualiza√ß√£o de armazenamento

###### Defini√ß√£o de virtualiza√ß√£o de armazenamento

Pools armazenamento f√≠sico de v√°rios dispositivos em uma √∫nica unidade de armazenamento virtual que pode ser gerenciada centralmente.

###### Casos de uso da defini√ß√£o de virtualiza√ß√£o de armazenamento

Gerenciamento de dados, otimiza√ß√£o de armazenamento, recupera√ß√£o de desastres.

###### Exemplos de defini√ß√£o de virtualiza√ß√£o de armazenamento

IBM SAN Volume Controller, VMware vsan, NetApp OTAP.

##### Virtualiza√ß√£o da √°rea de trabalho

###### Defini√ß√£o de virtualiza√ß√£o da √°rea de trabalho

Permite que um sistema operacional de desktop seja executado em uma m√°quina virtual hospedada em um servidor.

###### Casos de uso da defini√ß√£o de virtualiza√ß√£o de desktop

Infraestrutura de Desktop Virtual (VDI), Solu√ß√µes de Trabalho Remoto.

###### Exemplos de defini√ß√£o de virtualiza√ß√£o de desktop

Citrix Apps e desktops Citrix, VMware Horizon, Microsoft Remote Desktop Services.

##### Virtualiza√ß√£o de aplicativos

###### Defini√ß√£o de virtualiza√ß√£o do aplicativo

Separa os aplicativos do hardware subjacente e do sistema operacional, permitindo que eles sejam executados em ambientes isolados.

###### Casos de uso da defini√ß√£o de virtualiza√ß√£o de aplicativos

Implanta√ß√£o simplificada de aplicativos, teste de compatibilidade.

###### Exemplos de defini√ß√£o de virtualiza√ß√£o de aplicativos

VMware ThinApp, Microsoft App-V, Citrix XenApp.

##### Virtualiza√ß√£o de dados

###### Defini√ß√£o de virtualiza√ß√£o de dados

Integra dados de v√°rias fontes sem consolid√° -los fisicamente, fornecendo uma vis√£o unificada para an√°lise e relat√≥rio.

###### Casos de uso da defini√ß√£o de virtualiza√ß√£o de dados

Intelig√™ncia de neg√≥cios, integra√ß√£o de dados em tempo real.

###### Exemplos de defini√ß√£o de virtualiza√ß√£o de dados

Denodo, Red Hat JBoss Virtualiza√ß√£o de dados, IBM InfoSphere.

##### Benef√≠cios da virtualiza√ß√£o

-   ‚ö° Efici√™ncia de recursos: melhor utiliza√ß√£o de recursos f√≠sicos.
-   üí∞ Economia de custos: hardware reduzido e custos operacionais.
-   üìà Escalabilidade: f√°cil de aumentar ou diminuir de acordo com a demanda.
-   üîß Flexibilidade: suporta uma variedade de cargas de trabalho e aplica√ß√µes.
-   üîÑ Recupera√ß√£o de desastres: processos simplificados de backup e recupera√ß√£o.
-   üîí Isolamento: seguran√ßa aprimorada atrav√©s do isolamento de ambientes.

#### Emula√ß√£o

A emula√ß√£o envolve a simula√ß√£o do comportamento de hardware ou software em uma plataforma diferente do originalmente pretendido.

Esse processo permite que o software projetado para um sistema seja executado em outro sistema que possa ter arquitetura ou ambiente operacional diferente.

Embora a emula√ß√£o forne√ßa versatilidade, permitindo a execu√ß√£o de sistemas ou aplicativos operacionais de convidados n√£o modificados, ela geralmente vem com sobrecarga de desempenho.

Essa sobrecarga surge porque o sistema emulado precisa interpretar e traduzir instru√ß√µes destinadas ao sistema original em instru√ß√µes compat√≠veis com o sistema host. Como resultado, a emula√ß√£o pode ser mais lenta que a execu√ß√£o nativa, tornando-o menos eficiente para tarefas com uso intensivo de recursos.

Apesar dessa desvantagem, a emula√ß√£o permanece valiosa para a execu√ß√£o de software herdado, testando aplicativos em diferentes plataformas e facilitando o desenvolvimento de plataformas cruzadas.

#### Systemd-Mathined

O servi√ßo usinado pela SystemD √© dedicado ao gerenciamento de m√°quinas e cont√™ineres virtuais no ecossistema Systemd.
 Ele fornece funcionalidades essenciais para controlar, monitorar e manter inst√¢ncias virtuais, oferecendo integra√ß√£o e efici√™ncia robustas nos ambientes Linux.

<p align="right">(<a href="#topic-351.1">back to sub Topic 351.1</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351.2"></a>

### 351.2 Alterna√ß√£o

![xen-architecture](images/xen-achitecture.png)

![xen-architecture](images/xen-achitecture2.png)

**Peso:**3

**Descri√ß√£o:**Os candidatos devem poder instalar, configurar, manter, migrar e solucionar problemas de instala√ß√µes XEN. O foco est√° no Xen vers√£o 4.x.

**Principais √°reas de conhecimento:**

-   Entenda a arquitetura de Xen, incluindo networking e armazenamento
-   Configura√ß√£o b√°sica dos n√≥s e dom√≠nios Xen
-   Gerenciamento b√°sico de n√≥s e dom√≠nios Xen
-   Solu√ß√£o de problemas b√°sicos de instala√ß√µes Xen
-   Avarines fora da p√≠lula
-   Consci√™ncia de Xenstore
-   Consci√™ncia dos par√¢metros de inicializa√ß√£o do Xen
-   Consci√™ncia do utilit√°rio XM

#### Alternar

![panda](images/xen-panda.png)

O XEN √© um hipervisor de c√≥digo aberto tipo 1 (sem metal), que permite que v√°rios sistemas operacionais sejam executados simultaneamente no mesmo hardware f√≠sico.xen fornece uma camada entre o hardware f√≠sico e as m√°quinas virtuais (VMs), permitindo compartilhamento de recursos eficientes e isolamento.

-   **Arquitetura:**O Xen opera com um sistema de duas camadas em que o Dom√≠nio 0 (DOM0) √© o dom√≠nio privilegiado com acesso direto ao hardware e gerencia o hipervisor. Outras m√°quinas virtuais, chamadas de dom√≠nio U (DOMU), executam sistemas operacionais convidados e s√£o gerenciados pelo DOM0.
-   **Tipos de virtualiza√ß√£o:**O XEN suporta paravirtualiza√ß√£o (PV), que requer o sistema operacional convidado modificado e a virtualiza√ß√£o assistida por hardware (HVM), que usa extens√µes de hardware (por exemplo, Intel VT-X ou AMD-V) para executar sistemas operacionais de convidados n√£o modificados.
    O XEN √© amplamente utilizado em ambientes em nuvem, principalmente pela Amazon Web Services (AWS) e outros provedores de nuvem em larga escala.

#### Xensource

A Xensource foi a empresa fundada pelos desenvolvedores originais do Xen Hypervisor da Universidade de Cambridge para comercializar a Xen. A empresa forneceu solu√ß√µes corporativas com base no XEN e ofereceu ferramentas e suporte adicionais para aprimorar os recursos da XEN para uso corporativo.

-   **Aquisi√ß√£o pela Citrix**: Em 2007, a Xensource foi adquirida pela Citrix Systems, Inc. A Citrix usou a tecnologia Xen como base para o seu produto Citrix Xenserver, que se tornou uma popular plataforma de virtualiza√ß√£o de grau corporativo baseado em Xen.
-   **Transi√ß√£o**: Ap√≥s a aquisi√ß√£o, o projeto Xen continuou como um projeto de c√≥digo aberto, enquanto a Citrix se concentrou em ofertas comerciais como Xenserver, alavancando a tecnologia Xensource.

#### Projeto Xen

O projeto XEN refere-se √† comunidade de c√≥digo aberto e √† iniciativa respons√°vel pelo desenvolvimento e manuten√ß√£o do hipervisor Xen ap√≥s sua comercializa√ß√£o. O projeto Xen opera sob a Funda√ß√£o Linux, com foco na constru√ß√£o, melhoria e apoio a Xen como um esfor√ßo colaborativo e orientado pela comunidade.

-   **Metas:**O projeto XEN visa avan√ßar o hipervisor, melhorando seu desempenho, seguran√ßa e conjunto de recursos para uma ampla gama de casos de uso, incluindo computa√ß√£o em nuvem, virtualiza√ß√£o focada na seguran√ßa (por exemplo, Qubes OS) e sistemas incorporados.
-   **Colaboradores:**O projeto inclui colaboradores de v√°rias organiza√ß√µes, incluindo os principais provedores de nuvem, fornecedores de hardware e desenvolvedores independentes.
-   **P√≠lula e hedools:**O projeto XEN tamb√©m inclui ferramentas como XAPI (XenAPI), que √© usado para gerenciar instala√ß√µes do Xen Hypervisor e v√°rios outros utilit√°rios para gerenciamento e otimiza√ß√£o do sistema.

#### Xenstore

A Xen Store √© um componente cr√≠tico do hipervisor Xen.
Essencialmente, o Xen Store √© um banco de dados de valor-chave distribu√≠do usado para comunica√ß√£o e compartilhamento de informa√ß√µes entre o hypervisor Xen e as m√°quinas virtuais (tamb√©m conhecidas como dom√≠nios) que ele gerencia.

Aqui est√£o alguns aspectos importantes da Xen Store:

-   **Comunica√ß√£o entre dom√≠nios:**O Xen Store permite a comunica√ß√£o entre dom√≠nios, como o DOM0 (o dom√≠nio privilegiado que controla os recursos de hardware) e o DOMUS (dom√≠nios do usu√°rio, que s√£o as VMs). Isso √© feito atrav√©s de entradas de valor-chave, onde cada dom√≠nio pode ler ou escrever informa√ß√µes.
-   **Gerenciamento de configura√ß√£o:**√â usado para armazenar e acessar informa√ß√µes de configura√ß√£o, como dispositivos virtuais, redes e par√¢metros de inicializa√ß√£o. Isso facilita o gerenciamento din√¢mico e a configura√ß√£o das VMs.
-   **Eventos e notifica√ß√µes:**A Xen Store tamb√©m suporta notifica√ß√µes de eventos. Quando uma chave ou valor espec√≠fica na loja Xen √© modificada, os dom√≠nios interessados ‚Äã‚Äãpodem ser notificados para reagir a essas altera√ß√µes. Isso √© √∫til para monitorar e gerenciar recursos.
-   API simples: a Xen Store fornece uma API simples para ler e escrever dados, facilitando os desenvolvedores para integrar seus aplicativos ao sistema de virtualiza√ß√£o Xen.

#### P√≠lula

XAPI, ou Xenapi, √© a interface de programa√ß√£o de aplicativos (API) usada para gerenciar o hipervisor Xen e suas m√°quinas virtuais (VMs).
O XAPI √© um componente essencial do Xenserver (agora conhecido como Citrix Hypervisor) e fornece uma maneira padronizada de interagir com o hipervisor Xen para executar opera√ß√µes como criar, configurar, monitorar e controlar VMs.

Aqui est√£o alguns aspectos importantes de Xapi:

-   **Gerenciamento de VM:**O XAPI permite que os administradores criem, excluam, excluam, iniciem e parem e parem e parem programaticamente as m√°quinas virtuais.
-   **Automa√ß√£o:**Com o XAPI, √© poss√≠vel automatizar o gerenciamento de recursos virtuais, incluindo redes, armazenamento e computa√ß√£o, o que √© crucial para grandes ambientes em nuvem.
-   **Integra√ß√£o:**O XAPI pode ser integrado a outras ferramentas e scripts para fornecer administra√ß√£o mais eficiente e personalizada do ambiente XEN.
-   **Controle de acesso:**O XAPI tamb√©m fornece mecanismos de controle de acesso para garantir que apenas usu√°rios autorizados possam executar opera√ß√µes espec√≠ficas no ambiente virtual.

O XAPI √© a interface que permite o controle e a automa√ß√£o do hipervisor Xen, facilitando o gerenciamento de ambientes virtualizados.

#### Resumo Xen

-   **INCROPPING:**A tecnologia principal do hipervisor que permite que as m√°quinas virtuais sejam executadas em hardware f√≠sico.
-   **Xensource:**A empresa que comercializou Xen, mais tarde adquirida pela Citrix, levando ao desenvolvimento do Citrix Xenserver.
-   **Projeto Xen:**A iniciativa e a comunidade de c√≥digo aberto que continuam a desenvolver e manter o hipervisor Xen sob a Funda√ß√£o Linux.
-   **Xenstore:**A Xen Store atua como uma intermedi√°ria de comunica√ß√£o e configura√ß√£o entre o Hypervisor Xen e as VMs, simplificando a opera√ß√£o e o gerenciamento de ambientes virtualizados.
-   **P√≠lula**√© a interface que permite o controle e a automa√ß√£o do hipervisor Xen, facilitando o gerenciamento de ambientes virtualizados.

#### Domain0 (DOM0)

Domain0, OR DOM0, √© o dom√≠nio de controle em uma arquitetura Xen. Ele gerencia outros dom√≠nios (DOMUS) e tem acesso direto ao hardware.
O DOM0 executa drivers de dispositivo, permitindo que o Domus, que n√£o possua acesso direto ao hardware, se comunique com dispositivos. Normalmente, √© uma inst√¢ncia completa de um sistema operacional, como o Linux, e √© essencial para a opera√ß√£o de hipervisor do Xen.

#### Dom√≠nio (casa)

Domus s√£o dom√≠nios n√£o privilegiados que executam m√°quinas virtuais.
Eles s√£o gerenciados pelo DOM0 e n√£o t√™m acesso direto ao hardware. O DOMUS pode ser configurado para executar diferentes sistemas operacionais e √© usado para v√°rios fins, como servidores de aplicativos e ambientes de desenvolvimento. Eles dependem do DOM0 para intera√ß√£o de hardware.

#### Peewee-dom (paravardiyed domina)

O PV-Domus usa uma t√©cnica chamada paravirtutualiza√ß√£o. Neste modelo, o sistema operacional DOMU √© modificado para estar ciente de que ele √© executado em um ambiente virtualizado, permitindo que ele se comunique diretamente com o hipervisor para o desempenho otimizado.
Isso resulta em menor sobrecarga e melhor efici√™ncia em compara√ß√£o com a virtualiza√ß√£o total.

#### HVM-domu (dom√≠nio da m√°quina virtual de hardware)

O HVM-Domus s√£o m√°quinas virtuais que utilizam virtualiza√ß√£o completa, permitindo que os sistemas operacionais n√£o modificados sejam executados. O Xen Hypervisor fornece emula√ß√£o de hardware para esses Domus, permitindo que eles executem qualquer sistema operacional que suporta a arquitetura de hardware subjacente.
Embora isso ofere√ßa maior flexibilidade, pode resultar em uma sobrecarga mais alta em compara√ß√£o com o PV-Domus.

#### Rede Xen

Dispositivos de rede paravirtualizados![pv-networking](images/xen-networking2.png)

Ponte![pv-networking](images/xen-networking1.png)

#### 351.2 Objetos citados

```sh
Domain0 (Dom0), DomainU (DomU)
PV-DomU, HVM-DomU
/etc/xen/
xl
xl.cfg 
xl.conf # Xen global configurations
xentop
oxenstored # Xenstore configurations
```

#### 351.2 Notas

```sh

# Xen Settings
/etc/xen/
/etc/xen/xl.conf - Main general configuration file for Xen
/etc/xen/oxenstored.conf - Xenstore configurations

# VM Configurations
/etc/xen/xlexample.pvlinux
/etc/xen/xlexample.hvm

# Service Configurations
/etc/default/xen
/etc/default/xendomains

# xen-tools configurations
/etc/xen-tools/
/usr/share/xen-tools/

# docs
xl(1)
xl.conf(5)
xlcpupool.cfg(5)
xl-disk-configuration(5)
xl-network-configuration(5)
xen-tscmode(7)

# initialized domains auto
/etc/default/xendomains
   XENDOMAINS_AUTO=/etc/xen/auto

/etc/xen/auto/


# set domain for up after xen reboot
## create folder auto
cd /etc/xen && mkdir -p auto && cd auto

# create simbolic link
ln -s /etc/xen/lpic3-pv-guest /etc/xen/auto/lpic3-pv-guest
```

#### 351.2 Comandos importantes

##### Imagem Xen-Criar

```sh
# create a pv image
xen-create-image \
  --hostname=lpic3-pv-guest \
  --memory=1gb \
  --vcpus=2 \
  --lvm=vg_xen \
  --bridge=xenbr0 \
  --dhcp \
  --pygrub \
  --password=vagrant \
  --dist=bookworm
```

##### Imagens Xen-Lista

```sh
# list image
xen-list-image
```

##### Xen-Delete-Image

```sh
# delete a pv image
xen-delete-image lpic3-pv-guest --lvm=vg_xen
```

##### Xenstore-LS

```sh
# list xenstore infos
xenstore-ls
```

##### xl

```sh
# view xen information
xl infos

# list Domains
xl list
xl list lpic3-hvm-guest
xl list lpic3-hvm-guest -l

# uptime Domains
xl uptime

# pause Domain
xl pause 2
xl pause lpic3-hvm-guest

# save state Domains
xl -v save lpic3-hvm-guest ~root/image-lpic3-hvm-guest.save

# restore Domain
xl restore /root/image-lpic3-hvm-guest.save

# get Domain name
xl domname 2

# view dmesg information
xl dmesg

# monitoring domain
xl top
xentop
xen top

# Limit mem Dom0
xl mem-set 0 2048

# Limit cpu (not permanent after boot)
xl vcpu-set 0 2

# create DomainU - virtual machine
xl create /etc/xen/lpic3-pv-guest.cfg

# create DomainU virtual machine and connect to guest
xl create -c /etc/xen/lpic3-pv-guest.cfg

##----------------------------------------------
# create DomainU virtual machine HVM

## create logical volume
lvcreate -l +20%FREE -n lpic3-hvm-guest-disk  vg_xen

## create a ssh tunel for vnc
ssh -l vagrant -L 5900:localhost:5900  192.168.0.130

## configure /etc/xen/lpic3-hvm-guest.cfg
## set boot for cdrom: boot = "d"

## create domain hvm
xl create /etc/xen/lpic3-hvm-guest.cfg

## open vcn conection in your vnc client with localhost
## for view install details

## after installation finished, destroy domain: xl destroy <id_or_name>

## set /etc/xen/lpic3-hvm-guest.cfg: boot for hard disc: boot = "c"

## create domain hvm
xl create /etc/xen/lpic3-hvm-guest.cfg

## access domain hvm
xl console <id_or_name>
##----------------------------------------------

# connect in domain guest
xl console <id>|<name> (press enter)
xl console 1
xl console lpic3-pv-guest

#How do I exit domU "xl console" session
#Press ctrl+] or if you're using Putty press ctrl+5.

# Poweroff domain
xl shutdown lpic3-pv-guest

# destroy domain
xl destroy lpic3-pv-guest

# reboot domain
xl reboot lpic3-pv-guest

# list block devices
xl block-list 1
xl block-list lpic3-pv-guest

# detach block devices
xl block-detach lpic3-hvm-guest hdc
xl block-detach 2 xvdc

# attach block devices

## hard disk devices
xl block-attach lpic3-hvm-guest-ubuntu 'phy:/dev/vg_xen/lpic3-hvm-guest-disk2,xvde,w'

## cdrom
xl block-attach lpic3-hvm-guest 'file:/home/vagrant/isos/ubuntu/seed.iso,xvdc:cdrom,r'
xl block-attach 2 'file:/home/vagrant/isos/ubuntu/seed.iso,xvdc:cdrom,r'

# insert and eject cdrom devices
xl cd-insert lpic3-hvm-guest-ubuntu xvdb  /home/vagrant/isos/ubuntu/ubuntu-24.04.1-live-server-amd64.iso
xl cd-eject lpic3-hvm-guest-ubuntu xvdb
```

#### 251.2 Notas

##### VIF

Em Xen, "VIF" significa interface virtual e √© usado para configurar a rede para m√°quinas virtuais (dom√≠nios).

Ao especificar as diretrizes "VIF" nos arquivos de configura√ß√£o do dom√≠nio, os administradores podem definir interfaces de rede, atribuir endere√ßos IP, configurar VLANs e configurar outros par√¢metros de rede para m√°quinas virtuais em execu√ß√£o em hosts XEN. Por exemplo: VIF =[=Bridge  Xenbr0], neste caso, conecta a interface de rede da VM √† ponte Xen chamada "XenBr0".

````sh

<p align="right">(<a href="#topic-351.2">back to sub Topic 351.2</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

---

<a name="topic-351.3"></a>

### 351.3 QEMU

![xen-kvm-qemu](/images/xen-kvm-qemu.png)

**Weight:** 4

**Description:** Candidates should be able to install, configure, maintain, migrate and troubleshoot QEMU installations.

**Key Knowledge Areas:**

* Understand the architecture of QEMU, including KVM, networking and storage
* Start QEMU instances from the command line
* Manage snapshots using the QEMU monitor
* Install the QEMU Guest Agent and VirtIO device drivers
* Troubleshoot QEMU installations, including networking and storage
* Awareness of important QEMU configuration parameters

#### 351.3 Cited Objects

```sh
Kernel modules: kvm, kvm-intel and kvm-amd
/dev/kvm
QEMU monitor
qemu
qemu-system-x86_64
ip
brctl
tunctl
````

#### 351.3 Comandos importantes

##### 351.3 outros comandos

##### Verifique o m√≥dulo KVM

```sh
# check if kvm is enabled
egrep -o '(vmx|svm)' /proc/cpuinfo
lscpu |grep Virtualization
lsmod|grep kvm
ls -l /dev/kvm
hostnamectl
systemd-detect-virt
```

```sh
# check if kvm is enabled
egrep -o '(vmx|svm)' /proc/cpuinfo
lscpu |grep Virtualization
lsmod|grep kvm
ls -l /dev/kvm

# check kernel infos
uname -a

# check root device
findmnt /

# mount a qcow2 image
## Example 1:
mkdir -p /mnt/qemu
guestmount -a os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 -i /mnt/qemu/

## Example 2:
sudo guestfish --rw -a os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2
run
list-filesystems

# run commands in qcow2 images
## Example 1:
virt-customize -a  os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2  --run-command 'echo hello >/root/hello.txt'
## Example 2:
sudo virt-customize -a os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  --run-command 'echo -e "auto ens3\niface ens3 inet dhcp" > /etc/network/interfaces.d/ens3.cfg'

# generate mac 
printf 'DE:AD:BE:EF:%02X:%02X\n' $((RANDOM%256)) $((RANDOM%256))
```

##### IP

```sh
# list links
ip link show

# create bridge
ip link add br0 type bridge
```

##### BRCTL

```sh
# list links
ip link show

# create bridge
ip link add br0 type bridge
```

##### qemu-img

```sh
# create image
qemu-img create -f qcow2 vm-disk-debian-12.qcow2 20G

# convert vmdk to qcow2 image
qemu-img convert \
  -f vmdk \
  -O qcow2 os-images/Debian_12.0.0_VMM/Debian_12.0.0_VMM_LinuxVMImages.COM.vmdk os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -p \
  -m16

# check image
qemu-img info os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2
```

##### Qemu-System-X86_64

```sh
# create vm with ISO
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm -hda vm-disk-debian-12.qcow2 \
  -cdrom /home/vagrant/isos/debian/debian-12.8.0-amd64-DVD-1.iso  \
  -boot d \
  -m 2048 \
  -smp cpus=2 \
  -k pt-br

# create vm with ISO using vnc in no gui servers \ ssh connections

## create ssh tunel in host
 ssh -l vagrant -L 5902:localhost:5902  192.168.0.131

## create vm 
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -k pt-br \
  -vnc :2 \
  -device qemu-xhci \
  -device usb-tablet \
  -device ide-cd,bus=ide.1,drive=cdrom,bootindex=1 \
  -drive id=cdrom,media=cdrom,if=none,file=/home/vagrant/isos/debian/debian-12.8.0-amd64-DVD-1.iso \
  -hda vm-disk-debian-12.qcow2 \
  -boot order=d \
  -vga std \
  -display none \
  -monitor stdio

# create vm with OS Image - qcow2

## create vm
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -k pt-br \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2

## create vm with custom kernel params
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -kernel /vmlinuz \
  -initrd /initrd.img \
  -append "root=/dev/mapper/debian--vg-root ro fastboot console=ttyS0" \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -k pt-br \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2

## create vm with and attach disk
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -hdb vmdisk-debian12.qcow2 \
  -drive file=vmdisk-extra-debian12.qcow2,index=2,media=disk,if=ide \
  -netdev bridge,id=net0,br=qemubr0 \
  -device virtio-net-pci,netdev=net0
  
## create vm network netdev user
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -netdev user,id=mynet0,net=192.168.0.150/24,dhcpstart=192.168.0.155,hostfwd=tcp::2222-:22 \
  -device virtio-net-pci,netdev=mynet0

## create vm network netdev tap (Private Network)
ip link add br0 type bridge ; ifconfig br0 up
qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -vnc :2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -netdev tap,id=br0 \
  -device e1000,netdev=br0,mac=DE:AD:BE:EF:1A:24

## create vm with public bridge
#create a public bridge : https://www.linux-kvm.org/page/Networking

qemu-system-x86_64 \
  -name lpic3-debian-12 \
  -enable-kvm \
  -m 2048 \
  -smp cpus=2 \
  -hda os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -k pt-br \
  -vnc :2 \
  -device qemu-xhci \
  -device usb-tablet \
  -vga std \
  -display none \
  -netdev bridge,id=net0,br=qemubr0 \
  -device virtio-net-pci,netdev=net0

## get a ipv4 ip - open ssh in vm and:
dhcpclient ens4
```

#### Monitor qemu

Para iniciar o monitor Qemu no uso de linha de comando**-Monitor stdio**param in**Qemu-System-X86_64**

```sh
qemu-system-x86_64 -monitor stdio
```

Saia Qemu-Monitor:

```sh
ctrl+alt+2
```

```sh
# Managment
info status # vm info
info cpus # cpu information
info network # network informations
stop # pause vm
cont # start vm in status pause
system_powerdown # poweroff vm
system_reset # restart monitor


# Blocks
info block # block info
boot_set d # force boot iso
change ide1-cd0  /home/vagrant/isos/debian/debian-12.8.0-amd64-DVD-1.iso  # attach cdrom
eject ide1-cd0 # detach cdrom

# Snapshots
info snapshots # list snapshots
savevm snapshot-01  # create snapshot
loadvm snapshot-01 # restore snapshot
delvm snapshot-01
```

#### Agente convidado

Para ativar, use:

```sh
qemu-system-x86_x64
 -chardev socket,path=/tmp/qga.sock,server=on,wait=off,id=qga0 \
 -device virtio-serial \
 -device virtserialport,chardev=qga0,name=org.qemu.guest_agent.0
```

<p align="right">(<a href="#topic-351.3">back to sub Topic 351.3</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351.4"></a>

### 351.4 LibVirt M√°quina virtual Gerenciamento

![libvirt](images/libvirt.png)

![libvirt-network](images/libvirt-default-network.jpg)

**Peso:**9

**Descri√ß√£o:**Os candidatos devem ser capazes de gerenciar hosts de virtualiza√ß√£o e m√°quinas virtuais ('LibVirt Domains') usando o LibVirt e as ferramentas relacionadas.

**Principais √°reas de conhecimento:**

-   Entenda a arquitetura do Libvirt
-   Gerenciar conex√µes e n√≥s da LibVirt
-   Crie e gerencie dom√≠nios qemu e xen, incluindo instant√¢neos
-   Gerenciar e analisar o consumo de recursos de dom√≠nios
-   Crie e gerencie pools e volumes de armazenamento
-   Crie e gerencie redes virtuais
-   Migrar dom√≠nios entre n√≥s
-   Entenda como o LibVirt interage com Xen e Qemu
-   Entenda como a LibVirt interage com servi√ßos de rede, como Dnsmasq e RadVD
-   Entenda os arquivos de configura√ß√£o do LibVirt XML
-   Consci√™ncia de VirtLogd e Virtlockd

#### 351.4 Objetos citados

```sh
libvirtd
/etc/libvirt/
/var/lib/libvirt
/var/log/libvirt
virsh (including relevant subcommands) 
```

#### 351.4 Comandos importantes

##### Virsh

```sh
# using env variable for set virsh uri (local or remotly)
export LIBVIRT_DEFAULT_URI=qemu:///system
export LIBVIRT_DEFAULT_URI=xen+ssh://vagrant@192.168.0.130
export LIBVIRT_DEFAULT_URI='xen+ssh://vagrant@192.168.0.130?keyfile=/home/vagrant/.ssh/skynet-key-ecdsa'

# COMMONS

# get helps
virsh help
virsh help pool-create

# view version
virsh version

# view system info
sudo virsh sysinfo

# view node info
virsh nodeinfo

# hostname
virsh hostname

# check vcn allocated port
virsh vncdisplay <domain_id>
virsh vncdisplay <domain_name>
virsh vncdisplay rocky9-server01 

# HYPERVISIONER

# view libvirt hypervisioner connection
virsh uri

# list valid hypervisioners
virt-host-validate
virt-host-validate qemu

# test connetion uri(vm test)
virsh -c test:///default list

# connect remotly
virsh -c xen+ssh://vagrant@192.168.0.130
virsh -c xen+ssh://vagrant@192.168.0.130 list
virsh -c qemu+ssh://vagrant@192.168.0.130/system list

# connect remotly without enter password
virsh -c 'xen+ssh://vagrant@192.168.0.130?keyfile=/home/vagrant/.ssh/skynet-key-ecdsa'

# STORAGE

# list storage pools
virsh pool-list --details

# list all storage pool
virsh pool-list --all --details

# get a pool configuration
virsh pool-dumpxml default

# get pool info
virsh pool-info default

# create a storage pool
virsh pool-define-as --name default --type dir --target /var/lib/libvirt/images

# create a storage pool with dumpxml
virsh pool-create --overwrite --file configs/kvm/libvirt/pool.xml

# start storage pool
virsh pool-start default

# set storage pool for autostart
virsh pool-autostart default

# stop storage pool
virsh pool-destroy linux

# delete xml storage pool file
virsh pool-undefine linux

# edit storage pool
virsh pool-edit linux

# list volumes
virsh vol-list linux

# get volume infos
virsh vol-info Debian_12.0.0.qcow2 os-images
virsh vol-info --pool os-images Debian_12.0.0.qcow2 

# get volume xml
virsh vol-dumpxml rocky9-disk1 default

# create volume
virsh vol-create-as default --format qcow2 disk1 10G

# delete volume
virsh vol-delete  disk1 default

# DOMAINS \ INSTANCES \ VIRTUAL MACHINES

# list domain\instance\vm
virsh list
virsh list --all

# create domain\instance\vm
virsh create configs/kvm/libvirt/rocky9-server03.xml

# view domain\instance\vm info
virsh dominfo rocky9-server01

# view domain\instance\vm xml
virsh dumpxml rocky9-server01

# edit domain\instance\vm xml
virsh edit rocky9-server01

# stop domain\instance\vm
virsh shutdown rocky9-server01 # gracefully
virsh destroy 1
virsh destroy rocky9-server01

# suspend domain\instance\vm
virsh suspend rocky9-server01

# resume domain\instance\vm
virsh resume rocky9-server01

# start domain\instance\vm
virsh start rocky9-server01

# remove domain\instance\vm
virsh undefine rocky9-server01

# remove domain\instance\vm and storage volumes
virsh undefine rocky9-server01 --remove-all-storage

# save domain\instance\vm
virsh save rocky9-server01 rocky9-server01.qcow2

# restore domain\instance\vm
virsh restore rocky9-server01.qcow2

# list snapshots
virsh snapshot-list rocky9-server01

# create snapshot
virsh snapshot-create rocky9-server01

# restore snapshot
virsh snapshot-revert rocky9-server01 1748983520

# view snapshot xml
virsh snapshot-info rocky9-server01 1748983520

# dumpxml snapshot
virsh snapshot-dumpxml rocky9-server01 1748983520

# xml snapshot path
/var/lib/libvirt/qemu/snapshot/rocky9-server01/

# view snapshot info
virsh snapshot-info rocky9-server01 1748983671

# edit snapshot
virsh snapshot-edit rocky9-server01 1748983520

# delete snapshot
virsh snapshot-delete rocky9-server01 1748983520

# DEVICES

# list block devices
virsh domblklist rocky9-server01 --details

# add cdrom media 
virsh change-media rocky9-server01 sda /home/vagrant/isos/rocky/Rocky-9.5-x86_64-minimal.iso
virsh attach-disk rocky9-server01 /home/vagrant/isos/rocky/Rocky-9.5-x86_64-minimal.iso sda --type cdrom --mode readonly

# remove cdrom media
virsh change-media rocky9-server01 sda --eject

# add new disk
virsh attach-disk rocky9-server01  /var/lib/libvirt/images/rocky9-disk2  vdb --persistent

# remove disk
virsh detach-disk rocky9-server01 vdb --persistent

# RESOURCES (CPU and Memory)

# get cpu infos
virsh vcpuinfo rocky9-server01 --pretty
virsh dominfo rocky9-server01 | grep 'CPU'

# get vcpu count
virsh vcpucount rocky9-server01

# set vcpus maximum config
virsh setvcpus rocky9-server01 --count 4 --maximum --config
virsh shutdown rocky9-server01
virsh start rocky9-server01

# set vcpu current config
virsh setvcpus rocky9-server01 --count 4 --config

# set vcpu current live
virsh setvcpus rocky9-server01 --count 3 --current
virsh setvcpus rocky9-server01 --count 3 --live

# configure vcpu afinity config
virsh vcpupin rocky9-server01 0 7 --config
virsh vcpupin rocky9-server01 1 5-6 --config

# configure vcpu afinity current
virsh vcpupin rocky9-server01 0 7
virsh vcpupin rocky9-server01 1 5-6

# set maximum memory config
virsh setmaxmem rocky9-server01 3000000 --config
virsh shutdown rocky9-server01
virsh start rocky9-server01

# set current memory config
virsh setmem rocky9-server01 2500000 --current

# NETWORK

# get netwwork bridges
brctl show

# get iptables rules for libvirt
sudo iptables -L -n -t  nat

# list network
virsh net-list --all

# set default network
virsh net-define /etc/libvirt/qemu/networks/default.xml

# get network infos
virsh net-info default

# get xml network
virsh net-dumpxml default

# xml file
cat /etc/libvirt/qemu/networks/default.xml

# dhcp config
sudo cat /etc/libvirt/qemu/networks/default.xml | grep -A 10 dhcp
sudo cat /var/lib/libvirt/dnsmasq/default.conf

# get domain ipp address
virsh net-dhcp-leases default
virsh net-dhcp-leases default --mac 52\:54\:00\:89\:19\:86

# edit network
virsh net-edit default

# get domain network detais
virsh domiflist debian-server01

# path for network filter files
/etc/libvirt/nwfilter/

# list network filters
virsh nwfilter-list

# create network filter - block icmp traffic
virsh nwfilter-define block-icmp.xml
# virsh edit Debian-Server
    #  <interface type='network'>
    #        ...
    #        <filterref filter='block-icmp'/>
    #        ...
    # </interface>
# virsh destroy debian-server01
# virsh start debian-server01

# delete network filter
virsh nwfilter-undefine block-icmp

# get xml network filter
virsh nwfilter-dumpxml block-icmp
```

###### Virt-Install

```sh
# list os variants
virt-install --os-variant list
osinfo-query os

# create domain\instance\vm with iso file
virsh vol-create-as default --format qcow2 rocky9-disk1 20G
virt-install --name rocky9-server01 \
--vcpus 2 \
--cpu host \
--memory 2048 \
--disk vol=default/rocky9-disk1 \
--cdrom /home/vagrant/isos/rocky/Rocky-9.5-x86_64-minimal.iso \
--os-variant=rocky9 \
--graphics vnc,listen=0.0.0.0,port=5905

# create debian domain\instance\vm with qcow2 file
virt-install --name debian-server01 \
--vcpus 2 \
--ram 2048 \
--disk vol=os-images/Debian_12.0.0.qcow2 \
--import \
--osinfo detect=on \
--graphics vnc,listen=0.0.0.0,port=5906 \
--network network=default \
--noautoconsole

# create rocky9 domain\instance\vm with qcow2 file
virt-install --name rocky9-server02 \
--vcpus 2 \
--ram 2048 \
--disk path=os-images/RockyLinux_9.4_VMG/RockyLinux_9.4.qcow2,format=qcow2,bus=virtio \
--import \
--osinfo detect=on \
--graphics vnc,listen=0.0.0.0,port=5907 \
--network bridge=qemubr0,model=virtio \
--noautoconsole

# open domain\instance\vm gui console
virt-viewer debian-server01

# check metadata domain\instance\vm file (if uri is qemu:////system)
less /etc/libvirt/qemu/debian-server01.xml
```

<p align="right">(<a href="#topic-351.4">back to sub Topic 351.4</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-351.5"></a>

### 351.5 Gerenciamento de imagem em disco da m√°quina virtual

![disk-managment](images/virtual-machine-disk.png)

**Peso:**3

**Descri√ß√£o:**Os candidatos devem poder gerenciar imagens de disco de m√°quinas virtuais. Isso inclui a convers√£o de imagens de disco entre v√°rios formatos e hipervisores e acesso a dados armazenados em uma imagem.

**Principais √°reas de conhecimento:**

-   Entenda os recursos de v√°rios formatos de imagem de disco virtual, como imagens cruas, QCOW2 e VMDK
-   Gerenciar imagens de disco da m√°quina virtual usando Qemu-IMG
-   Monte Parti√ß√µes e Arquivos de Acesso contidos em imagens de disco da m√°quina virtual usando LibGuestfish
-   Copie o conte√∫do do disco f√≠sico para uma imagem de disco da m√°quina virtual
-   Migrar o conte√∫do do disco entre v√°rios formatos de imagem de disco da m√°quina virtual
-   Consci√™ncia do formato de virtualiza√ß√£o aberta (OVF)

#### 351.5 Objetos citados

```sh
qemu-img
guestfish (including relevant subcommands)
guestmount
guestumount
virt-cat
virt-copy-in
virt-copy-out
virt-diff
virt-inspector
virt-filesystems
virt-rescue
virt-df
virt-sparsify
virt-p2v
virt-p2v-make-disk
virt-v2v
```

#### 351.5 Comandos importantes

##### 351.5.1 Qemu-img

```sh
# Display detailed information about a disk image
qemu-img info UbuntuServer_24.04.qcow2

# Create a new 22G raw disk image (default format is raw)
qemu-img create new-disk 22G

# Create a new 22G disk image in qcow2 format
qemu-img create -f qcow2 new-disk2 22G

# Convert a VDI image to raw format using 5 threads and show progress
qemu-img convert -f vdi -O raw Ubuntu-Server.vdk new-Ubuntu.raw -m5 -p

# Convert vmdk to qcow2 image
qemu-img convert \
-f vmdk \
-O qcow2 os-images/UbuntuServer_24.04_VM/UbuntuServer_24.04_VM_LinuxVMImages.COM.vmdk \
os-images/UbuntuServer_24.04_VM/UbuntuServer_24.04.qcow2 \
-p \
-m16

# Resize a raw image to 30G
qemu-img resize -f raw new-disk 30G

# Resize a qcow2 image to 15G(actual size 30Gdisk 30G)
qemu-img resize -f raw --shrink new-disk 15G

# Snapshots

# List all snapshots in the image
qemu-img snapshot -l new-disk2.qcow2

# Create a snapshot named SNAP1
qemu-img snapshot -c SNAP1 disk

# Apply a snapshot by ID or name
qemu-img snapshot -a 123456789 disk

# Delete the snapshot named SNAP1
qemu-img snapshot -d SNAP1 disk
```

##### peixe -convidado

```sh
# set enviroment variables for guestfish
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg

# Launch guestfish with a disk image
guestfish -a UbuntuServer_24.04.qcow2
#run
#list-partitions

# Run the commands in a script file
guestfish -a UbuntuServer_24.04.qcow2 -m /dev/sda -i < script.ssh

# Interactively run commands
guestfish --rw -a UbuntuServer_24.04.qcow2 <<'EOF'
run
list-filesystems
EOF

# Copy a file from the guest image to the host
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
sudo guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
copy-out /etc/hostname /tmp/
EOF

# Copy a file from the host into the guest image
echo "new-hostname" > /tmp/hostname
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
sudo guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
copy-in /tmp/hostname /etc/
EOF

# View contents of a file in the guest image
guestfish --ro -a UbuntuServer_24.04.qcow2 -i <<'EOF'
cat /etc/hostname
EOF

# List files in the guest image
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
ls /home/ubuntu
EOF

# Edit a file in the guest image
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
edit /etc/hosts
EOF
```

###### CONGUIDADE

```sh
# Mount a disk image to a directory
guestmount -a UbuntuServer_24.04.qcow2 -m /dev/ubuntu-vg/ubuntu-lv /mnt/ubuntu
# domain
guestmount -d rocky9-server02 -m /dev/ubuntu-vg/ubuntu-lv /mnt/ubuntu 

# Mount a specific partition from a disk image
guestmount -a UbuntuServer_24.04.qcow2 -m /dev/sda2 /mnt/ubuntu
# domain
guestmount -d debian-server01 --ro -m  /dev/debian-vg/root /mnt/debian
```

###### GuestUmount

```sh
# Umount a disk image to a directory
sudo guestunmount /mnt/ubuntu
```

##### virt-df

```sh
# Show free and used space on virtual machine filesystems
virt-df UbuntuServer_24.04.qcow2 -h
virt-df -d rocky9-server02 -h
```

##### Virt-Filesystems

```sh
# List filesystems, partitions, and logical volumes in a VM disk image (disk image)
virt-filesystems -a UbuntuServer_24.04.qcow2 --all --long -h

# List filesystems, partitions, and logical volumes in a VM disk image (domain)
virt-filesystems -d debian-server01 --all --long -h
```

##### Virt-Inspetor

```sh
# Inspect and report on the operating system in a VM disk image
virt-inspector -a UbuntuServer_24.04.qcow2 #(disk)
virt-inspector -d debian-server01 #(domain) 
```

##### Virt-Cat

```sh
# Display the contents of a file inside a VM disk image
virt-cat -a UbuntuServer_24.04.qcow2 /etc/hosts
virt-cat -d debian-server01 /etc/hosts #(domain)
```

##### Virt-Diff

```sh
# Show differences between two VM disk images
virt-diff -a UbuntuServer_24.04.qcow2 -A Rocky-Linux.qcow2
```

##### virt-sparsify

```sh
# Make a VM disk image smaller by removing unused space
virt-sparsify UbuntuServer_24.04.qcow2 UbuntuServer_24.04-sparse.qcow2
```

##### Virt-resize

```sh
# Resize a VM disk image or its partitions
virt-filesystems -a UbuntuServer_24.04.qcow2 --all --long -h #(check size of partitions)
qemu-img create -f qcow2 UbuntuServer_24.04-expanded.qcow2 100G #(create new disk image with 100G)
virt-resize --expand /dev/ubuntu-vg/ubuntu-lv \
UbuntuServer_24.04.qcow2 UbuntuServer_24.04-expanded.qcow2

```

##### Virt-copy-in

```sh
# Copy files from the host into a VM disk image

virt-copy-in -a UbuntuServer_24.04.qcow2 ~vagrant/test-virt-copy-in.txt /home/ubuntu
```

##### Virt-copy-out

```sh
# Copy files from a VM disk image to the host
virt-copy-out -a UbuntuServer_24.04.qcow2 /home/ubuntu/.bashrc /tmp
```

##### virt-ls

```sh
# List files and directories inside a VM disk image
virt-ls -a UbuntuServer_24.04.qcow2 /home/ubuntu
```

##### Virt-rescue

```sh
# Launch a rescue shell on a VM disk image for recovery
virt-rescue -a UbuntuServer_24.04.qcow2
```

##### Virt-sysprep

```sh
# Prepare a VM disk image for cloning by removing system-specific data
virt-sysprep -a UbuntuServer_24.04.qcow2
```

##### virt-v2v

```sh
# Convert a VM from a foreign hypervisor to run on KVM
virt-v2v -i disk input-disk.img -o local -os /var/tmp
```

##### Virt-P2V

```sh
# Convert a physical machine to use KVM
```

##### Virt-P2V-Make-Disk

```sh
# Create a bootable disk image for physical to virtual conversion
sudo virt-p2v-make-disk -o output.img
```

#### 351.5 Notas

##### OVF: Formato de virtualiza√ß√£o aberto

OVF: um formato aberto que define um padr√£o para embalagem e distribui√ß√£o de m√°quinas virtuais em diferentes ambientes.

O pacote gerado possui a extens√£o .ova e cont√©m os seguintes arquivos:

-   .ovf: arquivo xml com metadados definindo o ambiente da m√°quina virtual
-   Arquivos de imagem: .vmdk, .vhd, .vhdx, .qcow2, .raw
-   Arquivos adicionais: metadados, instant√¢neos, configura√ß√£o, hash

<p align="right">(<a href="#topic-351.5">back to sub Topic 351.5</a>)</p>
<p align="right">(<a href="#topic-351">back to Topic 351</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-352"></a>

## T√≥pico 352: Virtualiza√ß√£o de cont√™ineres

* * *

<a name="topic-352.1"></a>

### 352.1 conceitos de virtualiza√ß√£o de cont√™ineres

![virtualization-container](images/virtualization-container.png)

```mermaid
timeline
    title Time Line Containers Evolution
    1979 : chroot
    2000 : FreeBSD Jails
    2002 : Linux Namespaces
    2005 : Solaris Containers
    2007 : cgroups
    2008 : LXC
    2013 : Docker
    2015 : Kubernetes
```

* * *

**Peso:**7

**Descri√ß√£o:**Os candidatos devem entender o conceito de virtualiza√ß√£o de cont√™ineres. Isso inclui a compreens√£o dos componentes do Linux usados ‚Äã‚Äãpara implementar a virtualiza√ß√£o de cont√™ineres, bem como usar as ferramentas padr√£o do Linux para solucionar esses componentes.

**Principais √°reas de conhecimento:**

-   Entenda os conceitos de sistema e cont√™iner de aplicativos
-   Entender e analisar namespaces de kernel
-   Entender e analisar grupos de controle
-   Entender e analisar recursos
-   Entenda o papel do Seccomp, Selinux e Apparmor for Container Virtualization
-   Entenda como o LXC e o Docker alavancam namespaces, cgroups, recursos, Seccomp e Mac
-   Entenda o princ√≠pio de Runc
-   Entenda o princ√≠pio de Cri-O e Containerd
-   Consci√™ncia das especifica√ß√µes de tempo de execu√ß√£o da OCI e imagem
-   Consci√™ncia da interface de tempo de execu√ß√£o do cont√™iner Kubernetes (CRI)
-   Consci√™ncia de Podman, Buildah e Scopeo
-   Consci√™ncia de outras abordagens de virtualiza√ß√£o de cont√™ineres no Linux e em outros sistemas operacionais gratuitos, como RKT, OpenVZ, Systemd-Nspawn ou BSD pris√µes

* * *

#### 352.1 Objetos citados

```sh
nsenter
unshare
ip (including relevant subcommands)
capsh
/sys/fs/cgroups
/proc/[0-9]+/ns
/proc/[0-9]+/status
```

* * *

#### üß† Entendendo os recipientes

![container](images/containers1.png)

Os cont√™ineres s√£o uma tecnologia de virtualiza√ß√£o leve que empacota aplicativos, juntamente com as depend√™ncias necess√°rias - c√≥digo, bibliotecas, vari√°veis ‚Äã‚Äãde ambiente e arquivos de configura√ß√£o - em unidades isoladas, port√°teis e reproduz√≠veis.

> Em termos simples: um cont√™iner √© uma caixa independente que executa seu aplicativo da mesma maneira, em qualquer lugar.

##### üí° O que √© um cont√™iner?

Ao contr√°rio das m√°quinas virtuais (VMs), os cont√™ineres n√£o virtualizam o hardware. Em vez disso, eles virtualizam o sistema operacional. Os cont√™ineres compartilham o mesmo kernel Linux com o host, mas cada um opera em um espa√ßo de usu√°rio totalmente isolado.

üìå Recipientes versus m√°quinas virtuais:

| Recurso                 | Cont√™ineres                     | M√°quinas virtuais                           |
| ----------------------- | ------------------------------- | ------------------------------------------- |
| OS Kernel               | Compartilhado com o host        | Cada VM tem seu pr√≥prio sistema operacional |
| Hora de inicializa√ß√£o   | R√°pido (segundos ou menos)      | Lento (minutos)                             |
| Tamanho da imagem       | Leve (MBS)                      | Pesado (GBS)                                |
| Efici√™ncia de recursos  | Alto                            | Mais baixo                                  |
| Mecanismo de isolamento | Recursos de kernel (namespaces) | Hipervisor                                  |

##### üîë Caracter√≠sticas -chave dos cont√™ineres

üîπ**Leve**: Compartilhe o kernel do OS host, reduzindo a sobrecarga e permitindo uma inicializa√ß√£o r√°pida.

üîπ**Port√°til**: Execute de forma consistente em diferentes ambientes (dev, estadiamento, Prod, Cloud, On-Prem).

üîπ**Isolado**: Use namespaces para isolamento de processo, rede e sistema de arquivos.

üîπ**Eficiente**: Habilite maior densidade e melhor utiliza√ß√£o de recursos do que as VMs tradicionais.

üîπ**Escal√°vel**: Ajuste perfeito para microsservi√ßos e arquitetura nativa em nuvem.

##### üß± Tipos de recipientes

1.  Cont√™ineres do sistema

    -   Projetado para executar o sistema operacional inteiro, assemelhar -se a m√°quinas virtuais.
    -   Suporte a v√°rios processos e servi√ßos do sistema (init, syslog).
    -   Ideal para aplica√ß√µes legadas ou monol√≠ticas.
    -   Exemplo: lxc, libvirt-lxc.
2.  Cont√™ineres de aplica√ß√£o

    -   Projetado para executar um √∫nico processo.
    -   Sem estado, ef√™mero e horizontalmente escal√°vel.
    -   Utilizado amplamente em ambientes modernos de DevOps e Kubernetes.
    -   Exemplo: Docker, Containerd, Cri-O.

##### üöÄ Tempos de cont√™ineres populares

| Tempo de execu√ß√£o | Descri√ß√£o                                                                                 |
| ----------------- | ----------------------------------------------------------------------------------------- |
| **Docker**        | A CLI/daemon mais amplamente adotada para construir e executar recipientes.               |
| **cont√™iner**     | Docker e Kubernetes com tempo de execu√ß√£o leves.                                          |
| **CRI-O**         | Tempo de execu√ß√£o nativo de Kubernetes para cont√™ineres OCI.                              |
| **LXC**           | Cont√™ineres tradicionais do sistema Linux, mais pr√≥ximos do sistema operacional completo. |
| **Rkt**           | Tempo de execu√ß√£o focado na seguran√ßa (depreciado).                                       |

##### üîê Interna√ß√µes de cont√™ineres e elementos de seguran√ßa

| Componente            | Papel                                                                  |
| --------------------- | ---------------------------------------------------------------------- |
| **Namespaces**        | Isolar processos, usu√°rios, montagens, redes.                          |
| **CGROUPS**           | Controle e limite o uso de recursos (CPU, mem√≥ria, IO).                |
| **Recursos**          | Controle de privil√©gios de granula√ß√£o fina dentro de recipientes.      |
| **Seccomp**           | Restringem os syscalls permitidos para reduzir a superf√≠cie de ataque. |
| **APARMOR / SELinux** | Execu√ß√£o obrigat√≥ria de controle de acesso no n√≠vel do kernel.         |

* * *

#### üß† Entendendo o Chroot - Alterar o diret√≥rio raiz no Unix/Linux

![chroot](images/chroot.png)

##### O que √© chroot?

O Chroot (abrevia√ß√£o de ROOTE de mudan√ßa) √© uma chamada e comando do sistema em sistemas operacionais do tipo UNIX que altera o diret√≥rio raiz aparente (/) para o processo de execu√ß√£o atual e seus filhos. Isso cria um ambiente isolado, comumente referido como uma pris√£o de chroot.

##### üß± Casos de prop√≥sito e uso

-   üîí Isolar solicita√ß√µes de seguran√ßa (pris√£o).
-   üß™ Crie ambientes de teste sem afetar o restante do sistema.
-   Recovery Recupera√ß√£o do sistema (por exemplo, inicializa√ß√£o no LiveCD e Chroot no sistema instalado).
-   üì¶ Construindo pacotes de software em um ambiente controlado.

##### üìÅ Estrutura m√≠nima necess√°ria

O ambiente de chroot deve ter seus pr√≥prios arquivos e estrutura essenciais:

```sh
/mnt/myenv/
‚îú‚îÄ‚îÄ bin/
‚îÇ   ‚îî‚îÄ‚îÄ bash
‚îú‚îÄ‚îÄ etc/
‚îú‚îÄ‚îÄ lib/
‚îú‚îÄ‚îÄ lib64/
‚îú‚îÄ‚îÄ usr/
‚îú‚îÄ‚îÄ dev/
‚îú‚îÄ‚îÄ proc/
‚îî‚îÄ‚îÄ tmp/
```

Use LDD para identificar as bibliotecas necess√°rias:

```sh
ldd /bin/bash
```

##### üö® Limita√ß√µes e considera√ß√µes de seguran√ßa

-   Chroot n√£o √© um limite de seguran√ßa como recipientes ou VMs.
-   Um usu√°rio privilegiado (root) dentro da pris√£o pode potencialmente sair.
-   Nenhum isolamento de namespaces de processo, dispositivos ou recursos no n√≠vel do kernel.

Para um isolamento mais forte, considere alternativas como:

-   Cont√™ineres Linux (LXC, Docker)
-   M√°quinas Virtuais (KVM, Qemu)
-   Namespaces de kernel e cgroups

##### üß™ Teste o chroot com Debootstrap

```sh
# download debain files
sudo debootstrap stable ~vagrant/debian http://deb.debian.org/debian
sudo chroot ~vagrant/debian bash
```

##### : üß™ CHROOT LAB

Use este script para laborat√≥rio:[chroot.sh](scripts/container/chroot.sh)

[![asciicast](https://asciinema.org/a/PWkjazgTXll9678Qy6LLOaKdN.svg)](https://asciinema.org/a/PWkjazgTXll9678Qy6LLOaKdN)

* * *

#### üß† Entendendo namespaces Linux

![linux-namespaces](images/linux-namespaces2.png)

Os namespaces s√£o um recurso principal do kernel Linux que permite o isolamento no n√≠vel do processo. Eles criam "visualiza√ß√µes" separadas dos recursos globais do sistema - como IDs de processo, redes, sistemas de arquivos e usu√°rios - para que cada grupo de processos acredite que est√° em execu√ß√£o em seu pr√≥prio sistema.

> Em termos simples: os namespaces enganam um processo a pensar que ele √© dono da m√°quina, mesmo que esteja apenas compartilhando -a.

Esta √© a base para o isolamento de cont√™ineres.

##### üîç O que os namespaces isolam?

Cada tipo de espa√ßo para nome isola um recurso espec√≠fico do sistema. Juntos, eles comp√µem a caixa de areia em que um cont√™iner opera:

| Espa√ßo para nome | Isolados ...                              | Exemplo do mundo real                                           |
| ---------------- | ----------------------------------------- | --------------------------------------------------------------- |
| **PID**          | IDs de processo                           | Processos dentro de um recipiente, veja um espa√ßo PID diferente |
| **Montar**       | Pontos de montagem do sistema de arquivos | Cada cont√™iner v√™ seu pr√≥prio sistema de arquivos raiz          |
| **Rede**         | Pilha de rede                             | Cont√™ineres t√™m IPs isolados, interfaces e rotas                |
| **Uts**          | Nome de host e nome de dom√≠nio            | Cada cont√™iner define seu pr√≥prio nome de host                  |
| **IPC**          | Mem√≥ria compartilhada e sem√°foros         | Impede a comunica√ß√£o entre processos entre cont√™ineres          |
| **Usu√°rio**      | IDs de usu√°rio e grupo                    | Ativa a raiz falsa (UID 0) dentro do recipiente                 |
| **CGROUP (V2)**  | Associa√ß√£o do grupo de controle           | La√ßos em controles de recursos como CPU e limites de mem√≥ria    |

##### üß™ Analogia visual

![linux-namespaces](images/linux-namespaces.png)

Imagine um pr√©dio de escrit√≥rios compartilhado:

-   Todos os inquilinos compartilham a mesma base (Linux Kernel).
-   Cada empresa possui seu pr√≥prio escrit√≥rio (espa√ßo para nome): bloqueios diferentes, m√≥veis, linhas telef√¥nicas e nome da empresa.
-   Para cada inquilino, parece seu pr√≥prio pr√©dio.

√â exatamente assim que os cont√™ineres experimentam o sistema - isolados, mas eficientes.

##### üîß Como os cont√™ineres usam namespaces

Quando voc√™ executa um cont√™iner (por exemplo, com Docker ou Podman), o tempo de execu√ß√£o cria um novo conjunto de espa√ßos para nome:

```bash
docker run -it --rm alpine sh
```

Este comando fornece o processo:

-   Um novo espa√ßo para nome de PID ‚Üí √© o processo 1 dentro do cont√™iner.
-   Um novo espa√ßo para nome de rede ‚Üí sua pr√≥pria Ethernet virtual.
-   Um espa√ßo para nome de montagem ‚Üí Um sistema de arquivos raiz espec√≠fico do cont√™iner.
-   Outros espa√ßos para nome, dependendo da configura√ß√£o (usu√°rio, IPC, etc.)

O resultado: um ambiente de tempo de execu√ß√£o leve e isolado que se comporta como um sistema separado.

##### ‚öôÔ∏è Recursos de kernel complementares

Os namespaces oculam recursos de cont√™ineres. Mas para controlar o quanto eles podem usar e o que podem fazer, precisamos de mecanismos adicionais:

###### üî© CGROUPS (Grupos de controle)

Os cgroups permitem que o kernel limite, priorize e monitore o uso de recursos entre os grupos de processos.

| Recurso      | Use exemplos de casos                       |
| ------------ | ------------------------------------------- |
| CPU          | Limitar o tempo da CPU por cont√™iner        |
| Mem√≥ria      | Cap Ram Uso                                 |
| E/S de disco | Opera√ß√µes de leitura/grava√ß√£o do acelerador |
| Rede (V2)    | Restri√ß√µes de largura de banda              |

üõ°Ô∏è Impede o problema "vizinho barulhento", impedindo que um cont√™iner consumindo todos os recursos do sistema.

###### üß± Capacidades

O Linux tradicional usa um modelo de privil√©gio bin√°rio: raiz (UID 0) pode fazer tudo, todo mundo √© limitado.

| Capacidade             | Permite ...                                                   |
| ---------------------- | ------------------------------------------------------------- |
| `CAP_NET_BIND_SERVICE` | Liga√ß√£o a portas privilegiadas (por exemplo, 80, 443)         |
| `CAP_SYS_ADMIN`        | Uma poderosa captura para tarefas de administra√ß√£o do sistema |
| `CAP_KILL`             | Enviando sinais para processos arbitr√°rios                    |

Ao soltar recursos desnecess√°rios, os cont√™ineres podem executar apenas o que precisam - reduzindo o risco.

##### üîê Mecanismos de seguran√ßa

Usado em conjunto com namespaces e cgroups para bloquear o que um processo cont√™iner pode fazer:

| Recurso     | Descri√ß√£o                                                                   |
| ----------- | --------------------------------------------------------------------------- |
| **Seccomp** | Lista de permiss√µes ou bloqueios de chamadas do sistema Linux (syscalls)    |
| **APARMOR** | Aplicar perfis de seguran√ßa por aplica√ß√£o                                   |
| **Selinux** | Aplicar o controle de acesso obrigat√≥rio com pol√≠ticas de sistema apertadas |

##### üß† Resumo para iniciantes

> ‚úÖ Namespaces Isolle o que um cont√™iner pode ver
> ‚úÖ CGROUPS Controle o que pode usar
> ‚úÖ Capacidades e m√≥dulos de seguran√ßa definem o que pode fazer

Juntos, esses recursos do kernel formam a espinha dorsal t√©cnica do isolamento de cont√™ineres-permitindo implanta√ß√£o de aplica√ß√£o de alta densidade, seguran√ßa e efici√™ncia sem VMs completas.

##### üß™ Namespaces de laborat√≥rio

Use este script para laborat√≥rio:[namespace.sh](scripts/container/namespace.sh)

[![asciicast](https://asciinema.org/a/8H6iczCMO24VgjWqwCcXEKWBG.svg)](https://asciinema.org/a/8H6iczCMO24VgjWqwCcXEKWBG)

* * *

#### üß© Entendendo os cgroups (grupos de controle)

![cgroups](images/cgroups1.png)

##### üìå Defini√ß√£o

Os grupos de controle (CGROUPS) s√£o um recurso Linux Kernel introduzido em 2007 que permite limitar, explicar e isolar o uso de recursos (CPU, mem√≥ria, E/S de disco, etc.) de grupos de processos.

Os cgroups s√£o fortemente usados ‚Äã‚Äãpor tempos de execu√ß√£o de cont√™ineres de baixo n√≠vel, como Runc e Crun, e alavancados por motores de cont√™ineres como Docker, Podman e LXC para aplicar os limites dos recursos e fornecer isolamento entre os cont√™ineres.

Os namespaces isolam o controle de cgroups.

Os namespaces criam ambientes separados para processos (como PID, rede ou montagens), enquanto o CGROUPS limitam e monitoram o uso de recursos (CPU, mem√≥ria, E/S) para esses processos.

‚öôÔ∏è Capacidades -chave

| Recurso                   | Descri√ß√£o                                                        |
| ------------------------- | ---------------------------------------------------------------- |
| **Limita√ß√£o de recursos** | Impor limites para quanto de um recurso um grupo pode usar       |
| **Prioriza√ß√£o**           | Alocar mais prioridade da CPU/IO para alguns grupos sobre outros |
| **Contabilidade**         | Rastrear o uso de recursos por grupo                             |
| **Controlar**             | Suspender, retomar ou matar processos a granel                   |
| **Isolamento**            | Impedir a fome de recursos entre os grupos                       |

##### üì¶ Subsistemas (controladores)

Os cgroups operam atrav√©s dos controladores, cada um respons√°vel pelo gerenciamento de um tipo de recurso:

| Subsistema | Descri√ß√£o                                 |
| ---------- | ----------------------------------------- |
| `cpu`      | Controla a programa√ß√£o da CPU             |
| `cpuacct`  | Gera relat√≥rios de uso da CPU             |
| `memory`   | Limita e contas o uso da mem√≥ria          |
| `blkio`    | Limita a E/S do dispositivo de bloco      |
| `devices`  | Controla o acesso a dispositivos          |
| `freezer`  | Suspende/retoma a execu√ß√£o de tarefas     |
| `net_cls`  | Pacotes de tags para modelagem de tr√°fego |
| `ns`       | Gerencia o acesso ao namespace (raro)     |

##### Layout Layout do sistema de arquivos

Os cgroups s√£o expostos atrav√©s do sistema de arquivos virtual em/sys/fs/cgroup.

Dependendo da vers√£o:

-   **CGROUPS V1**: Hierarquias separadas para cada controlador (por exemplo, mem√≥ria, CPU, etc.)
-   **CGROUPS V2**: Hierarquia unificada sob um √∫nico ponto de montagem

Montado em:

```sh
/sys/fs/cgroup/
```

Hierarquia t√≠pica de CGROUPS v1:

```sh
/sys/fs/cgroup/
‚îú‚îÄ‚îÄ memory/
‚îÇ   ‚îú‚îÄ‚îÄ mygroup/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory.limit_in_bytes
‚îú‚îÄ‚îÄ cpu/
‚îÇ   ‚îî‚îÄ‚îÄ mygroup/
‚îî‚îÄ‚îÄ ...
```

No CGROUPS V2, todos os recursos s√£o gerenciados sob uma hierarquia unificada:

```sh
/sys/fs/cgroup/
‚îú‚îÄ‚îÄ cgroup.procs
‚îú‚îÄ‚îÄ cgroup.controllers
‚îú‚îÄ‚îÄ memory.max
‚îú‚îÄ‚îÄ cpu.max
‚îî‚îÄ‚îÄ ...
```

##### üß™ Uso comum (exemplos V1 e V2)

v1 - Crie e atribua limite de mem√≥ria:

```sh
# Mount memory controller (if needed)
mount -t cgroup -o memory none /sys/fs/cgroup/memory

# Create group
mkdir /sys/fs/cgroup/memory/mygroup

# Set memory limit (100 MB)
echo 104857600 | tee /sys/fs/cgroup/memory/mygroup/memory.limit_in_bytes

# Assign a process (e.g., current shell)
echo $$ | tee /sys/fs/cgroup/memory/mygroup/tasks
```

V2 - Hierarquia unificada:

```sh
# Create subgroup
mkdir /sys/fs/cgroup/mygroup

# Enable controllers
echo +memory +cpu > /sys/fs/cgroup/cgroup.subtree_control

# Move shell into group
echo $$ > /sys/fs/cgroup/mygroup/cgroup.procs

# Set limits
echo 104857600 > /sys/fs/cgroup/mygroup/memory.max
echo "50000 100000" > /sys/fs/cgroup/mygroup/cpu.max  # 50ms quota per 100ms period
```

üß≠ Process e inspe√ß√£o de grupo

| Comando                 | Descri√ß√£o                                 |
| ----------------------- | ----------------------------------------- |
| `cat /proc/self/cgroup` | Mostra a associa√ß√£o atual do CGROUP       |
| `cat /proc/PID/cgroup`  | cgroup de outro processo                  |
| `cat /proc/PID/status`  | Informa√ß√µes de mem√≥ria e cgroup           |
| `ps -o pid,cmd,cgroup`  | Mostre mapeamento de processo para cgrupo |

##### üì¶ Uso em cont√™ineres

Motores de cont√™iner como Docker, Podman e Containerd Delegate Resource Control para CGroups (via Runc ou Crun), permitindo:

-   CPU por conte√∫do e limites de mem√≥ria
-   Controle de gr√£o fino sobre o BLKIO e dispositivos
-   Contabilidade de recursos em tempo real

Exemplo do Docker:

```sh
docker run --memory=256m --cpus=1 busybox
```

Nos bastidores, isso cria regras do CGROUP para limites de mem√≥ria e CPU para o processo de cont√™iner.

##### üß† Resumo dos conceitos

| Conceito          | Explica√ß√£o                                                             |
| ----------------- | ---------------------------------------------------------------------- |
| **Controladores** | M√≥dulos como`cpu`,`memory`,`blkio`, etc. Aplique limites e regras      |
| **Tarefas**       | PIDs (processos) atribu√≠dos ao grupo de controle                       |
| **Hierarquia**    | CGROUPS est√£o estruturados em uma √°rvore pai-filho                     |
| **Delega√ß√£o**     | Os servi√ßos Systemd e do usu√°rio podem gerenciar sub√°rvores de cgroups |

##### üß™ CGROUPS LAB

Use este script para laborat√≥rio:[cgroups.sh](scripts/container/cgroups.sh)

[![asciicast](https://asciinema.org/a/WbudWJpHKPzBWMh8CGRxCIpZf.svg)](https://asciinema.org/a/WbudWJpHKPzBWMh8CGRxCIpZf)

* * *

#### üõ°Ô∏è Recursos de compreens√£o

‚ùì Quais s√£o os recursos do Linux?

Tradicionalmente no Linux, o usu√°rio raiz tem acesso irrestrito ao sistema. Os recursos do Linux foram introduzidos para dividir esses privil√©gios todo-poderosos em permiss√µes menores e discretas, permitindo que os processos realizem opera√ß√µes privilegiadas espec√≠ficas sem exigir acesso total √† raiz.

Isso aprimora a seguran√ßa do sistema, aplicando o princ√≠pio do menor privil√©gio.

| üîê Capacidade          | üìã Descri√ß√£o                                                        |
| ---------------------- | ------------------------------------------------------------------- |
| `CAP_CHOWN`            | Alterar o propriet√°rio do arquivo, independentemente das permiss√µes |
| `CAP_NET_BIND_SERVICE` | Ligue para as portas abaixo de 1024 (por exemplo, 80, 443)          |
| `CAP_SYS_TIME`         | Defina o rel√≥gio do sistema                                         |
| `CAP_SYS_ADMIN`        | ‚ö†Ô∏è Muito poderoso - inclui Mount, BPF e muito mais                  |
| `CAP_NET_RAW`          | Use soquetes crus (por exemplo, ping, traceroute)                   |
| `CAP_SYS_PTRACE`       | Rastrear outros processos (depura√ß√£o)                               |
| `CAP_KILL`             | Envie sinais para qualquer processo                                 |
| `CAP_DAC_OVERRIDE`     | Modificar arquivos e diret√≥rios sem permiss√£o                       |
| `CAP_SETUID`           | Alterar ID de usu√°rio (UID) do processo                             |
| `CAP_NET_ADMIN`        | Gerenciar interfaces de rede, roteamento, etc.                      |

üîê Alguns tipos de recursos do Linux

| Tipo de capacidade       | Descri√ß√£o                                                                      |
| ------------------------ | ------------------------------------------------------------------------------ |
| **CapInh (Inherited)**   | Recursos herdados do processo pai.                                             |
| **CAPPRM (permitido)**   | Recursos que o processo pode ter.                                              |
| **Capeff (eficaz)**      | Recursos que o processo est√° usando atualmente.                                |
| **Capbnd (delimitador)** | Restringe o conjunto m√°ximo de recursos eficazes que um processo pode obter.   |
| **Capamb (ambiente)**    | Permite que um processo defina explicitamente seus pr√≥prios recursos eficazes. |

üì¶ Capacidades em recipientes e vagens
Os cont√™ineres normalmente n√£o s√£o executados como raiz completa, mas recebem um conjunto limitado de recursos por padr√£o, dependendo do tempo de execu√ß√£o.

Os recursos podem ser adicionados ou descartados em Kubernetes usando o SecurityContext.

üìÑ Kubernetes Exemplo:

```yaml
securityContext:
  capabilities:
    drop: ["ALL"]
    add: ["NET_BIND_SERVICE"]
```

üîê Isso garante que o cont√™iner inicie com privil√©gios zero e receba apenas o que √© necess√°rio.

##### üß™ Recursos de laborat√≥rio

Use este script para laborat√≥rio:[capabilities.sh](scripts/container/capabilities.sh)

[![asciicast](https://asciinema.org/a/kCiUGvY0YGA5Mdzbj1NSdfLAx.svg)](https://asciinema.org/a/kCiUGvY0YGA5Mdzbj1NSdfLAx)

#### üõ°Ô∏è Seccomp (modo de computa√ß√£o segura)

**O que √©?**

-   Um recurso do kernel do Linux para restringir quais syscalls (sistema chama) um processo pode usar.
-   Comumente usado em recipientes (como o docker), navegadores, caixas de areia, etc.

**Como funciona?**

-   Um processo permite um perfil/filtro Seccomp.
-   O kernel bloqueia, registra ou mata o processo se tentar os syscalls proibidos.
-   Os filtros s√£o escritos no formato BPF (Berkeley Packet Filter).

**Comandos r√°pidos**

```sh
# Check support
docker info | grep Seccomp

# Disable for a container:
docker run --security-opt seccomp=unconfined ...

# Inspect running process:
grep Seccomp /proc/$$/status
```

**Ferramentas**

```sh
# for analyzing
seccomp-tools 

# Profiles
/etc/docker/seccomp.json
```

#### ü¶∫APARMOR

**O que √©?**

-   Um sistema de controle de acesso obrigat√≥rio (MAC) para restringir o que programas espec√≠ficos podem acessar.
-   Os perfis s√£o baseados em texto, orientados para o caminho, f√°ceis de ler e editar.

**Como funciona?**

-   Cada bin√°rio pode ter um perfil que define seus arquivos, rede e recursos permitidos - mesmo como root!
-   F√°cil de alternar entre reclamar, aplicar e desativar os modos desativados.

**Comandos r√°pidos:**

```sh
#Status
aa-status

# Put a program in enforce mode
sudo aa-enforce /etc/apparmor.d/usr.bin.foo

# Profiles
location: /etc/apparmor.d/
```

**Ferramentas:**

AA-GENPROF, AA-LOGPROF para gerar/atualizar perfis

Logs

```sh
/var/log/syslog (search for apparmor)
```

#### üîíSeLinux (Linux aprimorado de seguran√ßa)

**O que √©?**

-   Um sistema MAC muito poderoso para controlar o acesso a tudo: arquivos, processos, usu√°rios, portas, redes e muito mais.
-   Usa r√≥tulos (contextos) e pol√≠ticas detalhadas.

**Como funciona?**

-   Tudo (processo, arquivo, porta, etc.) recebe um contexto de seguran√ßa.
-   O kernel verifica todas as a√ß√µes contra regras pol√≠ticas.

**Comandos r√°pidos:**

```sh
#Status
sestatus

#Set to enforcing/permissive:
setenforce 1  # Enforcing
setenforce 0  # Permissive

#List security contexts:
ls -Z  # Files
ps -eZ # Processes
```

**Ferramentas:**

-   Audit2allow, Semanage, CHCON (para gerenciar pol√≠ticas/etiquetas)
-   Logs: /var/log/audit/audit.log
-   Pol√≠ticas:/etc/Selinux/

#### üìã Tabela de resumo para sistemas de seguran√ßa comuns

| Sistema | Foco                    | Complexidade | Localiza√ß√£o da pol√≠tica                | Uso t√≠pico              |
| ------- | ----------------------- | ------------ | -------------------------------------- | ----------------------- |
| Seccomp | Syscalls do kernel      | M√©dio        | Por processo (via c√≥digo/configura√ß√£o) | Docker, caixas de areia |
| APARMOR | Acesso por programa     | F√°cil        | /etc/apparmor.d/                       | Ubuntu, Snap, Suse      |
| Selinux | Mac do sistema completo | Avan√ßado     | /etc/selinux/ + r√≥tulos                | Rhel, Fedora, Centos    |

#### üóÇÔ∏è Isolamento de cont√™ineres Linux e compara√ß√£o de seguran√ßa

| Tecnologia        | Prop√≥sito / o que faz                                                                                                   | Principais diferen√ßas                                                                                         | Exemplo em cont√™ineres                                                                                |
| ----------------- | ----------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------- |
| **Chroot üè†**     | Altera o diret√≥rio raiz aparente para um processo. Isolate o sistema de arquivos.                                       | Isolamento simples do sistema de arquivos; faz**n√£o**restringir recursos, privil√©gios ou chamadas do sistema. | Docker usa`chroot`Internamente para criar imagens m√≠nimas, mas n√£o para um forte isolamento.          |
| **CGROUPS üìä**    | Controla e limita o uso de recursos (CPU, mem√≥ria, E/S de disco, etc.) por grupo de processos.                          | Recurso do kernel; Controle de recursos de gr√£o fino, n√£o isolamento.                                         | Docker e Kubernetes usam cgroups para limitar a CPU/MEM por cont√™iner/pod.                            |
| **Namespaces üåê** | Isolar recursos do sistema: PID, MOUNT, UTS, Rede, Usu√°rio, IPC, Time.                                                  | Recurso do kernel; fornece diferentes tipos de isolamento.                                                    | Cada cont√™iner √© executado em seu pr√≥prio conjunto de espa√ßos para nome (PID, rede, montagem etc.).   |
| **Recursos üõ°Ô∏è**  | Dividir privil√©gios de raiz em unidades de gr√£o fino (por exemplo, rede_admin, sys_admin).                              | Mais granular do que tudo o ou nada raiz/n√£o raiz; pode abandonar ou conceder privil√©gios espec√≠ficos.        | Os cont√™ineres do Docker geralmente s√£o executados com recursos reduzidos (solteiros perigosos).      |
| **Seccomp üß±**    | Filtrar/restringir quais syscalls um processo pode fazer (lista de permiss√µes/lista negra).                             | Muito focado: blocos de syscalls do kernel; n√£o pode bloquear todas as a√ß√µes.                                 | O perfil padr√£o do Docker bloqueia syscalls perigosos (por exemplo,,`ptrace`,`mount`).                |
| **APARMOR üêß**    | Estrutura de controle de acesso obrigat√≥rio (MAC): restringe o acesso de arquivo/rede dos programas por meio de perfis. | Baseado em perfil, mais f√°cil de gerenciar do que o Selinux; menos granula√ß√£o fina em alguns casos.           | Os cont√™ineres baseados em Ubuntu geralmente usam o Apmor para perfis de processo de cont√™iner.       |
| **Selinux üîí**    | Estrutura MAC mais complexa, baseada em etiquetas, muito fina. Pode limitar usu√°rios, processos e arquivos.             | Mais poderoso e complexo que o Aparmor; For√ßado em Fedora/Rhel/Centos.                                        | No OpenShift/Kubernetes com RHEL, os r√≥tulos do Selinux s√£o usados ‚Äã‚Äãpara manter as vagens separadas. |

Resumo

-   CHROOT: Isolamento b√°sico, sem garantias de recurso/seguran√ßa.
-   CGROUPS: Controle de recursos, n√£o isolamento.
-   Namespaces: isolar "vistas" dos recursos do kernel.
-   Recursos: privil√©gios de processo de ajuste fino.
-   Seccomp: Restre a superf√≠cie da chamada do sistema.
-   APARMOR/SELinux: limite o que os processos podem tocar, mesmo como root (Mac).

#### üß© OCI, Runc, Containerd, CRI, CRI-O-O que eles s√£o no ecossistema de cont√™ineres

##### Vis√£o geral e pap√©is

-   **OCI (iniciativa de cont√™iner aberto) üèõÔ∏è**

    Uma funda√ß√£o criando padr√µes abertos para**imagens de cont√™iner**e**Runtimes**.

    _Define como as imagens s√£o formatadas, armazenadas e como os cont√™ineres s√£o iniciados/parados (especifica√ß√µes de tempo de execu√ß√£o)._
-   **‚öôÔ∏è Runc**

    Uma ferramenta CLI universal, de baixo n√≠vel e leve que pode executar cont√™ineres de acordo com a especifica√ß√£o de tempo de execu√ß√£o da OCI.

    _"O motor" que transforma uma configura√ß√£o de imagem + em um cont√™iner Linux em execu√ß√£o real._
-   **Containerd üèãÔ∏è**

    Um daemon de tempo de execu√ß√£o do cont√™iner principal para gerenciar o ciclo de vida completo do cont√™iner:**puxando imagens, gerenciando armazenamento, executando recipientes**(chama Runc), plugins de rede, etc.

    _Usado por Docker, Kubernetes, Nerdctl e outras ferramentas como seu principal back -end de tempo de execu√ß√£o do cont√™iner._
-   **CRI (interface de tempo de execu√ß√£o do cont√™iner) üîå**

    Uma API GRPC espec√≠fica para Kubernetes para conectar o Kubernetes com os tempos de execu√ß√£o do cont√™iner.

    _N√£o usado fora de Kubernetes, mas permite que os K8s conversem com cont√™ineres, Cri-O, etc._
-   **CRI-O ü•§**

    Um tempo de execu√ß√£o leve e focado em Kubernetes que**apenas**Executa cont√™ineres OCI, usando o Runc sob o cap√¥.

    _Principalmente usado em Kubernetes, mas demonstra como criar um tempo de execu√ß√£o m√≠nimo de cont√™iner focado nos padr√µes abertos._

##### Tables Tabelas de compara√ß√£o: OCI, Runc, Containerd, CRI, CRI-O

| Componente    | Emoji | O que √©?                                     | Quem o usa?                             | Exemplo de uso                                                                        |
| ------------- | ----- | -------------------------------------------- | --------------------------------------- | ------------------------------------------------------------------------------------- |
| **OCI**       | üèõÔ∏è   | Padr√µes/especifica√ß√µes                       | Docker, Podman, CRI-O, containerd, runc | Garante que imagens/recipientes sejam compat√≠veis entre as ferramentas                |
| **Runc**      | ‚öôÔ∏è    | Time de execu√ß√£o de cont√™ineres (CLI)        | containerd, CRI-O, Docker, Podman       | Executando diretamente um recipiente de um pacote (por exemplo`runc run`)             |
| **cont√™iner** | üèãÔ∏è   | Daemon de tempo de execu√ß√£o do cont√™iner     | Docker, Kubernetes, Nerdctl             | Man√ßas de puxar imagens, gerenciar armazenamento/rede, inicia os cont√™ineres via Runc |
| **Cri**       | üîå    | Interface de tempo de execu√ß√£o do K8S (API)  | Somente Kubernetes                      | Deixe Kubelet falar com o cont√™iner/Cri-O                                             |
| **CRI-O**     | ü•§    | Tempo de execu√ß√£o do cont√™iner leve para K8s | Kubernetes, OpenShift                   | Usado como motor de cont√™iner K8S                                                     |

* * *

##### Exemplos Exemplos pr√°ticos (mundo geral de cont√™ineres)

-   **Imagens de constru√ß√£o:**

    Qualquer ferramenta (Docker, Podman, Builtah) pode produzir imagens seguindo o**OCI Image Spec**Ent√£o eles s√£o compat√≠veis em todos os lugares.
-   **Recipientes em execu√ß√£o:**

    Podman e Docker finalmente usam**Runc**(via cont√™iner ou diretamente) para criar cont√™ineres.
-   **Gerenciando muitos cont√™ineres:**

    **cont√™iner**pode ser usado por conta pr√≥pria (via`ctr`ou`nerdctl`) ou como um back -end para Docker e Kubernetes.
-   **Tempos de execu√ß√£o plug-and-play:**

    Obrigado a**OCI**, voc√™ pode trocar o Runc por outro tempo de execu√ß√£o compat√≠vel com OCI (como os cont√™ineres KATA para VMS, Gvisor for Sandboxing) sem alterar a maneira como voc√™ cria ou gerencia imagens.

* * *

##### üö¢ Pilha t√≠pica

```plaintext
[User CLI / Orchestration]
           |
   [containerd / CRI-O]
           |
        [runc]
           |
[Linux Kernel: namespaces, cgroups, etc]
```

-   **Docker**: Usu√°rio 151 ‚Üí Cont√™iner ‚Üí Runc
-   **Subman**: Usu√°rio 151 ‚Üí Runc
-   **Kubernetes**: Kubelet (CRI) ‚Üí Cont√™iner ou Cri-O ‚Üí Runc

* * *

##### üß† Resumo

-   **OCI**= Linguagem comum para imagens/tempo de execu√ß√£o (padr√µes/especifica√ß√µes)
-   **Runc**= Ferramenta real que cria e gerencia processos de cont√™iner
-   **cont√™iner**= Daemon completo que gerencia imagens, recipientes, ciclo de vida
-   **Cri**= Somente para Kubernetes, para tornar os tempos de execu√ß√£o que
-   **CRI-O**= Tempo de execu√ß√£o leve focado em Kubernetes, constru√≠dos com os padr√µes da OCI e Runc

##### üß© Diagrama: ecossistema de cont√™ineres

```mermaid
graph TD
    subgraph OCI_Standards
        OCI1["OCI Image Spec"]
        OCI2["OCI Runtime Spec"]
    end

    subgraph Orchestration_CLI
        Docker["Docker CLI"]
        Podman["Podman CLI"]
        Kubelet["Kubelet"]
        Nerdctl["nerdctl CLI"]
    end

    subgraph Container_Runtimes
        containerd["containerd"]
        crio["CRI-O"]
    end

    runc["runc"]

    Kernel["Linux Kernel(namespaces, cgroups, seccomp, etc)"]

    %% Connections
    Docker --> containerd
    Podman --> runc
    Nerdctl --> containerd
    Kubelet --> CRI[CRI API]
    CRI --> containerd
    CRI --> crio
    containerd --> runc
    crio --> runc
    runc --> Kernel

    OCI1 -.-> containerd
    OCI1 -.-> crio
    OCI2 -.-> runc
```

##### üß™ Lab Runc

Para o Runc Lab, voc√™ pode usar este script:[runc.sh](scripts/container/runc.sh)

[![asciicast](https://asciinema.org/a/UDVnhKSxPFRXDcwg0HYFkZdlX.svg)](https://asciinema.org/a/UDVnhKSxPFRXDcwg0HYFkZdlX)

##### üß™ Container de laborat√≥rio

Para o cont√™iner, voc√™ pode usar este script:[containerd.sh](scripts/container/container.sh)

![containerd](images/containerd-lab.png)

* * *

#### üöÄ Podman, Buildah, Skopeo, OpenVZ, Crun e Kata Containers - Fast Track

* * *

##### üê≥**Subman**

-   **O que √©?**Um gerente de cont√™ineres compat√≠vel com a CLI do Docker, mas**Sem daemon**e pode correr**sem raiz**.
-   **Usar:**Crie, execute, pare e inspecione recipientes e vagens.
-   **Destaques:**Nenhum Daemon Central, mais seguro para o MultiUser, integra-se ao Systemd.
-   [Mais informa√ß√µes](<>)

* * *

##### üì¶**Buildah**

-   **O que √©?**Ferramenta para**Construir e manipular imagens de cont√™ineres**(OCI/Docker) sem daemon.
-   **Usar:**Construindo imagens em pipelines CI/CD ou scripts.
-   **Destaques:**Suporte leve e sem raiz, usado por podman sob o cap√¥.
-   [Mais informa√ß√µes](https://www.redhat.com/en/topics/containers/what-is-buildah)

* * *

##### üî≠**Escopo**

-   **O que √©?**Utilidade para**Inspecionar, copiar e mover imagens de cont√™iner**entre registros**sem puxar ou correr**eles.
-   **Usar:**Mova imagens, verifique as assinaturas e os metadados.
-   **Destaques:**Sem daemon, ideal para automa√ß√£o e seguran√ßa.
-   [Mais informa√ß√µes](<>)

* * *

##### üè¢**OpenVZ**

-   **O que √©?****Virtualiza√ß√£o baseada em cont√™iner**Solu√ß√£o para Linux (ferramentas modernas de cont√™iner modernas).
-   **Usar:**VPs leves (servidores privados virtuais) compartilhando o mesmo kernel.
-   **Destaques:**Muito eficiente, mas menos isolado que a VM (a√ß√µes do kernel).
-   [Mais informa√ß√µes](https://en.wikipedia.org/wiki/OpenVZ)

* * *

##### ‚ö°**Crun**

-   **O que √©?**Tempo de execu√ß√£o Ultra-Fast e Minimal OCI para cont√™ineres, escrito em C (n√£o v√°).
-   **Usar:**Executa recipientes com sobrecarga m√≠nima.
-   **Destaques:**Mais r√°pido e mais leve que o Runc, padr√£o para o Podman em alguns sistemas.
-   [Mais informa√ß√µes](https://www.redhat.com/sysadmin/introduction-crun)

* * *

##### üõ°Ô∏è**Cont√™iner de palavras**

-   **O que √©?**Projeto de c√≥digo aberto Combinando recipientes e VMs: Cada cont√™iner √© executado em um micro-VM leve.
-   **Usar:**Isolamento forte para cargas de trabalho sens√≠veis ou ambientes multi-inquilinos.
-   **Destaques:**Seguran√ßa de grau de VM, desempenho pr√≥ximo do contorno.
-   [Mais informa√ß√µes](https://katacontainers.io/)

* * *

##### üìä**Tabela de compara√ß√£o**

| Projeto                   | Categoria               | Isolamento            | Daemon? | Uso principal                         | Sem raiz | Notas                                   |
| ------------------------- | ----------------------- | --------------------- | ------- | ------------------------------------- | -------- | --------------------------------------- |
| **Subman**                | Orquestra√ß√£o            | Recipiente            | No      | Gerenciar cont√™ineres                 | Sim      | CLI do tipo Docker                      |
| **Buildah**               | Construir               | N / D                 | No      | Construir imagens                     | Sim      | Para CI/CD, sem execu√ß√£o de cont√™ineres |
| **Escopo**                | Transfer√™ncia de imagem | N / D                 | No      | Mova/verifique as imagens             | Sim      | Nenhuma execu√ß√£o de cont√™iner           |
| **OpenVZ**                | Virtualiza√ß√£o           | Cont√™iner/vps         | Sim     | VPS leves                             | No       | Kernel compartilhou, Tech Legacy        |
| **Crun**                  | OCI Runtime             | Recipiente            | No      | Tempo de execu√ß√£o r√°pido do cont√™iner | Sim      | Mais r√°pido que o Runc                  |
| **Cont√™iner de palavras** | Runtime/VM              | Microvm por cont√™iner | No      | Isolamento forte                      | Sim      | Seguran√ßa no n√≠vel da VM                |

* * *

##### ‚òëÔ∏è**Recapitula√ß√£o r√°pida**

-   **Podman:**Alternativa moderna e sem daemon sem daemon.
-   **Buildah:**Crie imagens, n√£o executa recipientes.
-   **Skeape:**Move/inspeciona imagens, nunca as executa.
-   **OpenVZ:**VPs baseados em cont√™ineres legados.
-   **Cruel:**Tempo de execu√ß√£o super r√°pido e leve da OCI.
-   **Dizer:**Recipientes com isolamento no n√≠vel da VM.

#### 352.1 Comandos importantes

##### n√£o se bem

```sh
# create a new namespaces and run a command in it
unshare --mount --uts --ipc --user --pid --net  --map-root-user --mount-proc --fork chroot ~vagrant/debian bash
# mount /proc for test
#mount -t proc proc /proc
#ps -aux
#ip addr show
#umount /proc
```

##### lsns

```sh
# show all namespaces
lsns

# show only pid namespace
lsns -s <pid>
lsns -p 3669

ls -l /proc/<pid>/ns
ls -l /proc/3669/ns

ps -o pid,pidns,netns,ipcns,utsns,userns,args -p <PID>
ps -o pid,pidns,netns,ipcns,utsns,userns,args -p 3669
```

##### NSENTER

```sh
# execute a command in namespace
sudo nsenter -t <PID> -n  ip link show
sudo nsenter -t 3669 -n ip link show
```

##### 252.1 IP

```sh
# create a new network namespace
sudo ip netns add lxc1

# list network list
ip netns list

# exec command in network namespace
sudo ip netns exec lxc1 ip addr show
```

##### Stat

```sh
# get cgroup version
stat -fc %T /sys/fs/cgroup
```

##### SystemCTL e Systemd

```sh
# get cgroups of system
systemctl status
systemd-cgls
```

##### cgcreate

```sh
cgcreate -g memory,cpu:lsf
```

##### cgclassify

```sh
cgclassify -g memory,cpu:lsf <PID>
```

##### PSCAP - Recursos de processo de lista

```sh
# List capabilities of all process
pscap
```

##### getCap/usr/bin/tcpdump

```sh
getcap /usr/bin/tcpdump
```

##### setcap cap_net_raw = ep/usr/bin/tcpdump

```sh
# add capabilities to tcpdump
sudo setcap cap_net_raw=ep /usr/bin/tcpdump

# remove capabilities from tcpdump
sudo setcap -r /usr/bin/tcpdump
sudo setcap '' /usr/bin/tcpdump
```

##### Verifique os recursos por processo

```sh
grep Cap /proc/<PID>/status
```

##### Capsh - Capability Shell Wrapper

```sh
# use grep Cap /proc/<PID>/statusfor get hexadecimal value(Example CApEff=0000000000002000)
capsh --decode=0000000000002000
```

##### Appmor - Aprimoramento do kernel para limitar os programas a um conjunto limitado de recursos

```sh
# check AppArmor status
sudo aa-status

#  unload all AppArmor profiles
aa-teardown

# loads AppArmor profiles into the kernel
aaparmor_parser
```

##### Selinux - Linux aprimorado de seguran√ßa

```sh
# check SELinux status
sudo sestatus

# check SELinux mode
sudo getenforce 

# set SELinux to enforcing mode
sudo setenforce 1
```

##### Runc

```sh
#create a spec file for runc
runc spec

# run a container using runc
sudo runc run mycontainer


```

* * *

<p align="right">(<a href="#topic-352.1">back to sub topic 352.1</a>)</p>
<p align="right">(<a href="#topic-352">back to topic 352</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-352.2"></a>

### 352.2 LXC

**Peso:**6

**Descri√ß√£o:**Os candidatos devem poder usar cont√™ineres do sistema usando LXC e LXD. A vers√£o do LXC coberta √© 3,0 ou superior.

**Principais √°reas de conhecimento:**

-   Entenda a arquitetura do LXC e LXD
-   Gerencie recipientes LXC com base nas imagens existentes usando LXD, incluindo redes e armazenamento
-   Configurar propriedades de cont√™iner LXC
-   Limite o uso de recursos de cont√™iner LXC
-   Use perfis LXD
-   Entenda imagens LXC
-   Consci√™ncia das ferramentas tradicionais do LXC

#### 352.2 Objetos citados

```sh
lxd
lxc (including relevant subcommands)
/etc/lxc/
/var/log/lxc/
/usr/share/lxc/templates
```

#### üß© LXC & LXD - O conjunto de cont√™ineres do sistema Linux

* * *

##### üì¶ LXC (cont√™ineres Linux)

-   **O que √©?**

    O_essencial_Usu√°riosPace ToolSet para gerenciar cont√™ineres de aplicativos e sistemas no Linux. Pense no LXC como**"Chroot em ester√≥ides"**- Ele fornece isolamento leve do processo usando recursos do kernel (espa√ßos para nome, cgroups, Aparmor, Seccomp, etc.).
-   **Usar:**

    -   Execute distribui√ß√µes completas do Linux como cont√™ineres (n√£o apenas aplicativos √∫nicos).
    -   √ötil para testes, aplicativos herdados ou servidores simulados.
-   **Destaques:**

    -   Focado na CLI:`lxc-create`,`lxc-start`,`lxc-attach`, etc.
    -   Controle de gr√£o fino sobre os recursos de cont√™iner.
    -   Nenhum Daemon-executa processos por conte√∫do.
-   **Melhor para:**

    Especialistas do Linux que desejam controle total e sensa√ß√£o de "metal nu" para recipientes.
-   [Documentos](https://linuxcontainers.org/lxc/introduction/)

* * *

##### üåê LXD

-   **O que √©?**

    **Lxd**√© a_pr√≥xima gera√ß√£o_Container e VM Manager,**Constru√≠do em cima do LXC**. Ele oferece uma experi√™ncia poderosa, mas f√°cil de usar, para gerenciar cont√™ineres e m√°quinas virtuais via API REST, CLI ou at√© uma interface da web.
-   **Usar:**

    -   Gerenciar cont√™ineres do sistema e m√°quinas virtuais em escala.
    -   Cont√™iner em rede ‚Äúcomo servi√ßo‚Äù com orquestra√ß√£o f√°cil.
-   **Destaques:**

    -   **Rest API**: Gerencie cont√™ineres/VMs sobre a rede.
    -   **Imagens:**Implanta√ß√£o instant√¢nea de muitas distros do Linux.
    -   **Instant√¢neos, piscinas de armazenamento, clustering, migra√ß√£o ao vivo.**
    -   Suporta a execu√ß√£o de cont√™ineres sem privil√©gios por padr√£o.
    -   CLI:`lxc launch`,`lxc exec`,`lxc snapshot`, etc._(Sim, o mesmo prefixo que LXC, mas back -end diferente!)_
-   **Melhor para:**

    DevOps, sysadmins, configura√ß√µes nativas da nuvem, ambientes de laborat√≥rio.
-   [Documentos](https://linuxcontainers.org/lxd/)\|[LXD can√¥nico](https://canonical.com/lxd)

* * *

##### üìä LXC vs Tabela de compara√ß√£o LXD

| Recurso           | üè∑Ô∏è LXC                                       | üåê LXD                                                       |
| ----------------- | --------------------------------------------- | ------------------------------------------------------------ |
| **Tipo**          | Gerente de cont√™iner de espa√ßo de baixo n√≠vel | Gerente de alto n√≠vel (cont√™ineres + VMs)                    |
| **Interface**     | Apenas CLI                                    | API REST, CLI, interface da usu√°rio da web                   |
| **Daemon?**       | No (runs as processes)                        | Sim (daemon/servi√ßo central)                                 |
| **Orquestra√ß√£o**  | Manual, Scriptable                            | Clustering embutido e API                                    |
| **Imagens**       | Baseado em modelo                             | Reposit√≥rio de imagem completa, muitos sistemas operacionais |
| **Instant√¢neos**  | Manual                                        | Nativo, integrado                                            |
| **Suporte da VM** | No                                            | Sim (qemu/kvm)                                               |
| **Uso de uso**    | Controle de gr√£o fino, ‚ÄúBare-metal‚Äù           | Multi-host escal√°vel, f√°cil de usar                          |
| **Seguran√ßa**     | Pode ser sem privil√©gios, mas DIY             | N√£o privilegiado, mais isolamento                            |
| **Melhor para**   | Pr√≥s Linux, script avan√ßado                   | DevOps, nuvem, equipes, autoatendimento                      |

* * *

##### ‚òëÔ∏è Recapitula√ß√£o r√°pida

-   **LXC**= Os blocos de constru√ß√£o de baixo n√≠vel. Poder e flexibilidade para_Puristas de cont√™ineres_.
-   **Lxd**= Moderno, orientado a API e plataforma escal√°vel em cima do LXC para_f√°cil_Gerenciamento de cont√™ineres e VM (n√≥ √∫nico ou clusters).

#### 352.2 Comandos importantes

##### LXC

```sh
####### Examples of lxc commands #####

# check lxc version
lxc-create --version

# create a priveleged container
sudo lxc-create -n busybox -t busybox

# list containers
sudo lxc-ls --fancy
sudo lxc-ls -f

# create container with template
sudo lxc-create -n debian01 -t download
lxc-create --name server2 --template download -- --dist alpine --release 3.19 --arch amd64

# get container info
sudo lxc-info -n debian01

# start container
sudo lxc-start -n debian01

# stop container
sudo lxc-stop -n debian01

# connect to container
sudo lxc-attach -n debian01

# excute a command in container
sudo lxc-attach -n debian01 --  echo "Hello from"
sudo lxc-attach -n debian01 -- bash -c ls

# delete container
sudo lxc-destroy -n debian01
```

<p align="right">(<a href="#topic-352.2">back to sub topic 352.2</a>)</p>
<p align="right">(<a href="#topic-352">back to topic 352</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-352.3"></a>

### 352.3 Docker

**Peso:**9

**Descri√ß√£o:**O candidato deve ser capaz de gerenciar n√≥s do Docker e recipientes do Docker. Isso inclui entender a arquitetura do Docker, al√©m de entender como o Docker interage com o sistema Linux do n√≥.

**Principais √°reas de conhecimento:**

-   Entenda a arquitetura e componentes do Docker
-   Gerencie os cont√™ineres do Docker usando imagens de um registro do Docker
-   Entenda e gerencie imagens e volumes para recipientes do Docker
-   Entenda e gerencie o log para recipientes do docker
-   Entenda e gerencie a rede para o Docker
-   Use DockerFiles para criar imagens de cont√™iner
-   Execute um registro do Docker usando a imagem do Docker do Registro

#### 352.3 Objetos citados

```sh
dockerd
/etc/docker/daemon.json
/var/lib/docker/
docker
Dockerfile
```

#### 352.3 Comandos importantes

##### Docker

```sh
# Examples of docker
```

<p align="right">(<a href="#topic-352.3">back to sub topic 352.3</a>)</p>
<p align="right">(<a href="#topic-352">back to topic 352</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-352.4"></a>

### 352.4 Plataformas de orquestra√ß√£o de cont√™ineres

**Peso:**3

**Descri√ß√£o:**Os candidatos devem entender a import√¢ncia da orquestra√ß√£o de cont√™ineres e os principais conceitos Docker Swarm e Kubernetes fornecem para implementar a orquestra√ß√£o de cont√™ineres.

**Principais √°reas de conhecimento:**

-   Entenda a relev√¢ncia da orquestra√ß√£o de cont√™ineres
-   Entenda os principais conceitos de composi√ß√£o do Docker e Swarm Docker
-   Entenda os principais conceitos de Kubernetes e comando
-   Consci√™ncia do OpenShift, Rancher e Mesosfera DC/OS

<p align="right">(<a href="#topic-352.4">back to sub topic 352.4</a>)</p>
<p align="right">(<a href="#topic-352">back to topic 352</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-353"></a>

## T√≥pico 353: implanta√ß√£o e provisionamento da VM

* * *

<a name="topic-353.1"></a>

### 353.1 Ferramentas de gerenciamento de nuvem

**Peso:**2

**Descri√ß√£o:**Os candidatos devem entender as ofertas comuns em nuvens p√∫blicas e ter o conhecimento b√°sico das ferramentas de gerenciamento de nuvem comumente dispon√≠veis.

**Principais √°reas de conhecimento:**

-   Entender ofertas comuns em nuvens p√∫blicas
-   Conhecimento b√°sico de recurso do OpenStack
-   Feature Basic Feature Knowledge of Terraform
-   Consci√™ncia do CloudStack, Eucalyptus e Opennebula

#### 353.1 Objetos citados

```sh
IaaS, PaaS, SaaS
OpenStack
Terraform
```

#### 353.1 Comandos importantes

##### foo

```sh
# examples
```

<p align="right">(<a href="#topic-353.1">back to sub topic 353.1</a>)</p>
<p align="right">(<a href="#topic-353">back to topic 353</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-353.2"></a>

### 353.2 Packer

**Peso:**2

**Descri√ß√£o:**Os candidatos devem poder usar o Packer para criar imagens do sistema. Isso inclui a execu√ß√£o do Packer em v√°rios ambientes de nuvem p√∫blica e privada, al√©m de criar imagens de cont√™ineres para LXC/LXD.

**Principais √°reas de conhecimento:**

-   Entenda a funcionalidade e os recursos do Packer
-   Crie e mantenha arquivos de modelo
-   Crie imagens a partir de arquivos de modelo usando diferentes construtores

#### 353.2 Objetos citados

```sh
packer
```

#### 353.2 Comandos importantes

##### Packer

```sh
# examples
```

<p align="right">(<a href="#topic-353.2">back to sub topic 353.2</a>)</p>
<p align="right">(<a href="#topic 353">back to topic 353</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-353.3"></a>

### 353.3 Cloud-Init

**Peso:**3

**Descri√ß√£o:**Os candidatos devem usar a entrada da nuvem para configurar m√°quinas virtuais criadas a partir de imagens padronizadas. Isso inclui o ajuste das m√°quinas virtuais para corresponder aos seus recursos de hardware dispon√≠veis, especificamente, espa√ßo em disco e volumes.
Al√©m disso, os candidatos devem poder configurar inst√¢ncias para permitir logins SSH seguros e instalar um conjunto espec√≠fico de pacotes de software.
Al√©m disso, os candidatos devem ser capazes de criar novas imagens do sistema com suporte √† init√™ncia da nuvem.

**Principais √°reas de conhecimento:**

-   Compreendendo os recursos e conceitos de entrada de nuvem, incluindo dados de usu√°rio, inicializa√ß√£o e configura√ß√£o
-   Use Cloud-Init para criar, redimensionar e montar sistemas de arquivos, configurar contas de usu√°rio, incluindo credenciais de login, como teclas SSH e instalar pacotes de software do reposit√≥rio da distribui√ß√£o
-   Integre a nuvem-ingressos nas imagens do sistema
-   Use Config Drive DataSource para testar

#### 353.3 Objetos citados

```sh
cloud-init
user-data
/var/lib/cloud/
```

#### 353.3 Comandos importantes

##### foo

```sh
# examples
```

<p align="right">(<a href="#topic-353.3">back to sub topic 353.3</a>)</p>
<p align="right">(<a href="#topic 353">back to topic 353</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<a name="topic-353.4"></a>

### 353.4 Vagrant

**Peso:**3

**Descri√ß√£o:**O candidato deve poder usar o Vagrant para gerenciar m√°quinas virtuais, incluindo o fornecimento da m√°quina virtual.

**Principais √°reas de conhecimento:**

-   Entenda a arquitetura e os conceitos vagantes, incluindo armazenamento e rede
-   Recuperar e usar caixas do Atlas
-   Crie e execute o VagrantFiles
-   Acesse m√°quinas virtuais vagantes
-   Compartilhe e sincronize a pasta entre uma m√°quina virtual vagante e o sistema host
-   Entenda o provisionamento vagante, ou seja, provisionistas de arquivos e shell
-   Entenda a configura√ß√£o de v√°rias m√°quinas

#### 353.4 Objetos citados

```sh
vagrant
Vagrantfile
```

#### 353.4 Comandos importantes

##### vagabundo

```sh
# examples
```

<p align="right">(<a href="#topic-353.4">back to sub topic 353.4</a>)</p>
<p align="right">(<a href="#topic 353">back to topic 353</a>)</p>
<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

## Contribuindo

Contribui√ß√µes s√£o o que tornam a comunidade de c√≥digo aberto um lugar t√£o incr√≠vel para
Aprenda, inspire e crie. Quaisquer contribui√ß√µes que voc√™ faz s√£o**muito apreciado**.

Se voc√™ tiver uma sugest√£o que melhoraria isso, bif√≥r -se o reposit√≥rio e
Crie uma solicita√ß√£o de tra√ß√£o. Voc√™ tamb√©m pode simplesmente abrir um problema com a tag "aprimoramento".
N√£o se esque√ßa de dar uma estrela ao projeto! Obrigado novamente!

1.  Bifurcar o projeto
2.  Crie sua filial de recursos (`git checkout -b feature/AmazingFeature`)
3.  Compreenda suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4.  Empurre para o ramo (`git push origin feature/AmazingFeature`)
5.  Abra um pedido de tra√ß√£o

* * *

## Licen√ßa

-   Este projeto est√° licenciado sob a licen√ßa do MIT \* Veja o arquivo License.md para obter detalhes

* * *

## Contato

Marcos Silvestrini -[marcos.silvestrini@gmail.com](mailto:marcos.silvestrini@gmail.com)[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/mrsilvestrini.svg?style=social&label=Follow%20%40mrsilvestrini)](https://twitter.com/mrsilvestrini)

Link do projeto:<https://github.com/marcossilvestrini/learning-lpic-3-305-300>

<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

## Agradecimentos

-   [Richard Stallman's](http://www.stallman.org/)
-   [GNU](<>)
    -   [GNU/FAQ Linux por Richard Stallman](https://www.gnu.org/gnu/gnu-linux-faq.html)
    -   [GNU](https://www.gnu.org/)
    -   [Sistema operacional GNU](https://www.gnu.org/gnu/thegnuproject.html)
    -   [Compilador GCC](https://gcc.gnu.org/wiki/History)
    -   [GNU tar](https://www.gnu.org/software/tar/)
    -   [GNU faz](https://www.gnu.org/software/make/)
    -   [GNU Emacs](https://en.wikipedia.org/wiki/Emacs)
    -   [Pacotes GNU](https://www.gnu.org/software/)
    -   [Cole√ß√£o GNU/Linux](https://directory.fsf.org/wiki/Collection:GNU/Linux)
    -   [GNU GRUB Bootloader](https://www.gnu.org/software/grub/)
    -   [GNU Hurd](https://www.gnu.org/software/hurd/hurd/what_is_the_gnu_hurd.html)
-   [Kernel](<>)
    -   [Kernel](https://www.kernel.org/)
    -   [P√°ginas do Kernel Linux](https://www.kernel.org/doc/man-pages/)
    -   [Compile seu kernel](https://wiki.linuxquestions.org/wiki/How_to_build_and_install_your_own_Linux_kernel)
-   [Base padr√£o Linux](<>)
    -   [Base padr√£o Linux](https://en.wikipedia.org/wiki/Linux_Standard_Base)
    -   [Padr√£o de hierarquia do sistema de arquivos](https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard)
    -   [Estrutura de hierarquia de arquivos](https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.pdf)
-   [Software livre](<>)
    -   [FSF](https://www.fsf.org)
    -   [Diret√≥rio de software livre](https://directory.fsf.org/wiki/Free_Software_Directory:Free_software_replacements)
-   [Licen√ßa](<>)
    -   [Software livre](https://www.gnu.org/philosophy/free-sw.html)
    -   [Copyleft](https://www.gnu.org/licenses/copyleft.en.html)
    -   [Gpl](https://www.gnu.org/licenses/quick-guide-gplv3.html)
    -   [GNU Licen√ßa p√∫blica geral menor](https://www.gnu.org/licenses/lgpl-3.0.html)
    -   [BSD](https://opensource.org/licenses/BSD-3-Clause)
    -   [Iniciativa de c√≥digo aberto](https://opensource.org/)
    -   [Creative Commons](https://creativecommons.org/)
    -   [Licen√ßa LTS](https://en.wikipedia.org/wiki/Long-term_support)
-   [Distos](<>)
    -   [Diretrizes de software livre do Debian](https://www.debian.org/social_contract#guidelines)
    -   [Lista de distribui√ß√£o Linux](https://en.wikipedia.org/wiki/List_of_Linux_distributions)
    -   [Distrowatch](https://distrowatch.com/)
    -   [Compara√ß√£o Distribui√ß√µes Linux](https://en.wikipedia.org/wiki/Comparison_of_Linux_distributions)
-   [Ambientes de mesa](<>)
    -   [X11 org](https://www.x.org/wiki/)
    -   [Wayland](https://wayland.freedesktop.org/)
    -   [GNU Gnome](https://www.gnu.org/press/gnome-1.0.html)
    -   [GNOMO](https://www.gnome.org/)
    -   [Xfce](https://xfce.org/)
    -   [Onde plasma](https://kde.org/plasma-desktop/)
    -   [Harmonia](https://en.wikipedia.org/wiki/Harmony_(toolkit))
-   [Protocolos](<>)
    -   [Http](<>)
        -   [W3Techs](https://w3techs.com/)
        -   [Apache](https://www.apache.org/)
        -   [Diretivas Apache][def]
        -   [C√≥digos de status HTTP](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)
        -   [Cifras fortes para Apache, Nginx e LightTPD](https://cipherlist.eu/)
        -   [Tutoriais da SSL](https://www.golinuxcloud.com/blog/)
        -   [SSL Config Mozilla](https://ssl-config.mozilla.org/)
    -   [XRDP](https://bytexd.com/xrdp-centos/)
    -   [Ntp](https://www.ntppool.org/en/)
-   [Dns](<>)
    -   [Vincular](https://www.isc.org/bind/)
    -   [Vincular o log](https://www.zytrax.com/books/dns/ch7/logging.html)
    -   [Lista de tipos de registro DNS](https://en.wikipedia.org/wiki/List_of_DNS_record_types)
    -   [Lista de tipos de registro DNS](https://en.wikipedia.org/wiki/List_of_DNS_record_types)
-   [Gerente de pacotes](<>)
    -   [Baixar pacotes](https://pkgs.org/)
    -   [Instale pacotes](https://installati.one/)
    -   [Guia de instala√ß√£o de pacotes](https://installati.one/)
-   [Script de shell](<>)
    -   [Bourne novamente Shell](https://www.gnu.org/software/bash/manual/)
    -   [Shebang](https://bash.cyberciti.biz/guide/Shebang)
    -   [Vari√°veis ‚Äã‚Äãde ambiente](https://linuxize.com/post/how-to-set-and-list-environment-variables-in-linux/)
    -   [GNU Globbing](https://man7.org/linux/man-pages/man7/glob.7.html)
    -   [Globbing](https://linuxhint.com/bash_globbing_tutorial/)
    -   [Citando](https://www.gnu.org/software/bash/manual/html_node/Quoting.html)
    -   [Express√µes regulares](https://www.gnu.org/software/grep/manual/html_node/Regular-Expressions.html)
    -   [Comando n√£o encontrado](https://command-not-found.com/)
    -   [Bash gerador de prompt](https://bash-prompt-generator.org/)
    -   [Explique a casca](https://explainshell.com/)
    -   [Tutorial Vim](https://www.openvim.com/)
    -   [Tutorial de script linux shell](https://bash.cyberciti.biz/guide/Main_Page)
    -   [Comandos exemplos](https://www.geeksforgeeks.org/)
-   [Outras ferramentas](<>)
    -   [Bugzila](https://bugzilla.kernel.org/)
    -   [Crach√°s do github](https://github.com/alexandresanlim/Badges4-README.md-Profile)
-   [Defini√ß√µes de virtualiza√ß√£o](<>)
    -   [Chap√©u vermelho](https://www.redhat.com/pt-br/topics/virtualization/what-is-virtualization/)
    -   [AWS](https://aws.amazon.com/pt/what-is/virtualization/)
    -   [IBM](https://www.ibm.com/topics/virtualization)
    -   [OpenSource.com](https://opensource.com/resources/virtualization)
-   [Alternar](<>)
    -   [Xenserver](https://www.xenserver.com/)
    -   [Wiki XenProject](https://wiki.xenproject.org/wiki/Main_Page)
    -   [Interfaces de rede](https://wiki.xenproject.org/wiki/Xen_Networking#Virtual_Network_Interfaces)
    -   [Ferramentas Xen](https://xen-tools.org/software/)
    -   [LPI Blog: Xen Virtualiza√ß√£o e computa√ß√£o em nuvem #01: Introdu√ß√£o](https://www.lpi.org/pt-br/blog/2020/10/01/xen-virtualization-and-cloud-computing-01-introduction/)
    -   [LPI Blog: Xen Virtualiza√ß√£o e computa√ß√£o em nuvem #02: Como Xen faz o trabalho](https://www.lpi.org/blog/2020/10/08/xen-virtualization-and-cloud-computing-02-how-xen-does-job/)
    -   [LPI Blog: Xen Virtualiza√ß√£o e computa√ß√£o em nuvem #04: Cont√™ineres, OpenStack e outras plataformas relacionadas](https://www.lpi.org/pt-br/blog/2020/10/22/xen-virtualization-and-cloud-computing-04-containers-openstack-and-other-related/)
    -   [Virtualiza√ß√£o Xen e Computa√ß√£o em Cloud #05: O Projeto Xen, Unikernels e o Futuro](https://www.lpi.org/pt-br/blog/2020/10/29/xen-virtualization-and-cloud-computing-05-xen-project-unikernels-and-future/)
    -   [Guia para iniciantes do projeto Xen](https://wiki.xenproject.org/wiki/Xen_Project_Beginners_Guide#Installing_the_Xen_Project_Software)
    -   [Livro maluco](https://wiki.xenproject.org/wiki/Book/HelloXenProject/0-Contents)
-   [Unicernel](https://www.lpi.org/blog/2020/10/29/xen-virtualization-and-cloud-computing-05-xen-project-unikernels-and-future/)
    -   [For√ßa √∫nica](https://github.com/unikraft/unikraft)
    -   [Mirageos](https://mirage.io/docs/hello-world)
    -   [Ruim](https://galois.com/project/halvm/)
    -   [Exclusivo](https://github.com/solo-io/unik/blob/master/docs/providers/virtualbox.md)
-   [KVM](<>)
    -   [Oficial Doc](https://linux-kvm.org/page/Main_Page)
    -   [KVM (m√°quinas virtuais do kernel por redhat)](https://www.redhat.com/pt-br/topics/virtualization/what-is-KVM)
    -   [Ferramentas de gerenciamento da KVM](https://www.linux-kvm.org/page/Management_Tools)
    -   [Rede KVM](https://www.linux-kvm.org/page/Networking)
-   [Qemu](<>)
    -   [Oficial Doc](https://www.qemu.org/)
    -   [Baixe imagens osboxes](https://www.osboxes.org/)
    -   [Fa√ßa o download de imagens linuximages](https://www.linuxvmimages.com/)
    -   [Urbano](https://en.wikibooks.org/wiki/QEMU/Devices/Virtio)
    -   [Agente convidado](https://wiki.qemu.org/Features/GuestAgent)
-   [Libvirt](<>)
    -   [Oficial Doc](https://libvirt.org/)
    -   [Ativa√ß√£o do soquete do sistema](https://libvirt.org/manpages/libvirtd.html#system-socket-activation)
    -   [Conex√µes](https://libvirt.org/uri.html)
    -   [Armazenar](https://libvirt.org/storage.html)
    -   [Rede](https://wiki.libvirt.org/Networking.html)
    -   [VirtualNetwork](https://wiki.libvirt.org/VirtualNetworking.html)
    -   [Virtogd](https://libvirt.org/manpages/virtlogd.html)
    -   [Virtlockd](https://libvirt.org/manpages/virtlockd.html)
    -   [virt-manager](https://virt-manager.org/)
-   [Gerenciamento de disco](<>)
    -   [Imagens de disco](https://qemu-project.gitlab.io/qemu/system/images.html)
    -   [c√≥pia-em-escrever](https://sempreupdate.com.br/linux/tutoriais/sistema-de-arquivos-copy-on-write-saiba-o-que-e-e-quais-as-vantagens-e-desvantagens/)
    -   [RAM X QCOW2](https://docs.redhat.com/en/documentation/red_hat_virtualization/4.3/html/technical_reference/qcow2)
    -   [Libguestfs](https://libguestfs.org/)
-   [Cont√™ineres](<>)
    -   [Cont√™ineres da AWS DOC](https://aws.amazon.com/pt/containers/)
    -   [Cont√™ineres do DOC GCP](https://cloud.google.com/learn/what-are-containers?hl=pt-br)
    -   [IBM Doc Container](https://www.ibm.com/br-pt/topics/containers)
    -   [Red Hat Docs Containers](https://www.redhat.com/en/topics/containers/whats-a-linux-container)
    -   [Namespaces](https://manpages.ubuntu.com/manpages/noble/man7/namespaces.7.html)
    -   [Os namespaces mais importantes](https://www.redhat.com/en/blog/7-linux-namespaces)
    -   [Classes CGROUPS](https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/6/html/resource_management_guide/ch01)
    -   [Homem CGROUPS](https://manpages.ubuntu.com/manpages/noble/man7/cgroups.7.html)
    -   [Recursos Doc](https://linux-audit.com/kernel/capabilities/linux-capabilities-101/)
    -   [Capacidades do homem](https://manpages.ubuntu.com/manpages/noble/man7/capabilities.7.html)
    -   [Perfis Seccomp no Docker](https://docs.docker.com/engine/security/seccomp/)
    -   [Perfis de Aparmor no Docker](https://docs.docker.com/engine/security/apparmor/)
    -   [Selinux](https://pt.wikipedia.org/wiki/SELinux)
    -   [Compara√ß√£o do Appmor Selinux](https://www.redhat.com/en/blog/apparmor-selinux-isolation)
    -   [Runc](https://www.docker.com/blog/runc/)
    -   [Runc Github](https://github.com/opencontainers/runc)
    -   [OCI](https://opencontainers.org/about/overview/)
    -   [Cri](https://kubernetes.io/docs/concepts/architecture/cri/)
    -   [CRI-O](https://cri-o.io/)
    -   [cont√™iner](https://containerd.io/)
    -   [Subman](https://www.redhat.com/pt-br/topics/containers/what-is-podman)
    -   [Escopo](https://www.redhat.com/pt-br/topics/containers/what-is-skopeo)
    -   [Buildah](https://www.redhat.com/en/topics/containers/what-is-buildah)
    -   [OpenVZ](https://openvz.org/)
    -   [Crun](https://www.redhat.com/en/blog/introduction-crun)
    -   [dizer](https://katacontainers.io/)
-   [LXC - Cont√™ineres Linux](<>)
    -   [LXC](https://linuxcontainers.org/lxc/introduction/)
    -   [Lxd can√¥nico](https://canonical.com/lxd)
    -   [LXD Github can√¥nico](https://github.com/canonical/lxd)
    -   [Documenta√ß√£o LXD](https://linuxcontainers.org/lxd/docs/master/)
    -   [Imagens de cont√™iner Linux](https://images.linuxcontainers.org/)
-   [OpenStack Docs](<>)
    -   [Redhat](https://www.redhat.com/pt-br/topics/openstack)
-   [Aberto vswitch](<>)
    -   [OVS DOC 4LINUX](https://blog.4linux.com.br/open-vswitch-o-que-e-o-que-come-onde-vive)
-   [Exame LPIC-3 305-300](<>)
    -   [Lpic-3 305-300 Objetivos](https://www.lpi.org/our-certifications/exam-305-objectives/)
    -   [LPIC-3 305-300 Wiki](https://wiki.lpi.org/wiki/LPIC-305_Objectives_V3.0)
    -   [Lpic-3 305-300 Material de aprendizado](https://cursos.linuxsemfronteiras.com.br/courses/preparatorio-para-certificacao-lpic-3-305/)
    -   [LPIC-3 305-300 Exame simulado pela ITEXAMS](https://www.itexams.com/info/305-300)

<p align="right">(<a href="#readme-top">back to top</a>)</p>

* * *

<!-- MARKDOWN LINKS & IMAGES -->

<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->

[contributors-shield]: https://img.shields.io/github/contributors/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[contributors-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/graphs/contributors

[forks-shield]: https://img.shields.io/github/forks/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[forks-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/network/members

[stars-shield]: https://img.shields.io/github/stars/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[stars-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/stargazers

[issues-shield]: https://img.shields.io/github/issues/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[issues-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/issues

[license-shield]: https://img.shields.io/github/license/marcossilvestrini/learning-lpic-3-305-300.svg?style=for-the-badge

[license-url]: https://github.com/marcossilvestrini/learning-lpic-3-305-300/blob/main/LICENSE

[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555

[linkedin-url]: https://linkedin.com/in/marcossilvestrini

[def]: https://httpd.apache.org/docs/2.4/mod/directives.html
