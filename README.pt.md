# LEARNING LPIC-3 305-300

![LPIC3-305-300](images/lpic3-305-300.jpg)

<p align="center">
<strong>Explore a documenta√ß√£o ¬ª</strong></a>
    <br />
    <a href="https://marcossilvestrini.github.io/learning-lpic-3-305-300/">Site Web</a>
    -
    <a href="https://github.com/marcossilvestrini/learning-lpic-3-305-300">P√°gina de C√≥digo</a>
    -
    <a href="https://skynet-8.gitbook.io/learning-lpic-3-305-300">Gitbook</a>
    -
    <a href="https://github.com/marcossilvestrini/learning-lpic-3-305-300/issues">Reportar Bug</a>
    -
    <a href="https://github.com/marcossilvestrini/learning-lpic-3-305-300/issues">Solicitar Funcionalidade</a>
</p>

---

## Resumo

<details>
  <summary><b>TABELA DE CONTE√öDO</b></summary>
  <ol>
    <li>
      <a href="#about-the-project">Sobre o Projeto</a>
    </li>
    <li>
      <a href="#getting-started">Come√ßando</a>
      <ul>
        <li><a href="#prerequisites">Pr√©-requisitos</a></li>
        <li><a href="#installation">Instala√ß√£o</a></li>
      </ul>
    </li>
    <li><a href="#usage">Uso</a></li>
    <li><a href="#roadmap">Roteiro</a></li>
    <li><a href="#freedoms">Quatro Liberdades Essenciais</a></li>
    <li>
      <a href="#topic-351">T√≥pico 351: Virtualiza√ß√£o Completa</a>
      <ul>
        <li><a href="#topic-351.1">351.1 Conceitos e Teoria da Virtualiza√ß√£o</a></li>
        <li><a href="#topic-351.2">351.2 Xen</a></li>
        <li><a href="#topic-351.3">351.3 QEMU</a></li>
        <li><a href="#topic-351.4">351.4 Gerenciamento de M√°quinas Virtuais com Libvirt</a></li>
        <li><a href="#topic-351.5">351.5 Gerenciamento de Imagens de Disco de M√°quinas Virtuais</a></li>
      </ul>
    </li>
    <li>
      <a href="#topic-352">T√≥pico 352: Virtualiza√ß√£o de Cont√™ineres</a>
      <ul>
        <li><a href="#topic-352.1">352.1 Conceitos de Virtualiza√ß√£o por Cont√™iner</a></li>
        <li><a href="#topic-352.2">352.2 LXC</a></li>
        <li><a href="#topic-352.3">352.3 Docker</a></li>
        <li><a href="#topic-352.4">352.4 Plataformas de Orquestra√ß√£o de Cont√™ineres</a></li>
      </ul>
    </li>
    <li>
      <a href="#topic-353">T√≥pico 353: Implanta√ß√£o e Provisionamento de VM</a>
      <ul>
        <li><a href="#topic-353.1">353.1 Ferramentas de Gerenciamento Cloud</a></li>
        <li><a href="#topic-353.2">353.2 Packer</a></li>
        <li><a href="#topic-353.3">353.3 cloud-init</a></li>
        <li><a href="#topic-353.4">353.4 Vagrant</a></li>
      </ul>
    </li>
    <li><a href="#license">Licen√ßa</a></li>
    <li><a href="#contact">Contato</a></li>
    <li><a href="#acknowledgments">Agradecimentos</a></li>
  </ol>
</details><br>

---

<a name="about-the-project"></a>

## Sobre o Projeto

> Este projeto tem como objetivo ajudar estudantes ou profissionais a aprender os principais conceitos de GNULinux
> e softwares livres
> Algumas distribui√ß√µes GNULinux, como Debian e RPM, ser√£o abordadas
> Instala√ß√£o e configura√ß√£o de alguns pacotes tamb√©m ser√£o abordados
> Assim, voc√™ pode oferecer √† comunidade a oportunidade de se beneficiar de suas mudan√ßas.
> O acesso ao c√≥digo-fonte √© uma pr√©-condi√ß√£o para isso.
> Use o vagrant para levantar m√°quinas e executar laborat√≥rios e conte√∫dos pr√°ticos neste artigo.
> Publiquei na pasta Vagrant um arquivo Vagrantfile com o necess√°rio
> para voc√™ criar um ambiente de estudos

---

<p align="right">(<a href="#readme-top">voltar ao topo</a>)</p>

<a name="getting-started"></a>

## Come√ßando

Para iniciar o aprendizado, consulte a documenta√ß√£o acima.

<a name="prerequisites"></a>

### Pr√©-requisitos

* [Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
* [VMware Workstation](https://blogs.vmware.com/workstation/2024/05/vmware-workstation-pro-now-available-free-for-personal-use.html)
* [Vagrant VMWare Utility](https://developer.hashicorp.com/vagrant/install/vmware)
* [Vagrant](https://developer.hashicorp.com/vagrant/install)

<a name="installation"></a>

### Instala√ß√£o

Clone o reposit√≥rio

```sh
git clone https://github.com/marcossilvestrini/learning-lpic-3-305-300.git
cd learning-lpic-3-305-300
```

Personalize um arquivo modelo *Vagrantfile-topic-XXX*. Este arquivo cont√©m a configura√ß√£o de VMs para os laborat√≥rios. Exemplo:

* Arquivo [Vagrantfile-topic-351](vagrant/Vagrantfile-topic-351)
  * vm.clone_directory = "<letra_da_unidade>:\\`<pasta>`\\<para_vm>\\#{VM_NAME}-instance-1"
    Exemplo: vm.clone_directory = "E:\\Servidores\\VMWare\\#{VM_NAME}-instance-1"
  * vm.vmx["memsize"] = ""
  * vm.vmx["numvcpus"] = ""
  * vm.vmx["cpuid.coresPerSocket"] = ""

Altere a configura√ß√£o da rede nos arquivos [configs/network](configs/network/).

---

<a name="usage"></a>

## Uso

Utilize este reposit√≥rio para obter conhecimentos sobre o exame LPIC-3 305-300

### Para subir e parar

Altere o template *Vagrantfile-topic-xxx* e copie para um novo arquivo chamado *Vagrantfile*

```sh
cd vagrant && vagrant up
cd vagrant && vagrant destroy -f
```

### Para reiniciar as VMs

```sh
cd vagrant && vagrant reload
```

**Importante:**
*Se voc√™ reiniciar as VMs sem usar o vagrant, a pasta compartilhada n√£o ser√° montada ap√≥s a reinicializa√ß√£o.*

### Para usar powershell para subir e parar

Se usar Windows, criei um script powershell para subir e parar as VMs.

```powershell
vagrant/up.ps1
vagrant/destroy.ps1
```

### Esquema de Infraestrutura T√≥pico 351

![topic-351](images/infraestructure-topic-351.png)

<p align="right">(<a href="#readme-top">voltar ao topo</a>)</p>

---

<a name="roadmap"></a>

## Roteiro

* [X] Criar reposit√≥rio
* [X] Criar scripts para provisionamento dos laborat√≥rios
* [X] Criar exemplos sobre o T√≥pico 351
* [X] Criar exemplos sobre o T√≥pico 352
* [ ] Criar exemplos sobre o T√≥pico 353
* [ ] Carregar simulado do ITexams

---

<a name="freedoms"></a>

## Quatro Liberdades Essenciais

> 0. A liberdade de executar o programa como desejar, para qualquer prop√≥sito (liberdade 0).
> 1. A liberdade de estudar como o programa funciona, e modific√°-lo para que fa√ßa
> seu c√°lculo como desejar (liberdade 1).
> O acesso ao c√≥digo-fonte √© uma condi√ß√£o pr√©via para isso.
> 2. A liberdade de redistribuir c√≥pias para ajudar os outros (liberdade 2).
> 3. liberdade de distribuir c√≥pias das suas vers√µes modificadas para outras pessoas (liberdade 3).

---

## Comandos de inspe√ß√£o

```sh
type COMANDO
apropos COMANDO
whatis COMANDO --long
whereis COMANDO
COMANDO --help, --h
man COMANDO
```

<p align="right">(<a href="#readme-top">voltar ao topo</a>)</p>

---

<a name="topic-351"></a>

## T√≥pico 351: Virtualiza√ß√£o Completa

![LPIC3-305-300](images/virtualization-351.png)

---

<a name="topic-351.1"></a>

### 351.1 Conceitos e Teoria da Virtualiza√ß√£o

**Peso:** 6

**Descri√ß√£o:** Os candidatos devem conhecer e compreender os conceitos gerais, teoria e terminologia da virtualiza√ß√£o. Isso inclui Xen, QEMU e terminologia libvirt.

**√Åreas de Conhecimento-Chave:**

* üñ•Ô∏è Compreender terminologia de virtualiza√ß√£o
* ‚öñÔ∏è Entender os pr√≥s e contras da virtualiza√ß√£o
* üõ†Ô∏è Entender as v√°rias varia√ß√µes de Hipervisores e Monitores de M√°quinas Virtuais
* üîÑ Compreender os principais aspectos da migra√ß√£o de m√°quinas f√≠sicas para virtuais
* üöÄ Compreender os principais aspectos da migra√ß√£o de m√°quinas virtuais entre sistemas hospedeiros
* üì∏ Compreender recursos e implica√ß√µes da virtualiza√ß√£o para uma m√°quina virtual, como snapshot, pausa, clonagem e limites de recursos
* üåê Conhecimento de oVirt, Proxmox, systemd-machined e VirtualBox
* üîó Conhecimento de Open vSwitch

#### 351.1 Objetos Citados

```sh
Hypervisor
M√°quina Virtual de Hardware (HVM)
Paravirtualiza√ß√£o (PV)
Emula√ß√£o e Simula√ß√£o
Flags de CPU
/proc/cpuinfo
Migra√ß√£o (P2V, V2V)
```

#### Hipervisores

##### Tipo 1 Hypervisor (Hypervisor de Metal Nudo)

###### Defini√ß√£o de Tipo 1

Executa diretamente no hardware f√≠sico do host, fornecendo uma camada base para gerenciar VMs sem a necessidade de um sistema operacional hospedeiro.

###### Caracter√≠sticas do Tipo 1

* ‚ö° Alto desempenho e efici√™ncia.
* ‚è±Ô∏è Lat√™ncia e overhead menores.
* üè¢ Frequentemente usado em ambientes empresariais e data centers.

###### Exemplos de Tipo 1

* VMware ESXi: Um hypervisor robusto e amplamente utilizado em ambientes empresariais.
* Microsoft Hyper-V: Integrado ao Windows Server, oferecendo alto desempenho e recursos de gerenciamento.
* Xen: Hypervisor de c√≥digo aberto usado por muitos provedores de servi√ßos em nuvem.
* KVM (Kernel-based Virtual Machine): Integrado ao kernel Linux, oferecendo alto desempenho para sistemas Linux.

##### Tipo 2 Hypervisor (Hypervisor Hospedado)

###### Defini√ß√£o de Tipo 2

Executa sobre um sistema operacional convencional, dependendo do OS hospedeiro para gerenciamento de recursos e suporte a dispositivos.

###### Caracter√≠sticas do Tipo 2

* üõ†Ô∏è Mais f√°cil de configurar e usar, especialmente em PCs pessoais.
* üîß Mais flex√≠vel para desenvolvimento, testes e implanta√ß√µes em pequena escala.
* üê¢ Geralmente menos eficiente que Hypervisores de Tipo 1 devido ao overhead adicional do sistema operacional hospedeiro.

###### Exemplos de Tipo 2

* VMware Workstation: Um hypervisor potente para executar m√∫ltiplos sistemas operacionais em um desktop.
* Oracle VirtualBox: Hypervisor de c√≥digo aberto conhecido por sua flexibilidade e facilidade de uso.
* Parallels Desktop: Projetado para Mac para executar Windows e outros sistemas ao lado do macOS.
* QEMU (Quick EMUlator): Emulador e virtualizador de c√≥digo aberto, frequentemente usado junto com KVM.

##### Diferen√ßas Principais entre Hypervisores de Tipo 1 e Tipo 2

* Ambiente de Desdobramento:
  * Hypervisores de Tipo 1 s√£o comumente implantados em data centers e ambientes empresariais por seu contato direto com o hardware e alto desempenho.
  * Hypervisores de Tipo 2 s√£o mais apropriados para uso pessoal, desenvolvimento, testes e tarefas de virtualiza√ß√£o em pequena escala.
* Desempenho:
  * Hypervisores de Tipo 1 geralmente oferecem melhor desempenho e menor lat√™ncia por n√£o dependerem de um sistema operacional hospedeiro.
  * Hypervisores de Tipo 2 podem sofrer com degrada√ß√£o de desempenho devido ao overhead do sistema operacional hospedeiro.
* Gest√£o e Facilidade de Uso:
  * Hypervisores de Tipo 1 requerem configura√ß√£o e gerenciamento mais complexos, oferecendo recursos avan√ßados e escalabilidade para grandes ambientes.
  * Hypervisores de Tipo 2 s√£o mais f√°ceis de instalar e usar, sendo ideais para usu√°rios individuais e projetos menores.

##### Tipos de Migra√ß√£o

No contexto de hypervisores, que s√£o tecnologias usadas para criar e gerenciar m√°quinas virtuais, os termos P2V (F√≠sico para Virtual) e V2V (Virtual para Virtual) s√£o comuns em ambientes de virtualiza√ß√£o.
Refere-se aos processos de migra√ß√£o entre plataformas diferentes.

##### P2V - Migra√ß√£o de F√≠sico para Virtual

P2V refere-se ao processo de migrar um servidor f√≠sico para uma m√°quina virtual. Em outras palavras, um sistema operacional e seus aplicativos, executados em hardware dedicado, s√£o "convertidos" e movidos para uma m√°quina virtual que roda em um hypervisor (como VMware, Hyper-V, KVM, etc.).

* Exemplo: Voc√™ possui um servidor f√≠sico com Windows ou Linux e deseja mov√™-lo para um ambiente virtualizado, como uma infraestrutura de nuvem ou um servidor de virtualiza√ß√£o interno.
* O processo envolve copiar todo o estado do sistema, incluindo o sistema operacional, drivers e dados, para criar uma VM equivalente que possa ser executada como se estivesse no hardware f√≠sico.

##### V2V - Virtual para Virtual Migration

V2V refere-se ao processo de migrar uma m√°quina virtual de um hypervisor para outro. Neste caso, voc√™ j√° tem uma VM em execu√ß√£o em um ambiente virtualizado (como VMware), e deseja mov√™-la para outro ambiente virtualizado (por exemplo, para Hyper-V ou para um novo servidor VMware).

* Exemplo: Voc√™ tem uma VM rodando em um servidor VMware, mas decide migr√°-la para uma plataforma Hyper-V. Nesse caso, a migra√ß√£o V2V converte a VM de um formato ou hypervisor para outro, garantindo sua continuidade operacional.

#### HVM e Paravirtualiza√ß√£o

##### Virtualiza√ß√£o Assistida por Hardware (HVM)

###### Defini√ß√£o de HVM

HVM aproveita extens√µes de hardware fornecidas por CPUs modernas para virtualizar o hardware, permitindo a cria√ß√£o e gerenciamento de VMs com overhead de desempenho m√≠nimo.

###### Caracter√≠sticas Chave de HVM

* üñ•Ô∏è **Suporte de Hardware**: Necessita suporte de CPU para extens√µes de virtualiza√ß√£o, como Intel VT-x ou AMD-V.
* üõ†Ô∏è **Virtualiza√ß√£o Completa:** VMs podem rodar sistemas operacionais convidados n√£o modificados, pois o hypervisor fornece uma emula√ß√£o completa do hardware.
* ‚ö° **Desempenho:** Geralmente oferece desempenho quase nativo devido √† execu√ß√£o direta do c√≥digo do convidado na CPU.
* üîí **Isolamento:** Oferece forte isolamento entre VMs, uma vez que cada VM opera como se tivesse hardware dedicado.

###### Exemplos de HVM

VMware ESXi, Microsoft Hyper-V, KVM (Kernel-based Virtual Machine).

###### Vantagens de HVM

* ‚úÖ **Compatibilidade:** Pode executar qualquer sistema operacional sem modifica√ß√£o.
* ‚ö° **Desempenho:** Alto desempenho devido ao suporte de hardware.
* üîí **Seguran√ßa:** Recursos aprimorados de isolamento e seguran√ßa fornecidos pelo hardware.

###### Desvantagens de HVM

* üõ†Ô∏è **Depend√™ncia de Hardware:** Requer recursos espec√≠ficos de hardware, limitando a compatibilidade com sistemas antigos.
* üîß **Complexidade:** Pode envolver configura√ß√µes mais complexas e gerenciamento.

##### Paravirtualiza√ß√£o

###### Defini√ß√£o de Paravirtualiza√ß√£o

Paravirtualiza√ß√£o envolve modificar o sistema operacional convidado para estar ciente do ambiente virtualizado, permitindo uma intera√ß√£o mais eficiente com o hypervisor.

###### Caracter√≠sticas-Chave de Paravirtualiza√ß√£o

* üõ†Ô∏è **Modifica√ß√£o do Convidado:** Requer altera√ß√µes no sistema operacional convidado para comunicar-se diretamente com o hypervisor usando hypercalls.
* ‚ö° **Desempenho:** Pode ser mais eficiente que a virtualiza√ß√£o completa tradicional, pois reduz o overhead associado √† emula√ß√£o de hardware.
* üîó **Compatibilidade:** Limitado a OS que foram modificados para paravirtualiza√ß√£o.

###### Exemplos de Paravirtualiza√ß√£o

Xen com convidados paravirtualizados, ferramentas VMware em certas configura√ß√µes, e algumas configura√ß√µes de KVM.

###### Vantagens da Paravirtualiza√ß√£o

* ‚ö° **Efici√™ncia:** Reduz o overhead da virtualiza√ß√£o de hardware, oferecendo melhor desempenho para certos workloads.
* ‚úÖ **Utiliza√ß√£o de Recursos:** Uso mais eficiente dos recursos do sistema devido √† comunica√ß√£o direta entre o OS convidado e o hypervisor.

###### Desvantagens da Paravirtualiza√ß√£o

* üõ†Ô∏è **Modifica√ß√£o do Sistema Operacional:** Requer modifica√ß√µes no OS convidado, limitando compatibilidade a sistemas suportados.
* üîß **Complexidade:** Necessita de configura√ß√µes adicionais no sistema convidado para implementa√ß√£o de hypercalls.

##### Diferen√ßas-Chave

###### Requisitos do Sistema Operacional Convidado

* **HVM:** Pode rodar sistemas convidados n√£o modificados.
* **Paravirtualiza√ß√£o:** Requer modifica√ß√µes no OS convidado para funcionar com o hypervisor.

###### Desempenho

* **HVM:** Geralmente fornece desempenho pr√≥ximo ao nativo devido √† execu√ß√£o assistida por hardware.
* **Paravirtualiza√ß√£o:** Pode oferecer desempenho eficiente, reduzindo o overhead da emula√ß√£o de hardware, mas depende do OS convidado modificado.

###### Depend√™ncia de Hardware

* **HVM:** Requer recursos espec√≠ficos de CPU (Intel VT-x, AMD-V).
* **Paravirtualiza√ß√£o:** N√£o requer recursos espec√≠ficos de CPU, mas necessita de OS convidado modificado.

###### Isolamento

* **HVM:** Fornece forte isolamento usando recursos de hardware.
* **Paravirtualiza√ß√£o:** Confia em isolamento baseado em software, que pode n√£o ser t√£o robusto quanto o baseado em hardware.

###### Complexidade

* **HVM:** Geralmente mais simples de implementar, pois suporta OS n√£o modificados.
* **Paravirtualiza√ß√£o:** Requer configura√ß√µes adicionais e modifica√ß√µes no OS convidado, aumentando a complexidade.

#### NUMA (Acesso N√£o Uniforme √† Mem√≥ria)

NUMA (Non-Uniform Memory Access) √© uma arquitetura de mem√≥ria usada em sistemas multiprocessadores para otimizar o acesso √† mem√≥ria pelos processadores.
Em um sistema NUMA, a mem√≥ria √© distribu√≠da de forma desigual entre os processadores, ou seja, cada processador tem acesso mais r√°pido a uma por√ß√£o da mem√≥ria (sua "mem√≥ria local") do que √† mem√≥ria que est√° fisicamente mais distante (referida como "mem√≥ria remota") e associada a outros processadores.

##### Caracter√≠sticas Chave da Arquitetura NUMA

1. **Mem√≥ria Local e Remota**: Cada processador possui sua pr√≥pria mem√≥ria local, acess√≠vel mais rapidamente. No entanto, tamb√©m pode acessar a mem√≥ria de outros processadores, embora demore mais.
2. **Lat√™ncia Diferenciada**: A lat√™ncia de acesso √† mem√≥ria varia dependendo de o processador estar acessando sua mem√≥ria local ou a mem√≥ria de outro n√≥. O acesso √† mem√≥ria local √© mais r√°pido, enquanto o acesso a uma mem√≥ria remota √© mais lento.
3. **Escalabilidade**: A arquitetura NUMA foi projetada para melhorar a escalabilidade em sistemas com muitos processadores. √Ä medida que mais processadores s√£o adicionados, a mem√≥ria tamb√©m √© distribu√≠da, evitando o gargalo que ocorreria em uma arquitetura de acesso uniforme √† mem√≥ria (UMA).

##### Vantagens do NUMA

* ‚ö° Melhor desempenho em sistemas grandes: Como cada processador possui sua pr√≥pria mem√≥ria local, ele pode trabalhar de maneira mais eficiente, sem competir tanto por acesso √† mem√≥ria.
* üìà Escalabilidade: NUMA permite que sistemas com m√∫ltiplos processadores e grandes quantidades de mem√≥ria tenham uma expans√£o mais eficiente, em compara√ß√£o com uma arquitetura UMA.

##### Desvantagens

* üõ†Ô∏è Complexidade de programa√ß√£o: Os programadores precisam estar cientes de quais regi√µes de mem√≥ria s√£o locais ou remotas, otimizando o uso da mem√≥ria local para melhor desempenho.
* üê¢ Penalidades de desempenho potenciais: Se um processador acessar frequentemente a mem√≥ria remota, o desempenho pode sofrer devido √† maior lat√™ncia.
  Essa arquitetura √© comum em sistemas de multiprocessamento de alto desempenho, como servidores e supercomputadores, onde a escalabilidade e otimiza√ß√£o de mem√≥ria s√£o cr√≠ticas.

#### Solu√ß√µes Open Source

* üåê oVirt: [https://www.ovirt.org/](https://www.ovirt.org/)
* üåê Proxmox: [https://www.proxmox.com/en/proxmox-virtual-environment/overview](https://www.proxmox.com/en/proxmox-virtual-environment/overview)
* üåê Oracle VirtualBox: [https://www.virtualbox.org/](https://www.virtualbox.org/)
* üåê Open vSwitch: [https://www.openvswitch.org/](https://www.openvswitch.org/)

#### Tipos de Virtualiza√ß√£o

##### Virtualiza√ß√£o de Hardware (Virtualiza√ß√£o de Servidores)

###### HV Defini√ß√£o

Abstracts hardware f√≠sico para criar m√°quinas virtuais (VMs) que executam sistemas operacionais e aplicativos independentes.

###### Casos de Uso de HV

Data centers, computa√ß√£o em nuvem, consolida√ß√£o de servidores.

###### Exemplos de HV

VMware ESXi, Microsoft Hyper-V, KVM.

##### Virtualiza√ß√£o de Sistema Operacional (Cont√™ineres)

###### Defini√ß√£o de Cont√™ineres

Permite m√∫ltiplas inst√¢ncias isoladas de espa√ßo de usu√°rio (cont√™ineres) em um √∫nico kernel de sistema operacional.

###### Casos de Uso de Cont√™ineres

Arquitetura de microsservi√ßos, ambientes de desenvolvimento e testes.

###### Exemplos de Cont√™ineres

Docker, Kubernetes, LXC.

##### Virtualiza√ß√£o de Rede

###### Defini√ß√£o de Virtualiza√ß√£o de Rede

Combina recursos de rede de hardware e software em uma √∫nica entidade administrativa baseada em software.

###### Casos de Uso de Virtualiza√ß√£o de Rede

Redes definidas por software (SDN), virtualiza√ß√£o de fun√ß√µes de rede (NFV).

###### Exemplos de Virtualiza√ß√£o de Rede

VMware NSX, Cisco ACI, OpenStack Neutron.

##### Virtualiza√ß√£o de Armazenamento

###### Defini√ß√£o de Virtualiza√ß√£o de Armazenamento

Agrupa armazenamento f√≠sico de v√°rios dispositivos em uma √∫nica unidade de armazenamento virtual que pode ser gerenciada centralmente.

###### Casos de Uso de Virtualiza√ß√£o de Armazenamento

Gest√£o de dados, otimiza√ß√£o de armazenamento, recupera√ß√£o de desastres.

###### Exemplos de Virtualiza√ß√£o de Armazenamento

IBM SAN Volume Controller, VMware vSAN, NetApp ONTAP.

##### Virtualiza√ß√£o de Desktop

###### Defini√ß√£o de Virtualiza√ß√£o de Desktop

Permite que um sistema operacional desktop rode em uma m√°quina virtual hospedada em um servidor.

###### Casos de Uso de Virtualiza√ß√£o de Desktop

Infraestrutura de desktops virtuais (VDI), solu√ß√µes de trabalho remoto.

###### Exemplos de Virtualiza√ß√£o de Desktop

Citrix Virtual Apps and Desktops, VMware Horizon, Microsoft Remote Desktop Services.

##### Virtualiza√ß√£o de Aplicativos

###### Defini√ß√£o de Virtualiza√ß√£o de Aplicativos

Separa aplicativos do hardware e sistema operacional subjacentes, permitindo sua execu√ß√£o em ambientes isolados.

###### Casos de Uso de Virtualiza√ß√£o de Aplicativos

Simplifica√ß√£o do deployment de aplicativos, testes de compatibilidade.

###### Exemplos de Virtualiza√ß√£o de Aplicativos

VMware ThinApp, Microsoft App-V, Citrix XenApp.

##### Virtualiza√ß√£o de Dados

###### Defini√ß√£o de Virtualiza√ß√£o de Dados

Integra dados de v√°rias fontes sem consolid√°-los fisicamente, oferecendo uma vis√£o unificada para an√°lise e relat√≥rios.

###### Casos de Uso de Virtualiza√ß√£o de Dados

Intelig√™ncia de neg√≥cios, integra√ß√£o de dados em tempo real.

###### Exemplos de Virtualiza√ß√£o de Dados

Denodo, Red Hat JBoss Data Virtualization, IBM InfoSphere.

##### Benef√≠cios da Virtualiza√ß√£o

* ‚ö° Efici√™ncia de Recursos: Melhor utiliza√ß√£o de recursos f√≠sicos.
* üí∞ Economia de Custos: Redu√ß√£o de custos de hardware e opera√ß√£o.
* üìà Escalabilidade: Facilmente escalar para cima ou para baixo conforme a demanda.
* üîß Flexibilidade: Suporta variados workloads e aplicativos.
* üîÑ Recupera√ß√£o de Desastres: Processos simplificados de backup e recupera√ß√£o.
* üîí Isolamento: Seguran√ßa aprimorada por meio do isolamento de ambientes.

#### Emula√ß√£o

Emula√ß√£o envolve simular o comportamento de hardware ou software em uma plataforma diferente daquela originalmente pretendida.

Este processo permite que software projetado para um sistema seja executado em outro sistema que pode ter arquitetura ou ambiente operacional diferentes.

Embora a emula√ß√£o ofere√ßa versatilidade ao possibilitar a execu√ß√£o de sistemas operacionais convidados ou aplicativos n√£o modificados, ela geralmente tem custos de desempenho.

Esse overhead surge porque o sistema emulado precisa interpretar e traduzir instru√ß√µes destinadas ao sistema original para instru√ß√µes compat√≠veis com o sistema hospedeiro. Como resultado, a emula√ß√£o pode ser mais lenta que a execu√ß√£o nativa, tornando-a menos eficiente para tarefas intensivas em recursos.

Apesar dessa limita√ß√£o, a emula√ß√£o continua valiosa para rodar softwares legados, testar aplicativos em plataformas diferentes e facilitar o desenvolvimento multiplataforma.

#### systemd-machined

 O servi√ßo systemd-machined √© dedicado √† gest√£o de m√°quinas virtuais e cont√™ineres dentro do ecossistema systemd.
 Ele fornece funcionalidades essenciais para controle, monitoramento e manuten√ß√£o de inst√¢ncias virtuais, oferecendo integra√ß√£o robusta e efici√™ncia em ambientes Linux.

<p align="right">(<a href="#topic-351.1">voltar ao sub T√≥pico 351.1</a>)</p>
<p align="right">(<a href="#topic-351">voltar ao T√≥pico 351</a>)</p>
<p align="right">(<a href="#readme-top">voltar ao topo</a>)</p>

---

<a name="topic-351.2"></a>

### 351.2 Xen

![xen-architecture](images/xen-achitecture.png)

![xen-architecture](images/xen-achitecture2.png)

**Peso:** 3

**Descri√ß√£o:** Os candidatos devem ser capazes de instalar, configurar, manter, migrar e solucionar problemas nas instala√ß√µes Xen. O foco est√° na vers√£o Xen 4.x.

**√Åreas de Conhecimento-Chave:**

* Compreender arquitetura do Xen, incluindo redes e armazenamento
* Configura√ß√£o b√°sica de n√≥s e dom√≠nios Xen
* Gerenciamento b√°sico de n√≥s e dom√≠nios Xen
* Solu√ß√£o de problemas b√°sica de instala√ß√µes Xen
* Conhecimento de XAPI
* Conhecimento de XenStore
* Conhecimento de Par√¢metros de Boot do Xen
* Conhecimento da utilidade xm

#### Xen

![panda](images/xen-panda.png)

Xen √© um hypervisor de c√≥digo aberto de tipo 1 (de metal nu), que permite que m√∫ltiplos sistemas operacionais rodem simultaneamente no mesmo hardware f√≠sico. O Xen fornece uma camada entre o hardware f√≠sico e as m√°quinas virtuais (VMs), possibilitando compartilhamento eficiente de recursos e isolamento.

* **Arquitetura:** Xen opera com um sistema de dois n√≠veis onde o Dom√≠nio 0 (Dom0) √© o dom√≠nio privilegiado com acesso direto ao hardware e gerencia o hypervisor. Outras m√°quinas virtuais, chamadas de DomU, executam sistemas operacionais convidados e s√£o gerenciadas pelo Dom0.
* **Tipos de Virtualiza√ß√£o:** Xen suporta tanto paravirtualiza√ß√£o (PV), que requer OS convidados modificados, quanto virtualiza√ß√£o assistida por hardware (HVM), que usa extens√µes de hardware (por exemplo, VT-x da Intel ou AMD-V) para executar sistemas convidados n√£o modificados.
  Xen √© amplamente usado em ambientes de nuvem, notavelmente pela AWS e outros provedores de nuvem de grande escala.

#### XenSource

XenSource foi a empresa fundada pelos desenvolvedores originais do hypervisor Xen na Universidade de Cambridge para comercializar o Xen.
A empresa fornecia solu√ß√µes empresariais baseadas no Xen e oferecia ferramentas e suporte adicionais para aprimorar o Xen para uso corporativo.

* **Aquisi√ß√£o pela Citrix**: Em 2007, a XenSource foi adquirida pela Citrix Systems, Inc. A Citrix usou a tecnologia Xen como base para o seu produto XenServer da Citrix, que se tornou uma plataforma de virtualiza√ß√£o empresarial popular baseada em Xen.
* **Transi√ß√£o**: Ap√≥s a aquisi√ß√£o, o projeto Xen continuou como um projeto de c√≥digo aberto, enquanto a Citrix focou em ofertas comerciais como o XenServer, aproveitando a tecnologia XenSource.

#### Xen Project

Xen Project refere-se √† comunidade e iniciativa de c√≥digo aberto respons√°vel pelo desenvolvimento e manuten√ß√£o do hypervisor Xen ap√≥s sua comercializa√ß√£o. O Xen Project opera sob a Funda√ß√£o Linux, com foco em construir, melhorar e apoiar o Xen como um esfor√ßo colaborativo e conduzido pela comunidade.

* **Objetivos:** O Xen Project visa avan√ßar o hypervisor aprimorando seu desempenho, seguran√ßa e conjunto de recursos para uma ampla gama de casos de uso, incluindo computa√ß√£o em nuvem, virtualiza√ß√£o centrada em seguran√ßa (por exemplo, Qubes OS) e sistemas embarcados.
* **Colaboradores:** O projeto inclui contribuintes de v√°rias organiza√ß√µes, incluindo grandes provedores de nuvem, fornecedores de hardware e desenvolvedores independentes.
* **XAPI e XenTools:** O Xen Project tamb√©m inclui ferramentas como XAPI (XenAPI) e v√°rias utilidades para gerenciamento e otimiza√ß√£o do sistema.

#### XenStore

Xen Store √© um componente cr√≠tico do hypervisor Xen.
Basicamente, Xen Store √© um banco de dados de chaves e valores distribu√≠do usado para comunica√ß√£o e compartilhamento de informa√ß√µes entre o hypervisor Xen e as m√°quinas virtuais (dom√≠nios) que ele gerencia.

Vamos aos aspectos principais do Xen Store:

* **Comunica√ß√£o entre Dom√≠nios:** Xen Store permite comunica√ß√£o entre dom√≠nios, como o Dom0 (dom√≠nio privilegiado que controla recursos de hardware) e os DomUs (dom√≠nios de usu√°rio, que s√£o as VMs). Isso √© feito por meio de entradas de chaves e valores, onde cada dom√≠nio pode ler ou escrever informa√ß√µes.
* **Gerenciamento de Configura√ß√µes:** √â usado para armazenar e acessar informa√ß√µes de configura√ß√£o, como dispositivos virtuais, rede e par√¢metros de boot. Isso facilita o gerenciamento din√¢mico e configura√ß√£o das VMs.
* **Eventos e Notifica√ß√µes:** Xen Store tamb√©m suporta notifica√ß√µes de eventos. Quando uma chave ou valor espec√≠fico no Xen Store √© modificado, os dom√≠nios interessados podem ser notificados para reagir a essas altera√ß√µes. Isso √© √∫til para monitoramento e gerenciamento de recursos.
* **API Simples:** Xen Store fornece uma API simples para leitura e escrita de dados, facilitando a integra√ß√£o de aplicativos com o sistema de virtualiza√ß√£o Xen.

#### XAPI

XAPI, ou XenAPI, √© a interface de programa√ß√£o de aplicativos (API) usada para gerenciar o hypervisor Xen e suas m√°quinas virtuais (VMs).
XAPI √© um componente chave do XenServer (agora conhecido como Hypervisor Citrix) e fornece uma maneira padronizada de interagir com o hypervisor Xen para realizar opera√ß√µes como criar, configurar, monitorar e controlar VMs.

Vamos aos aspectos importantes de XAPI:

* **Gerenciamento de VMs:** XAPI permite que administradores criem, excluam, iniciem e parem m√°quinas virtuais de forma program√°tica.
* **Automa√ß√£o:** Com XAPI, √© poss√≠vel automa√ß√£o na gest√£o de recursos virtuais, incluindo rede, armazenamento e computa√ß√£o, o que √© crucial para ambientes de nuvem.
* **Integra√ß√£o:** XAPI pode ser integrado a outras ferramentas e scripts para fornecer administra√ß√£o mais eficiente e personalizada do ambiente Xen.
* **Controle de Acesso:** XAPI tamb√©m fornece mecanismos de controle de acesso para garantir que apenas usu√°rios autorizados possam executar opera√ß√µes espec√≠ficas no ambiente virtual.

XAPI √© a interface que possibilita controle e automa√ß√£o do hypervisor Xen, facilitando a gest√£o de ambientes virtualizados.

#### Resumo do Xen

* **Xen:** A tecnologia de hypervisor central que permite que m√°quinas virtuais rodem em hardware f√≠sico.
* **XenSource:** A empresa que comercializou o Xen, posteriormente adquirida pela Citrix, levando ao desenvolvimento do XenServer da Citrix.
* **Xen Project:** A iniciativa e comunidade de c√≥digo aberto que continua a desenvolver e manter o hypervisor Xen sob a Funda√ß√£o Linux.
* **XenStore:**  Xen Store atua como intermedi√°rio de comunica√ß√£o e configura√ß√£o entre o hypervisor Xen e as VMs, agilizando a opera√ß√£o e gest√£o de ambientes virtualizados.
* **XAPI** √© a interface que possibilita controle e automa√ß√£o do hypervisor Xen, facilitando sua gest√£o.

#### Domain0 (Dom0)

Domain0, ou Dom0, √© o dom√≠nio de controle na arquitetura Xen. Ele gerencia outros dom√≠nios (DomUs) e tem acesso direto ao hardware.
Dom0 executa drivers de dispositivos, permitindo que DomUs, que n√£o t√™m acesso direto ao hardware, comuniquem-se com os dispositivos. Geralmente, √© uma inst√¢ncia completa de sistema operacional, como Linux, e √© essencial para o funcionamento do hypervisor Xen.

#### DomainU (DomU)

DomUs s√£o dom√≠nios sem privil√©gios que executam m√°quinas virtuais.
Eles s√£o gerenciados pelo Dom0 e n√£o possuem acesso direto ao hardware. Os DomUs podem ser configurados para executar sistemas operacionais diferentes e s√£o usados para v√°rias finalidades, como servidores de aplicativos e ambientes de desenvolvimento. Dependem do Dom0 para intera√ß√£o com o hardware.

#### PV-DomU (Dom√≠nio ParavirtualizadoU)

PV-DomUs usam uma t√©cnica chamada paravirtualiza√ß√£o. Nesse modelo, o sistema operacional DomU √© modificado para estar ciente do ambiente virtualizado, permitindo comunica√ß√£o direta com o hypervisor para desempenho otimizado.
Isso resulta em overhead menor e maior efici√™ncia em compara√ß√£o √† virtualiza√ß√£o completa.

#### HVM-DomU (M√°quina Virtual de Hardware DomU)

HVM-DomUs s√£o m√°quinas virtuais que utilizam virtualiza√ß√£o completa, permitindo que sistemas operacionais n√£o modificados rodem. O hypervisor Xen fornece emula√ß√£o de hardware para esses DomUs, possibilitando a execu√ß√£o de qualquer sistema que suporte a arquitetura de hardware subjacente.
Embora ofere√ßa maior flexibilidade, pode resultar em overhead maior em compara√ß√£o aos PV-DomUs.

#### Rede Xen

Rede Paravirtualizada
![pv-networking](images/xen-networking2.png)

Bridging
![pv-networking](images/xen-networking1.png)

#### 351.2 Cita√ß√µes de Objetos

```sh
Domain0 (Dom0), DomainU (DomU)
PV-DomU, HVM-DomU
/etc/xen/
xl
xl.cfg 
xl.conf # configura√ß√µes globais do Xen
xentop
oxenstored # configura√ß√µes do Xenstore
```

#### 351.2 Notas

```sh

# Configura√ß√µes do Xen
/etc/xen/
/etc/xen/xl.conf - Arquivo de configura√ß√£o geral do Xen
/etc/xen/oxenstored.conf - Configura√ß√µes do Xenstore

# Configura√ß√µes das VMs
/etc/xen/xlexample.pvlinux
/etc/xen/xlexample.hvm

# Configura√ß√µes de servi√ßo
/etc/default/xen
/etc/default/xendomains

# configura√ß√µes de xen-tools
/etc/xen-tools/
/usr/share/xen-tools/

# documentos
xl(1)
xl.conf(5)
xlcpupool.cfg(5)
xl-disk-configuration(5)
xl-network-configuration(5)
xen-tscmode(7)

# dom√≠nios auto inicializados
/etc/default/xendomains
   XENDOMAINS_AUTO=/etc/xen/auto

/etc/xen/auto/


# define dom√≠nio para subir ap√≥s reboot do xen
## criar pasta auto
cd /etc/xen && mkdir -p auto && cd auto

# criar link simb√≥lico
ln -s /etc/xen/lpic3-pv-guest /etc/xen/auto/lpic3-pv-guest
```

#### 351.2 Comandos Importantes

##### xen-create-image

```sh
# criar uma imagem pv
xen-create-image \
  --hostname=lpic3-pv-guest \
  --memory=1gb \
  --vcpus=2 \
  --lvm=vg_xen \
  --bridge=xenbr0 \
  --dhcp \
  --pygrub \
  --password=vagrant \
  --dist=bookworm
```

##### xen-list-images

```sh
# listar imagens
xen-list-image
```

##### xen-delete-image

```sh
# deletar uma imagem pv
xen-delete-image lpic3-pv-guest --lvm=vg_xen
```

##### xenstore-ls

```sh
# listar infos do xenstore
xenstore-ls
```

##### xl

```sh
# visualizar informa√ß√µes do xen
xl infos

# listar dom√≠nios
xl list
xl list lpic3-hvm-guest
xl list lpic3-hvm-guest -l

# uptime dos dom√≠nios
xl uptime

# pausar dom√≠nio
xl pause 2
xl pause lpic3-hvm-guest

# salvar estado dos dom√≠nios
xl -v save lpic3-hvm-guest ~root/image-lpic3-hvm-guest.save

# restaurar dom√≠nio
xl restore /root/image-lpic3-hvm-guest.save

# obter nome do dom√≠nio
xl domname 2

# visualizar dmesg
xl dmesg

# monitorar dom√≠nio
xl top
xentop
xen top

# Limitar mem√≥ria do Dom0
xl mem-set 0 2048

# Limitar cpu (n√£o permanente ap√≥s boot)
xl vcpu-set 0 2

# criar DomainU - m√°quina virtual
xl create /etc/xen/lpic3-pv-guest.cfg

# criar e conectar a m√°quina virtual ao guest
xl create -c /etc/xen/lpic3-pv-guest.cfg

##----------------------------------------------
# criar DomainU m√°quina virtual HVM

## criar volume l√≥gico
lvcreate -l +20%FREE -n lpic3-hvm-guest-disk  vg_xen

## criar t√∫nel ssh para vnc
ssh -l vagrant -L 5900:localhost:5900  192.168.0.130

## configurar /etc/xen/lpic3-hvm-guest.cfg
## definir boot para cdrom: boot = "d"

## criar dom√≠nio hvm
xl create /etc/xen/lpic3-hvm-guest.cfg

## abrir conex√£o VNC no cliente com localhost
## para visualiza√ß√£o, podem-se instalar detalhes

## ap√≥s instala√ß√£o, destruir dom√≠nio: xl destroy <id_nome>

## definir /etc/xen/lpic3-hvm-guest.cfg: boot para disco r√≠gido: boot = "c"

## criar dom√≠nio hvm
xl create /etc/xen/lpic3-hvm-guest.cfg

## acessar dom√≠nio hvm
xl console <id_nome>
##----------------------------------------------

# conectar no guest da VM
xl console <id>|<nome> (pressionar enter)
xl console 1
xl console lpic3-pv-guest

# Como sair do "xl console" do domU
#Press ctrl+] ou, no Putty, ctrl+5.

# Desligar a VM
xl shutdown lpic3-pv-guest

# destruir dom√≠nio
xl destroy lpic3-pv-guest

# reiniciar dom√≠nio
xl reboot lpic3-pv-guest

# listar dispositivos de bloco
xl block-list 1
xl block-list lpic3-pv-guest

# detach dispositivos de bloco
xl block-detach lpic3-hvm-guest hdc
xl block-detach 2 xvdc

# conectar dispositivos de bloco

## dispositivos de disco r√≠gido
xl block-attach lpic3-hvm-guest-ubuntu 'phy:/dev/vg_xen/lpic3-hvm-guest-disk2,xvde,w'

## cdrom
xl block-attach lpic3-hvm-guest 'file:/home/vagrant/isos/ubuntu/seed.iso,xvdc:cdrom,r'
xl block-attach 2 'file:/home/vagrant/isos/ubuntu/seed.iso,xvdc:cdrom,r'

# inserir e ejetar dispositivos de cdrom
xl cd-insert lpic3-hvm-guest-ubuntu xvdb  /home/vagrant/isos/ubuntu/ubuntu-24.04.1-live-server-amd64.iso
xl cd-eject lpic3-hvm-guest-ubuntu xvdb
```

#### 251.2 Notas

##### vif

No Xen, ‚Äúvif‚Äù significa Interface Virtual e √© usado para configurar a rede de m√°quinas virtuais (dom√≠nios).

Ao especificar diretivas ‚Äúvif‚Äù nos arquivos de configura√ß√£o do dom√≠nio, administradores podem definir interfaces de rede, atribuir endere√ßos IP, configurar VLANs e outros par√¢metros de rede para VMs em hosts Xen. Por exemplo: vif = ['bridge=xenbr0'], nesse caso, conecta a interface de rede da VM √† ponte Xen chamada ‚Äúxenbr0‚Äù.

```sh

<p align="right">(<a href="#topic-351.2">voltar ao sub T√≥pico 351.2</a>)</p>
<p align="right">(<a href="#topic-351">voltar ao T√≥pico 351</a>)</p>
<p align="right">(<a href="#readme-top">voltar ao topo</a>)</p>

---

<a name="topic-351.3"></a>

### 351.3 QEMU

![xen-kvm-qemu](/images/xen-kvm-qemu.png)

**Peso:** 4

**Descri√ß√£o:** Os candidatos devem ser capazes de instalar, configurar, manter, migrar e solucionar problemas nas instala√ß√µes QEMU.

**√Åreas de Conhecimento-Chave:**

* Compreender a arquitetura do QEMU, incluindo KVM, redes e armazenamento
* Iniciar inst√¢ncias QEMU a partir da linha de comando
* Gerenciar snapshots usando o monitor do QEMU
* Instalar o Agente Guest do QEMU e drivers VirtIO
* Resolver problemas de instala√ß√µes do QEMU, incluindo rede e armazenamento
* Conhecimento de par√¢metros de configura√ß√£o importantes do QEMU

#### Objetos Citados de 351.3

```sh
M√≥dulos do Kernel: kvm, kvm-intel e kvm-amd
/dev/kvm
Monitor do QEMU
qemu
qemu-system-x86_64
ip
brctl
tunctl
```

#### Comandos Importantes de 351.3

##### Outros comandos de 351.3

##### verificar m√≥dulo kvm

```sh
# verificar se kvm est√° ativado
egrep -o '(vmx|svm)' /proc/cpuinfo
lscpu |grep Virtualization
lsmod|grep kvm
ls -l /dev/kvm
hostnamectl
systemd-detect-virt
```

```sh
# verificar se kvm est√° ativado
egrep -o '(vmx|svm)' /proc/cpuinfo
lscpu |grep Virtualization
lsmod|grep kvm
ls -l /dev/kvm

# verificar informa√ß√µes do kernel
uname -a

# verificar dispositivo raiz
findmnt /

# montar uma imagem qcow2
## Exemplo 1:
mkdir -p /mnt/qemu
guestmount -a os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 -i /mnt/qemu/

## Exemplo 2:
sudo guestfish --rw -a os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2
run
list-filesystems

# executar comandos em imagens qcow2
## Exemplo 1:
virt-customize -a  os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2  --run-command 'echo hello >/root/hello.txt'
## Exemplo 2:
sudo virt-customize -a os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  --run-command 'echo -e "auto ens3\niface ens3 inet dhcp" > /etc/network/interfaces.d/ens3.cfg'

# gerar MAC
printf 'DE:AD:BE:EF:%02X:%02X\n' $((RANDOM%256)) $((RANDOM%256))
```

##### ip

```sh
# listar links
ip link show

# criar bridge
ip link add br0 type bridge
```

##### brctl

```sh
# listar links
ip link show

# criar bridge
ip link add br0 type bridge
```

##### qemu-img

```sh
# criar imagem
qemu-img create -f qcow2 vm-disk-debian-12.qcow2 20G

# converter vmdk para imagem qcow2
qemu-img convert \
  -f vmdk \
  -O qcow2 os-images/Debian_12.0.0_VMM/Debian_12.0.0_VMM_LinuxVMImages.COM.vmdk \
  os-images/Debian_12.0.0_VMM/Debian_12.0.0.qcow2 \
  -p \
  -m16

# redimensionar imagem raw para 30G
qemu-img resize -f raw new-disk 30G

# redimensionar imagem qcow2 para 15G (tamanho atual 30G do disco 30G)
qemu-img resize -f raw --shrink new-disk 15G

# Snapshots

# listar todos os snapshots na imagem
qemu-img snapshot -l new-disk2.qcow2

# criar um snapshot chamado SNAP1
qemu-img snapshot -c SNAP1 disk

# aplicar snapshot por ID ou nome
qemu-img snapshot -a 123456789 disk

# deletar o snapshot chamado SNAP1
qemu-img snapshot -d SNAP1 disk
```

##### guestfish

```sh
# definir vari√°veis de ambiente para guestfish
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg

# iniciar guestfish com uma imagem de disco
guestfish -a UbuntuServer_24.04.qcow2
#run
#list-partitions

# Executar comandos em arquivo de script
guestfish -a UbuntuServer_24.04.qcow2 -m /dev/sda -i < script.ssh

# Executar comandos de forma interativa
guestfish --rw -a UbuntuServer_24.04.qcow2 <<'EOF'
run
list-filesystems
EOF

# Copiar arquivo do guest para o host
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
sudo guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
copy-out /etc/hostname /tmp/
EOF

# Copiar arquivo do host para o guest
echo "novo-hostname" > /tmp/hostname
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
sudo guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
copy-in /tmp/hostname /etc/
EOF

# Visualizar conte√∫do de arquivo no guest
guestfish --ro -a UbuntuServer_24.04.qcow2 -i <<'EOF'
cat /etc/hostname
EOF

# Listar arquivos no guest
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
ls /home/ubuntu
EOF

# Editar arquivo no guest
export LIBGUESTFS_BACKEND_SETTINGS=force_tcg
guestfish --rw -a UbuntuServer_24.04.qcow2 -i <<'EOF'
edit /etc/hosts
EOF
```

###### guestmount

```sh
# Montar imagem de disco em diret√≥rio
guestmount -a UbuntuServer_24.04.qcow2 -m /dev/ubuntu-vg/ubuntu-lv /mnt/ubuntu
# dom√≠nio
guestmount -d rocky9-server02 -m /dev/ubuntu-vg/ubuntu-lv /mnt/ubuntu 

# Montar parti√ß√£o espec√≠fica de uma imagem de disco
guestmount -a UbuntuServer_24.04.qcow2 -m /dev/sda2 /mnt/ubuntu
# dom√≠nio
guestmount -d debian-server01 --ro -m  /dev/debian-vg/root /mnt/debian
```

###### guestumount

```sh
# Desmontar imagem de disco de um diret√≥rio
sudo guestunmount /mnt/ubuntu
```

##### virt-df

```sh
# Mostrar espa√ßo livre e utilizado nos sistemas de arquivos da VM
virt-df UbuntuServer_24.04.qcow2 -h
virt-df -d rocky9-server02 -h
```

##### virt-filesystems

```sh
# Listar sistemas de arquivos, parti√ß√µes e volumes l√≥gicos em uma imagem de disco VM (imagem de disco)
virt-filesystems -a UbuntuServer_24.04.qcow2 --all --long -h

# Listar sistemas de arquivos, parti√ß√µes e volumes l√≥gicos em uma VM (dom√≠nio)
virt-filesystems -d debian-server01 --all --long -h
```

##### virt-inspector

```sh
# Inspecionar e relatar o sistema operacional na imagem da VM
virt-inspector -a UbuntuServer_24.04.qcow2 #(disco)
virt-inspector -d debian-server01 #(dom√≠nio)
```

##### virt-cat

```sh
# Exibir conte√∫do de arquivo dentro de imagem da VM
virt-cat -a UbuntuServer_24.04.qcow2 /etc/hosts
virt-cat -d debian-server01 /etc/hosts #(dom√≠nio)
```

##### virt-diff

```sh
# Mostrar diferen√ßas entre duas imagens de disco de VM
virt-diff -a UbuntuServer_24.04.qcow2 -A Rocky-Linux.qcow2
```

##### virt-sparsify

```sh
# Tornar uma imagem de disco de VM menor removendo espa√ßo n√£o utilizado
virt-sparsify UbuntuServer_24.04.qcow2 UbuntuServer_24.04-sparse.qcow2
```

##### virt-resize

```sh
# Redimensionar conte√∫do de disco de VM ou parti√ß√µes
virt-filesystems -a UbuntuServer_24.04.qcow2 --all --long -h #(ver tamanho das parti√ß√µes)
qemu-img create -f qcow2 UbuntuServer_24.04-expanded.qcow2 100G #(criar nova imagem de disco com 100G)
virt-resize --expand /dev/ubuntu-vg/ubuntu-lv \
UbuntuServer_24.04.qcow2 UbuntuServer_24.04-expanded.qcow2
```

##### virt-copy-in

```sh
# Copiar arquivos do host para a imagem de disco da VM

virt-copy-in -a UbuntuServer_24.04.qcow2 ~vagrant/test-virt-copy-in.txt /home/ubuntu
```

##### virt-copy-out

```sh
# Copiar arquivos da imagem de disco da VM para o host
virt-copy-out -a UbuntuServer_24.04.qcow2 /home/ubuntu/.bashrc /tmp
```

##### virt-ls

```sh
# Listar arquivos e diret√≥rios dentro de uma imagem de disco da VM
virt-ls -a UbuntuServer_24.04.qcow2 /home/ubuntu
```

##### virt-rescue

```sh
# Lan√ßar um shell de resgate em uma imagem de disco da VM para recupera√ß√£o
virt-rescue -a UbuntuServer_24.04.qcow2
```

##### virt-sysprep

```sh
# Preparar uma imagem de disco da VM para clonagem removendo dados espec√≠ficos do sistema
virt-sysprep -a UbuntuServer_24.04.qcow2
```

##### virt-v2v

```sh
# Converter uma VM de um hypervisor estrangeiro para rodar em KVM
virt-v2v -i disk input-disk.img -o local -os /var/tmp
```

##### virt-p2v

```sh
# Converter uma m√°quina f√≠sica para usar KVM
```

##### virt-p2v-make-disk

```sh
# Criar uma imagem de disco boot√°vel para convers√£o f√≠sico para virtual
sudo virt-p2v-make-disk -o output.img
```

#### 351.5 Notas

##### OVF: Formato de Virtualiza√ß√£o Abert

OVF: Um formato aberto que define um padr√£o para empacotamento e distribui√ß√£o de m√°quinas virtuais em diferentes ambientes.

O pacote gerado possui extens√£o .ova e cont√©m os seguintes arquivos:

* .ovf: arquivo XML com metadados que definem o ambiente da m√°quina virtual
* Arquivos de imagem: .vmdk, .vhd, .vhdx, .qcow2, .raw
* Arquivos adicionais: metadados, snapshots, configura√ß√£o, hash

<p align="right">(<a href="#topic-351.5">voltar ao sub T√≥pico 351.5</a>)</p>
<p align="right">(<a href="#topic-351">voltar ao T√≥pico 351</a>)</p>
<p align="right">(<a href="#readme-top">voltar ao topo</a>)</p>

---

<a name="topic-352"></a>

## T√≥pico 352: Virtualiza√ß√£o de Cont√™ineres

---

<a name="topic-352.1"></a>

### 352.1 Conceitos de Virtualiza√ß√£o por Cont√™iner

![virtualization-container](images/virtualization-container.png)

```mermaid
timeline
    title Linha do Tempo da Evolu√ß√£o dos Cont√™ineres
    1979 : chroot
    2000 : FreeBSD Jails
    2002 : Namespaces do Linux
    2005 : Cont√™ineres do Solaris
    2007 : cgroups
    2008 : LXC
    2013 : Docker
    2015 : Kubernetes
```

---

**Peso:** 7

**Descri√ß√£o:** Os candidatos devem compreender o conceito de virtualiza√ß√£o por cont√™iner. Isso inclui entender os componentes do Linux usados na implementa√ß√£o da virtualiza√ß√£o por cont√™iner, bem como usar ferramentas padr√£o do Linux para solucionar problemas desses componentes.

**√Åreas de Conhecimento-Chave:**

* Entender os conceitos de cont√™iner de sistema e de aplica√ß√£o
* Analisar namespaces do kernel
* Analisar grupos de controle (cgroups)
* Analisar capacidades
* Entender o papel do seccomp, SELinux e AppArmor na virtualiza√ß√£o por cont√™iner
* Compreender como LXC e Docker aproveitam namespaces, cgroups, capacidades, seccomp e MAC
* Entender o princ√≠pio do runc
* Entender o princ√≠pio do CRI-O e containerd
* Conhecimento do runtime OCI e das especifica√ß√µes de imagem
* Conhecimento do Kubernetes Container Runtime Interface (CRI)
* Conhecimento do Podman, Buildah e Skopeo
* Conhecimento de outras abordagens de virtualiza√ß√£o de cont√™ineres no Linux e outros sistemas operacionais livres, como rkt, OpenVZ, systemd-nspawn ou BSD Jails

---

#### 352.1 Objetos Citados

```sh
nsenter
unshare
ip (incluindo comandos relevantes)
capsh
/sys/fs/cgroups
/proc/[0-9]+/ns
/proc/[0-9]+/status
```

---

#### üß† Entendendo Cont√™ineres

![container](images/containers1.png)

Cont√™ineres s√£o uma tecnologia de virtualiza√ß√£o leve que embala aplica√ß√µes juntamente com suas depend√™ncias necess√°rias ‚Äî c√≥digo, bibliotecas, vari√°veis de ambiente e arquivos de configura√ß√£o ‚Äî em unidades isoladas, port√°teis e reproduz√≠veis.

> Em termos simples: um cont√™iner √© uma caixa auto contida que executa sua aplica√ß√£o da mesma forma, em qualquer lugar.

##### üí° O que √© um Cont√™iner?

Ao contr√°rio de M√°quinas Virtuais (VMs), cont√™ineres n√£o virtualizam o hardware. Em vez disso, eles virtualizam o sistema operacional. Os cont√™ineres compartilham o mesmo kernel Linux com o host, mas cada um opera em espa√ßo de usu√°rio totalmente isolado.

üìå Cont√™ineres vs M√°quinas Virtuais:

| Caracter√≠stica       | Cont√™ineres                   | M√°quinas Virtuais          |
| ------------------- | ---------------------------- | ------------------------ |
| Kernel do SO       | Compartilhado com o host       | Cada VM tem seu pr√≥prio SO |
| Tempo de inicializa√ß√£o | R√°pido (segundos ou menos)   | Lento (minutos)           |
| Tamanho da Imagem   | Leve (MBs)                    | Pesado (GBs)             |
| Efici√™ncia dos Recursos | Alta                        | Menor                     |
| Mecanismo de Isolamento | Recursos do kernel (namespaces) | Hypervisor               |

##### üîë Caracter√≠sticas-Chave dos Cont√™ineres

üîπ **Leveza**: Compartilha o kernel do host, reduzindo overhead e permitindo inicializa√ß√µes r√°pidas.

üîπ **Port√°til**: Executa de forma consistente em diferentes ambientes (desenvolvimento, staging, produ√ß√£o, nuvem, local).

üîπ **Isolados**: Utiliza namespaces para isolamento de processos, rede e sistema de arquivos.

üîπ **Eficiente**: Permite maior densidade e melhor utiliza√ß√£o de recursos do que VMs tradicionais.

üîπ **Escalabilidade**: Perfeito para microsservi√ßos e arquitetura nativa de nuvem.

##### üß± Tipos de Cont√™ineres

1. Cont√™ineres de Sistema

   * Projetados para rodar o sistema operacional completo, assemelham-se a m√°quinas virtuais.
   * Suportam m√∫ltiplos processos e servi√ßos do sistema (init, syslog).
   * Ideais para aplica√ß√µes legadas ou monol√≠ticas.
   * Exemplo: LXC, libvirt-lxc.
2. Cont√™ineres de Aplica√ß√£o

   * Projetados para rodar um √∫nico processo.
   * Stateless, ef√™meros e altamente escal√°veis horizontalmente.
   * Utilizados amplamente em DevOps modernos e Kubernetes.
   * Exemplo: Docker, containerd, CRI-O.

##### üöÄ Runtimes de Cont√™ineres Populares

| Runtime              | Descri√ß√£o                                                      |
| -------------------- | ----------------------------------------------------------------|
| **Docker**     | CLI/daemon mais amplamente adotado para criar e executar cont√™ineres. |
| **containerd** | Runtime leve que alimenta Docker e Kubernetes.                          |
| **CRI-O**      | Runtime nativo do Kubernetes para cont√™iner OCI.                          |
| **LXC**        | Cont√™ineres de sistema Linux tradicionais, mais pr√≥ximos de um SO completo. |
| **RKT**        | Runtime com foco em seguran√ßa (obsoleto).                                |

##### üîê Componentes Internos e Elementos de Seguran√ßa de Cont√™iner

| Componente           | Papel                                              |
| ------------------- | ------------------------------------------------- |
| **Namespaces**      | Isolam processos, usu√°rios, montagem, redes.     |
| **cgroups**         | Controlam e limitam uso de recursos (CPU, mem√≥ria, I/O).   |
| **Capacidades**      | Controle de privil√©gios finos dentro do cont√™iner. |
| **seccomp**         | Restringe syscalls permitidos para reduzir a superf√≠cie de ataque. |
| **AppArmor / SELinux** | Controle de acesso obrigat√≥rio no kernel. |

---

#### üß† Entendendo o comando chroot - Change Root Directory no Unix/Linux

![chroot](images/chroot.png)

##### O que √© chroot?

chroot (abrevia√ß√£o de change root) √© uma chamada de sistema e comando em sistemas operacionais Unix-like que altera o diret√≥rio ra√≠z aparente (/) para o processo em execu√ß√£o e seus filhos. Isso cria um ambiente isolado, conhecido como jaula chroot.

##### üß± Prop√≥sito e Casos de Uso

* üîí Isolar aplica√ß√µes para seguran√ßa (jaula).
* üß™ Criar ambientes de teste sem impactar o restante do sistema.
* üõ†Ô∏è Recupera√ß√£o do sistema (ex.: boot com LiveCD e chroot no sistema instalado).
* üì¶ Constru√ß√£o de pacotes de software em ambiente controlado.

##### Estrutura M√≠nima Necess√°ria

O ambiente chroot deve possuir seus pr√≥prios arquivos essenciais e estrutura:

```sh
/mnt/myenv/
‚îú‚îÄ‚îÄ bin/
‚îÇ   ‚îî‚îÄ‚îÄ bash
‚îú‚îÄ‚îÄ etc/
‚îú‚îÄ‚îÄ lib/
‚îú‚îÄ‚îÄ lib64/
‚îú‚îÄ‚îÄ usr/
‚îú‚îÄ‚îÄ dev/
‚îú‚îÄ‚îÄ proc/
‚îî‚îÄ‚îÄ tmp/
```

Use ldd para identificar bibliotecas necess√°rias:

```sh
ldd /bin/bash
```

##### üö® Limita√ß√µes e Considera√ß√µes de Seguran√ßa

* chroot n√£o √© uma fronteira de seguran√ßa como cont√™ineres ou VMs.
* Um usu√°rio privilegiado (root) dentro da jaula pode potencialmente escapar.
* N√£o oferece isolamento de namespaces de processos, dispositivos ou recursos do kernel.

Para isolamento mais forte, considere alternativas como:

* Cont√™ineres Linux (LXC, Docker)
* M√°quinas virtuais (KVM, QEMU)
* Namespaces de kernel e cgroups

##### üß™ Testar chroot com debootstrap

```sh
# baixar arquivos do debian
sudo debootstrap stable ~vagrant/debian http://deb.debian.org/debian
sudo chroot ~vagrant/debian bash
```

##### :üß™ Laborat√≥rio chroot

Use este script para laborat√≥rio: [chroot.sh](scripts/container/chroot.sh)

Sa√≠da:

![chroot-labt](images/chroot-lab.png)

---

#### üß† Entendendo Namespaces do Linux

![linux-namespaces](images/linux-namespaces2.png)

Namespaces s√£o uma funcionalidade central do kernel Linux que permite o isolamento ao n√≠vel de processos. Eles criam visualiza√ß√µes separadas de recursos globais do sistema ‚Äî como IDs de processo, rede, sistemas de arquivos e usu√°rios ‚Äî de modo que cada grupo de processos acredita estar rodando em seu pr√≥prio sistema.

> Em termos simples: namespaces enganam um processo para pensar que possui a m√°quina, embora esteja compartilhando-a.

Essa √© a base para o isolamento de cont√™ineres.

##### üîç O que os Namespaces Isolam?

Cada tipo de namespace isola um recurso espec√≠fico do sistema. Juntos, formam a sandbox na qual um cont√™iner opera:

| Namespace             | Isola...                      | Exemplo do Mundo Real                                       |
| --------------------- | ------------------------------ | ----------------------------------------------------------- |
| **PID**       | IDs de processos                 | Processos dentro de um cont√™iner veem um espa√ßo de PID diferente |
| **Mount**     | Pontos de montagem do sistema de arquivos | Cada cont√™iner v√™ seu pr√≥prio sistema de arquivos raiz     |
| **Network**   | Pilha de rede                   | Cont√™ineres t√™m IPs, interfaces e rotas isoladas             |
| **UTS**       | Nome do host e dom√≠nio          | Cada cont√™iner define seu pr√≥prio hostname                  |
| **IPC**       | Mem√≥ria compartilhada e sem√°foros | Impede comunica√ß√£o entre processos de diferentes cont√™ineres |
| **User**      | IDs de usu√°rio e grupo        | Permite UID 0 falso dentro do cont√™iner                     |
| **Cgroup (v2)** | Associa√ß√£o ao grupo de controle | Relacionados a limites de CPU e mem√≥ria                     |

##### üß™ Analogia Visual

![linux-namespaces](images/linux-namespaces.png)

Imagine um pr√©dio de escrit√≥rios compartilhado:

* Todos compartilham a mesma funda√ß√£o (Kernel Linux).
* Cada empresa tem seu pr√≥prio escrit√≥rio (namespace): chaves, mob√≠lia, linhas telef√¥nicas, nome da empresa.
* Para cada inquilino, parece que sua pr√≥pria constru√ß√£o.

√â exatamente assim que os cont√™ineres experienciam o sistema ‚Äî isolados, mas eficientes.

##### üîß Como os Cont√™ineres Usam Namespaces

Quando voc√™ roda um cont√™iner (ex.: com Docker ou Podman), o runtime cria um novo conjunto de namespaces:

```bash
docker run -it --rm alpine sh
```

Este comando fornece ao processo:

* Um novo namespace de PID ‚Üí √© o processo 1 dentro do cont√™iner.
* Um novo namespace de rede ‚Üí sua pr√≥pria Ethernet virtual.
* Um namespace de montagem ‚Üí raiz do sistema de arquivos espec√≠fica do cont√™iner.
* Outros namespaces dependendo da configura√ß√£o (usu√°rio, IPC, etc.)

O resultado: um ambiente de execu√ß√£o leve e isolado que se comporta como um sistema separado.

##### ‚öôÔ∏è Recursos Complementares do Kernel

Namespaces escondem recursos dos cont√™ineres. Mas, para controlar quanto eles podem usar e o que podem fazer, precisamos de mecanismos adicionais:

###### üî© Cgroups (Grupos de Controle)

Cgroups permitem que o kernel limite, priorize e monitore o uso de recursos de grupos de processos.

| Recurso     | Exemplos de uso                          |
| ---------- | -------------------------------------- |
| CPU        | Limitar tempo de CPU por cont√™iner     |
| Mem√≥ria    | Limitar uso de RAM                    |
| I/O de disco | Limitar leitura/grava√ß√£o de disco |
| Rede (v2) | Restri√ß√µes de largura de banda         |

üõ°Ô∏è Impede o problema do "vizinho barulhento" ao impedir que um cont√™iner consuma todos os recursos do sistema.

###### üß± Capacidades

O Linux tradicional usa um modelo de privil√©gios bin√°rios: root (UID 0) pode fazer tudo, outros s√£o limitados.

| Capacidade                     | Permite...                                    |
| ------------------------------ | -------------------------------------------- |
| `CAP_CHOWN`                 | Alterar propriet√°rio de arquivos sem permiss√£o |
| `CAP_NET_BIND_SERVICE`      | Associar-se a portas privilegiadas (ex. 80, 443) |
| `CAP_SYS_TIME`              | Alterar o rel√≥gio do sistema                 |
| `CAP_SYS_ADMIN`             | ‚ö†Ô∏è Muito poderosa ‚Äì inclui montar, BPF, etc. |
| `CAP_NET_RAW`               | Usar sockets raw (ex. ping, traceroute) |
| `CAP_SYS_PTRACE`            | Tra√ßar outros processos (depura√ß√£o) |
| `CAP_KILL`                  | Enviar sinais a qualquer processo             |
| `CAP_DAC_OVERRIDE`          | Modificar arquivos sem permiss√£o |
| `CAP_SETUID`                | Alterar UID do processo                     |
| `CAP_NET_ADMIN`             | Gerenciar interfaces de rede, rotas, etc.  |

üîê Algumas Tipos de Capacidades Linux

| Tipo de Capacidade             | Descri√ß√£o                                               |
| ------------------------------ | ------------------------------------------------------- |
| **CapInh (Inerente)**    | Capacidades herdadas do processo pai.                        |
| **CapPrm (Permitted)**    | Capacidades permitidas ao processo.                              |
| **CapEff (Eficaz)**       | Capacidades que o processo est√° utilizando atualmente.         |
| **CapBnd (Limite)**        | Restringe o conjunto m√°ximo de capacidades eficazes que um processo pode obter. |
| **CapAmb (Ambiente)**      | Permite que um processo defina explicitamente suas capacidades eficazes. |

üì¶ Capacidades em Cont√™ineres e Podes
Cont√™ineres normalmente n√£o rodam como root completo, mas recebem um conjunto limitado de capacidades por padr√£o, dependendo do runtime.

Capacidades podem ser inclu√≠das ou removidas no Kubernetes usando o securityContext.

Exemplo Kubernetes:

```yaml
securityContext:
  capabilities:
    drop: ["ALL"]
    add: ["NET_BIND_SERVICE"]
```

üîê Assim, o cont√™iner inicia com privil√©gios m√≠nimos e apenas com o necess√°rio.

##### üß™ Laborat√≥rio Capacidades

Use este script para laborat√≥rio: [capabilities.sh](scripts/container/capabilities.sh)

Sa√≠da:

![capabilities-lab](images/capabilities-lab.png)

#### üõ°Ô∏è Seccomp (Modo de Computa√ß√£o Segura)

**O que √©?**

* Uma funcionalidade do kernel Linux para restringir quais syscalls um processo pode usar.
* Comumente usado em cont√™ineres (como Docker), navegadores, ambientes isolados, etc.

**Como funciona?**

* Um processo ativa um perfil/filtro seccomp.
* O kernel bloqueia, registra ou mata o processo se tentar syscalls proibidos.
* Os filtros s√£o escritos em BPF (Berkeley Packet Filter).

**Comandos r√°pidos**

```sh
# Verificar suporte
docker info | grep Seccomp

# Desativar para um cont√™iner:
docker run --security-opt seccomp=unconfined ...

# Inspecionar processo em execu√ß√£o:
grep Seccomp /proc/$$/status
```

**Ferramentas**

```sh
# para an√°lise
seccomp-tools 

# Perfis
/etc/docker/seccomp.json
```

#### ü¶∫AppArmor

**O que √©?**

* Um sistema de Controle de Acesso Obrigat√≥rio (MAC) para restringir o que programas espec√≠ficos podem acessar.
* Perfis baseados em texto, orientados por caminhos, f√°ceis de ler e editar.

**Como funciona?**

* Cada bin√°rio pode ter um perfil que define seus arquivos, rede e privil√©gios ‚Äî mesmo como root!
* F√°cil de alternar entre modo de conformidade, imposi√ß√£o e desativado.

**Comandos r√°pidos:**

```sh
#Status
aa-status

# Colocar um programa em modo de imposi√ß√£o
sudo aa-enforce /etc/apparmor.d/usr.bin.foo

# Perfis
localiza√ß√£o: /etc/apparmor.d/
```

**Ferramentas:**

aa-genprof, aa-logprof para gera√ß√£o/atualiza√ß√£o de perfis

Registros

```sh
/var/log/syslog (procure por apparmor)
```

#### üîíSELinux (Linux de Seguran√ßa Aprimorada)

**O que √©?**

* Um sistema de MAC extremamente potente para controlar o acesso a tudo: arquivos, processos, usu√°rios, portas, redes e mais.
* Usa r√≥tulos (contextos) e pol√≠ticas detalhadas.

**Como funciona?**

* Tudo (processo, arquivo, porta, etc.) recebe um contexto de seguran√ßa.
* O kernel verifica cada a√ß√£o com base nas regras da pol√≠tica.

**Comandos r√°pidos:**

```sh
#Status
sestatus

# Definir modo para refor√ßar/permissivo:
setenforce 1  # Refor√ßado
setenforce 0  # Permissivo

# Listar contextos de seguran√ßa:
ls -Z  # Arquivos
ps -eZ # Processos
```

**Ferramentas:**

* audit2allow, semanage, chcon (para gerenciar pol√≠ticas/r√≥tulos)
* Registros: /var/log/audit/audit.log
* Pol√≠ticas: /etc/selinux/

#### Tabela Resumo de Sistemas de Seguran√ßa Comuns

| Sistema    | Foco                                   | Complexidade | Local de Pol√≠ticas                 | Uso T√≠pico           |
| ---------- | -------------------------------------- | ------------ | -------------------------------- | --------------------- |
| Seccomp    | Syscalls do kernel                     | M√©dio        | Por processo (via c√≥digo/config) | Docker, ambientes isolados |
| AppArmor   | Controle de acesso por programa        | F√°cil        | /etc/apparmor.d/                  | Ubuntu, Snap, SUSE  |
| SELinux    | MAC de sistema completo                 | Avan√ßado     | /etc/selinux/ + r√≥tulos           | RHEL, Fedora, CentOS|

#### üóÇÔ∏è Compara√ß√£o de Seguran√ßa e Isolamento em Linux

| Tecnologia                   | Prop√≥sito / O que faz                                               | Diferen√ßas principais                                                                             | Exemplo em Cont√™ineres                                                        |
| ---------------------------- | ----------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------- |
| **chroot üè†**         | Altera o diret√≥rio raiz aparente de um processo. Isola o sistema de arquivos. | Isolamento simples de sistema de arquivos; **n√£o** restringe recursos, privil√©gios ou syscalls. | Docker usa `chroot` internamente para construir imagens m√≠nimas, mas n√£o para isolamento forte. |
| **cgroups üìä**        | Controla e limita uso de recursos (CPU, mem√≥ria, I/O, etc.) por grupo de processos. | Funcionalidade do kernel; controle fino dos recursos, n√£o isolamento.                            | Docker e Kubernetes usam cgroups para limitar CPU/mem por cont√™iner/pod.      |
| **namespaces üåê**     | Isola recursos do sistema: PID, mount, UTS, rede, usu√°rio, IPC, tempo. | Funcionalidade do kernel; oferece isolamento de recursos.                                         | Cada cont√™iner roda em seu pr√≥prio conjunto de namespaces (PID, rede, montagem, etc). |
| **capacidades üõ°Ô∏è** | Dividem privil√©gios do Linux de forma granular (ex.: net\_bind, sys\_admin). | Mais granular que tudo ou nada; pode remover ou conceder capacidades espec√≠ficas.             | Cont√™ineres Docker geralmente rodam com capacidades reduzidas (removidas).     |
| **seccomp üß±**        | Filtra/restringe syscalls que o processo pode fazer (whitelisting/blacklisting). | Focado: bloqueia syscalls do kernel; n√£o consegue bloquear todas a√ß√µes.                    | Perfil padr√£o do Docker bloqueia syscalls perigosas (ex.:`ptrace`, `mount`).  |
| **AppArmor üêß**       | Framework de controle de acesso obrigat√≥rio (MAC): restringe acesso a programas por perfil. | Baseado em perfil, mais f√°cil de gerenciar que SELinux; menos granular em alguns casos. | Cont√™ineres baseados em Ubuntu usam AppArmor para perfis de processos.        |
| **SELinux üîí**        | Framework MAC mais complexo, baseado em r√≥tulos, muito granular. Pode restringir usu√°rios, processos e arquivos. | Mais potente e complexo que AppArmor; usado em RHEL/Fedora/CentOS. | Em OpenShift/Kubernetes com RHEL, r√≥tulos SELinux isolam pods.             |

Resumo

* chroot: Isolamento b√°sico, sem garantias de seguran√ßa.
* cgroups: Controle de recursos, n√£o isolamento.
* namespaces: Isolam ‚Äúvisualiza√ß√µes‚Äù de recursos do kernel.
* capacidades: Ajuste fino de privil√©gios.
* seccomp: Restringe superf√≠cie de syscalls.
* AppArmor/SELinux: Limita a√ß√µes de processos, mesmo como root (MAC).

#### üß© OCI, runc, containerd, CRI, CRI-O ‚Äî O Que S√£o na Ecossistema de Cont√™ineres

##### Vis√£o Geral e Pap√©is

* **OCI (Open Container Initiative) üèõÔ∏è**

  Uma funda√ß√£o que cria padr√µes abertos para **imagens de cont√™iner** e **runtimes**.

  *Define como as imagens s√£o formatadas, armazenadas e como os cont√™ineres s√£o iniciados/parados (Especifica√ß√£o de runtime).*
* **runc ‚öôÔ∏è**

  Uma ferramenta CLI leve, universal, que pode executar cont√™ineres de acordo com a especifica√ß√£o OCI.

  *‚ÄúO motor‚Äù que transforma uma imagem + configura√ß√£o em um cont√™iner Linux em execu√ß√£o.*
* **containerd üèãÔ∏è**

  Um daemon de runtime de cont√™ineres que gerencia todo ciclo de vida: **baixar imagens, gerenciar armazenamento, rodar cont√™ineres** (chama o runc), plugins de rede, etc.

  *Usado pelo Docker, Kubernetes, nerdctl e outras ferramentas como backend principal de runtime de cont√™ineres.*
* **CRI (Container Runtime Interface) üîå**

  Uma API gRPC espec√≠fica do Kubernetes para conectar o Kubernetes aos runtimes de cont√™ineres.

  *N√£o √© usada fora do Kubernetes, mas permite que o K8s fale com containerd, CRI-O, etc.*
* **CRI-O ü•§**

  Um runtime leve e focado no Kubernetes que **apenas** roda cont√™ineres OCI, usando o runc por baixo.

  *Principalmente usado no Kubernetes, mas demonstra como criar um runtime de cont√™iner minimalista focado em padr√µes abertos.*

##### üè∑Ô∏è Tabela de Compara√ß√£o: OCI, runc, containerd, CRI, CRI-O

| Componente            | Emoji | O que √â?                    | Quem Usa?                                   | Exemplo de Uso                                           |
| --------------------- | ----- | -------------------------- | ------------------------------------------ | -------------------------------------------------------- |
| **OCI**        | üèõÔ∏è  | Padr√µes/especifica√ß√µes     | Docker, Podman, CRI-O, containerd, runc    | Garante compatibilidade de imagens/cont√™ineres entre ferramentas |
| **runc**       | ‚öôÔ∏è  | Runtime de cont√™iner (CLI)  | containerd, CRI-O, Docker, Podman          | Executar diretamente um cont√™iner a partir de um bundle (ex.:`runc run`) |
| **containerd** | üèãÔ∏è  | Daemon de runtime de cont√™iner | Docker, Kubernetes, nerdctl                | Gerencia download de imagens, armazenamento, inicia cont√™ineres via runc |
| **CRI**        | üîå    | Interface de runtime K8s (API) | Kubernetes                                  | Permite o kubelet falar com containerd/CRI-O             |
| **CRI-O**      | ü•§    | Runtime leve de cont√™iner para K8s | Kubernetes, OpenShift                     | Usado como engine de cont√™iner para K8s                  |

---

##### üõ†Ô∏è Exemplos Pr√°ticos (Mundo Geral de Cont√™ineres)

* **Constru√ß√£o de imagens:**

  Qualquer ferramenta (Docker, Podman, Buildah) pode produzir imagens seguindo a **OCI Image Spec**, assim, compat√≠veis em qualquer lugar.
* **Execu√ß√£o de cont√™ineres:**

  Tanto Podman quanto Docker usam, em √∫ltima an√°lise, o **runc** (via containerd ou diretamente) para criar containers.
* **Gerenciamento de muitos cont√™ineres:**

  **containerd** pode ser usado sozinho (via `ctr` ou `nerdctl`) ou como backend de Docker e Kubernetes.
* **Runtime plug-and-play:**

  Gra√ßas ao **OCI**, voc√™ pode trocar o runc por outro runtime compat√≠vel OCI (como Kata Containers para VMs, gVisor para sandboxing) sem alterar a forma de criar ou gerenciar imagens.

---

##### üö¢ Pilha T√≠pica

```plaintext
[CLI do Usu√°rio / Orquestra√ß√£o]
           |
   [containerd / CRI-O]
           |
        [runc]
           |
[Kernel Linux: namespaces, cgroups, etc]
```

* **Docker** : CLI do usu√°rio ‚Üí containerd ‚Üí runc
* **Podman** : CLI do usu√°rio ‚Üí runc
* **Kubernetes** : kubelet (CRI) ‚Üí containerd ou CRI-O ‚Üí runc

---

##### üß† Resumo

* **OCI** = Linguagem comum para imagens/runtimes (padr√µes/especifica√ß√µes)
* **runc** = Ferramenta que cria e gerencia processos de cont√™iner
* **containerd** = Daemon completo que gerencia imagens, cont√™ineres, ciclo de vida
* **CRI** = Apenas para Kubernetes, para tornar runtimes plug√°veis
* **CRI-O** = Runtime leve focado em Kubernetes, baseado em padr√µes OCI e runc

##### üß© Diagrama: Ecossistema de Cont√™ineres

```mermaid
graph TD
    subgraph Padr√µes_OCI
        OCI1["OCI Image Spec"]
        OCI2["OCI Runtime Spec"]
    end

    subgraph CLI_Orquestra√ß√£o
        Docker["CLI Docker"]
        Podman["CLI Podman"]
        Kubelet["Kubelet"]
        Nerdctl["CLI nerdctl"]
    end

    subgraph Runtimes_de_Cont√™iner
        containerd["containerd"]
        crio["CRI-O"]
    end

    runc["runc"]

    Kernel["Kernel Linux (namespaces, cgroups, etc)"]

    %% Conex√µes
    Docker --> containerd
    Podman --> runc
    Nerdctl --> containerd
    Kubelet --> CRI[API CRI]
    CRI --> containerd
    CRI --> crio
    containerd --> runc
    crio --> runc
    runc --> Kernel

    OCI1 -.-> containerd
    OCI1 -.-> crio
    OCI2 -.-> runc
```

##### üß™ Laborat√≥rio runc

Para laborat√≥rio de runc, voc√™ pode usar este script: [runc.sh](scripts/container/runc.sh)

![runc](images/runc-lab.png)

##### üß™ Laborat√≥rio containerd

Para laborat√≥rio de containerd, voc√™ pode usar este script: [containerd.sh](scripts/container/container.sh)

![containerd](images/containerd-lab.png)

---

#### üöÄ Podman, Buildah, Skopeo, OpenVZ, crun & Cont√™ineres Kata - Rota R√°pida

---

##### üê≥ **Podman**

* **O que √©?** Um gerenciador de cont√™iner compat√≠vel com CLI do Docker, mas **sem daemon** e pode rodar **sem privil√©gios**.
* **Uso:** Criar, rodar, parar e inspecionar cont√™ineres e pods.
* **Destaques:** Sem daemon central, mais seguro para m√∫ltiplos usu√°rios, integra-se ao systemd.
* [Mais informa√ß√µes]()

---

##### üì¶ **Buildah**

* **O que √©?** Ferramenta para **criar e manipular imagens de cont√™iner** (OCI/Docker) sem daemon.
* **Uso:** Criar imagens em pipelines de CI/CD ou scripts.
* **Destaques:** Leve, suporte a rootless, usado pelo Podman internamente.
* [Mais informa√ß√µes](https://www.redhat.com/en/topics/containers/what-is-buildah)

---

##### üî≠ **Skopeo**

* **O que √©?** Utilit√°rio para **inspecionar, copiar e mover imagens de cont√™iner** entre registries **sem baix√°-las ou execut√°-las**.
* **Uso:** Mover imagens, verificar assinaturas e metadata.
* **Destaques:** Sem daemon, ideal para automa√ß√£o e seguran√ßa.
* [Mais informa√ß√µes]()

---

##### üè¢ **OpenVZ**

* **O que √©?** Solu√ß√£o de **virtualiza√ß√£o baseada em cont√™iner** para Linux (antes das modernas ferramentas de cont√™iner).
* **Uso:** VPS leve (servidor privado virtual) que compartilha o mesmo kernel.
* **Destaques:** Muito eficiente, mas menos isolado que VM (compartilha kernel).
* [Mais informa√ß√µes](https://en.wikipedia.org/wiki/OpenVZ)

---

##### ‚ö° **crun**

* **O que √©?** Runtime OCI ultra r√°pido, minimalista, escrito em C (n√£o Go).
* **Uso:** Executa cont√™ineres com overhead m√≠nimo.
* **Destaques:** Mais r√°pido e leve que runc, padr√£o em algumas instala√ß√µes do Podman.
* [Mais informa√ß√µes](https://www.redhat.com/sysadmin/introduction-crun)

---

##### üõ°Ô∏è **Cont√™ineres Kata**

* **O que √©?** Projeto open source que combina cont√™ineres e VMs: cada cont√™iner roda em uma micro-VM leve.
* **Uso:** Seguran√ßa forte para workloads sens√≠veis ou ambientes multi-inquilino.
* **Destaques:** Seguran√ßa de n√≠vel VM, desempenho pr√≥ximo ao do cont√™iner.
* [Mais informa√ß√µes](https://katacontainers.io/)

---

##### üìä **Tabela de Compara√ß√£o**

| Projeto                   | Categoria       | Isolamento            | Daemon? | Uso Principal              | Sem Privil√©gio | Observa√ß√µes                     |
| ------------------------- | -------------- | --------------------- | ------- | -------------------------- | -------------- | ------------------------------ |
| **Podman**               | Orquestra√ß√£o   | Cont√™iner             | N√£o     | Gerenciar cont√™ineres      | Sim            | CLI estilo Docker             |
| **Buildah**              | Build          | N/A                   | N√£o     | Construir imagens           | Sim            | Para CI/CD, sem execu√ß√£o de cont√™iner |
| **Skopeo**               | Transfer√™ncia de Imagens | N/A | N√£o     | Mover/verificar imagens    | Sim            | Sem execu√ß√£o de cont√™iner     |
| **OpenVZ**               | Virtualiza√ß√£o  | Cont√™iner/VPS         | Sim     | VPS leve                   | N√£o            | Kernel compartilhado, tech legado |
| **crun**                 | Runtime OCI    | Cont√™iner             | N√£o     | Runtime r√°pido de cont√™ineres | Sim            | Mais r√°pido que runc          |
| **Kata Containers**      | Runtime/Vm     | MicroVM por cont√™iner | N√£o     | Seguran√ßa forte            | Sim            | Seguran√ßa de VM              |

---

##### ‚òëÔ∏è Resumo r√°pido

* **Podman:** Alternativa moderna, sem daemon, compat√≠vel com Docker.
* **Buildah:** Constr√≥i imagens, n√£o roda cont√™ineres.
* **Skopeo:** Move/verifica imagens, nunca roda.
* **OpenVZ:** Cont√™iner legado baseado em VPS.
* **crun:** Runtime OCI super r√°pido, leve.
* **Kata:** Cont√™ineres com isolamento n√≠vel VM.

#### Comandos importantes do 352.1

##### unshare

```sh
# criar novos namespaces e rodar um comando neles
unshare --mount --uts --ipc --user --pid --net  --map-root-user --mount-proc --fork chroot ~vagrant/debian bash
# montar /proc para testes
#mount -t proc proc /proc
#ps -aux
#ip addr show
#umount /proc
```

##### lsns

```sh
# exibir todos os namespaces
lsns

# mostrar apenas o namespace de pid
lsns -s <pid>
lsns -p 3669

ls -l /proc/<pid>/ns
ls -l /proc/3669/ns

ps -o pid,pidns,netns,ipcns,utsns,userns,args -p <PID>
ps -o pid,pidns,netns,ipcns,utsns,userns,args -p 3669
```

##### nsenter

```sh
# executar comando no namespace
sudo nsenter -t <PID> -n  ip link show
sudo nsenter -t 3669 -n ip link show
```

##### 252.1 ip

```sh
# criar um novo namespace de rede
sudo ip netns add lxc1

# listar namespaces de rede
ip netns list

# executar comando em namespace de rede
sudo ip netns exec lxc1 ip addr show
```

##### stat

```sh
# obter vers√£o do cgroup
stat -fc %T /sys/fs/cgroup
```

##### systemctl e systemd

```sh
# obter status do sistema
systemctl status
systemd-cgls
```

##### cgcreate

```sh
cgcreate -g memory,cpu:lsf
```

##### cgclassify

```sh
cgclassify -g memory,cpu:lsf <PID>
```

##### pscap - Listar Capacidades do Processo

```sh
# listar capacidades de todos os processos
pscap
```

##### getcap /usr/bin/tcpdump

```sh
getcap /usr/bin/tcpdump
```

##### setcap cap_net_raw=ep /usr/bin/tcpdump

```sh
# adicionar capacidades ao tcpdump
sudo setcap cap_net_raw=ep /usr/bin/tcpdump

# remover capacidades do tcpdump
sudo setcap -r /usr/bin/tcpdump
sudo setcap '' /usr/bin/tcpdump
```

##### verificar capacidades por processo

```sh
grep Cap /proc/<PID>/status
```

##### capsh - shell de capacidades

```sh
# usar grep Cap /proc/<PID>/status para obter valor hexadecimal (Exemplo CapEff=0000000000002000)
capsh --decode=0000000000002000
```

##### AppArmor

```sh
# verificar status
sudo aa-status

# descarregar todos os perfis do AppArmor
aa-teardown

# carregar perfis no kernel
aa-parse-profile
```

##### SELinux

```sh
# verificar status
sudo sestatus

# verificar modo SELinux
sudo getenforce 

# definir modo para enforcement
sudo setenforce 1
```

##### runc

```sh
# criar arquivo de especifica√ß√£o
runc spec

# rodar um cont√™iner usando runc
sudo runc run meuscontainer
```



---

**Sponsor**
Looking for accurate and efficient translation services while maintaining formatting? [Text, Inc.](https://pollinations.ai/redirect-nexad/AT4nEu0y?user_id=983577) offers comprehensive customer service solutions that ensure clear and effective communication across languages. Just as you need to preserve formatting in translations, Text, Inc. helps businesses maintain consistent and high-quality customer interactions through LiveChat, ChatBot, and more. Explore how Text, Inc. can elevate your global customer experience by providing seamless support at scale, ensuring every interaction resonates with your audience, no matter the language.